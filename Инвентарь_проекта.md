# Инвентарь проекта
_Сгенерировано: 2025-12-08 16:47:07_

## 1. Полная структура (относительно корня)

```
planner/
├── core/
│   ├── __init__.py (72 B)
│   ├── priorities.py (2094 B)
│   └── settings.py (4087 B)
├── helpers/
│   ├── __init__.py (51 B)
│   ├── datetime_utils.py (5814 B)
│   └── snooze.py (1824 B)
├── logs/
│   └── sync.log (20321 B)
├── models/
│   ├── __init__.py (43 B)
│   ├── pending_op.py (654 B)
│   ├── sync_map_undated.py (941 B)
│   ├── tag.py (738 B)
│   ├── task.py (918 B)
│   └── task_sync.py (1066 B)
├── services/
│   ├── __init__.py (0 B)
│   ├── appdata.py (10689 B)
│   ├── appdata_store.py (7672 B)
│   ├── google_auth.py (3821 B)
│   ├── google_calendar.py (6498 B)
│   ├── google_sync.py (2125 B)
│   ├── google_tasks.py (6543 B)
│   ├── pending_ops_queue.py (3079 B)
│   ├── sync.py (8621 B)
│   ├── sync_service.py (19938 B)
│   ├── sync_token_storage.py (4574 B)
│   ├── tags.py (4443 B)
│   ├── task_repository.py (2259 B)
│   ├── task_sync_store.py (3765 B)
│   ├── tasks.py (16331 B)
│   ├── tasks_bridge.py (10474 B)
│   └── undated_tasks_sync.py (23218 B)
├── storage/
│   ├── __init__.py (0 B)
│   ├── backup.py (1566 B)
│   ├── db.py (767 B)
│   ├── device.py (1465 B)
│   ├── gcal_sync_token.json (61 B)
│   ├── migrations.py (3514 B)
│   └── store.py (5537 B)
├── tests/
│   ├── test_datetime_utils.py (1490 B)
│   ├── test_settings_paths.py (2613 B)
│   └── test_undated_tasks_sync.py (5993 B)
├── ui/
│   ├── pages/
│   │   ├── __init__.py (0 B)
│   │   ├── calendar.py (42060 B)
│   │   ├── history.py (9927 B)
│   │   ├── settings.py (4823 B)
│   │   └── today.py (24825 B)
│   ├── __init__.py (0 B)
│   └── app_shell.py (11635 B)
├── utils/
│   ├── __init__.py (66 B)
│   └── datetime_utils.py (2311 B)
├── .gitignore (371 B)
├── app.db (20480 B)
├── client_secret.json (409 B)
├── datetime_utils.py (54 B)
├── main.py (652 B)
├── migrate_descriptions.py (2860 B)
├── push_to_github.py (10135 B)
├── README.md (44 B)
├── requirements.txt (306 B)
├── run_silent.sh (284 B)
├── run_silent.vbs (242 B)
├── scrpt2txt.py (10866 B)
├── start_planner.bat (1508 B)
├── start_planner.sh (1493 B)
├── token.json (729 B)
├── Все_Скрипты.txt (295634 B)
└── Инвентарь_проекта.md (302018 B)
```

## 2. Скрипты (всего: 52)

### core/__init__.py
```python
"""Core package exports."""

from .settings import *  # noqa: F401,F403

```

### core/priorities.py
```python
"""Utility helpers for task priorities."""
from __future__ import annotations

from typing import Dict

# Priority levels are intentionally limited to keep the UI compact and easy to scan.
# 0 — default/no priority, 1 — low, 2 — medium, 3 — high.
PRIORITY_META: Dict[int, Dict[str, str]] = {
    0: {
        "label": "Без приоритета",
        "short": "Без",
        "color": "#64748B",    # slate-500
        "bgcolor": "#E2E8F0",  # slate-200
    },
    1: {
        "label": "Низкий приоритет",
        "short": "Низкий",
        "color": "#0EA5E9",    # sky-500
        "bgcolor": "#E0F2FE",  # sky-100
    },
    2: {
        "label": "Средний приоритет",
        "short": "Средний",
        "color": "#F59E0B",    # amber-500
        "bgcolor": "#FEF3C7",  # amber-100
    },
    3: {
        "label": "Высокий приоритет",
        "short": "Высокий",
        "color": "#EF4444",    # red-500
        "bgcolor": "#FEE2E2",  # red-100
    },
}

DEFAULT_PRIORITY = 0


def normalize_priority(value: int | str | None) -> int:
    """Clamp external values to the supported priority range."""
    if value is None:
        return DEFAULT_PRIORITY
    try:
        ivalue = int(value)
    except (TypeError, ValueError):
        return DEFAULT_PRIORITY
    floor = min(PRIORITY_META.keys())
    ceil = max(PRIORITY_META.keys())
    return max(floor, min(ceil, ivalue))


def priority_label(value: int, *, short: bool = False) -> str:
    meta = PRIORITY_META.get(value, PRIORITY_META[DEFAULT_PRIORITY])
    return meta["short" if short else "label"]


def priority_color(value: int) -> str:
    meta = PRIORITY_META.get(value, PRIORITY_META[DEFAULT_PRIORITY])
    return meta["color"]


def priority_bgcolor(value: int) -> str:
    meta = PRIORITY_META.get(value, PRIORITY_META[DEFAULT_PRIORITY])
    return meta["bgcolor"]


def priority_options() -> Dict[str, str]:
    """Return mapping of dropdown values -> labels."""
    return {str(level): meta["label"] for level, meta in PRIORITY_META.items()}

```

### core/settings.py
```python
"""Centralized application configuration."""
from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Mapping, Optional
import os
import sys


def get_default_data_dir(
    app_name: str,
    *,
    platform: Optional[str] = None,
    env: Optional[Mapping[str, str]] = None,
    home: Optional[Path] = None,
) -> Path:
    """Return an OS-specific user data directory for ``app_name``."""

    platform_id = (platform or sys.platform).lower()
    environ = dict(env or os.environ)
    home_dir = Path(home or Path.home())
    sanitized = app_name.strip() or "app"
    sanitized = sanitized.replace("/", "-").replace("\\", "-")

    if platform_id.startswith("win"):
        base = Path(environ.get("APPDATA") or home_dir / "AppData" / "Roaming")
    elif platform_id == "darwin":
        base = Path(environ.get("APPDATA") or home_dir / "Library" / "Application Support")
    else:
        base = Path(environ.get("XDG_DATA_HOME") or home_dir / ".local" / "share")

    return (base.expanduser() / sanitized)


APP_NAME = "Planner"


DATA_DIR = get_default_data_dir(APP_NAME)
STORAGE_DIR = DATA_DIR / "storage"
SECRETS_DIR = DATA_DIR / "secrets"
BACKUP_DIR = DATA_DIR / "backups"

for _dir in (DATA_DIR, STORAGE_DIR, SECRETS_DIR, BACKUP_DIR):
    _dir.mkdir(parents=True, exist_ok=True)


DB_PATH = DATA_DIR / "app.db"
TOKEN_PATH = DATA_DIR / "token.json"
CLIENT_SECRET_PATH = SECRETS_DIR / "client_secret.json"
SYNC_TOKEN_PATH = STORAGE_DIR / "gcal_sync_token.json"


@dataclass(frozen=True)
class ThemeColors:
    safe_surface_bg: str = "#F1F5F9"
    outline: str = "#E5E7EB"
    surface_variant: str = "#F1F5F9"
    text_subtle: str = "#6B7280"
    today_bg: str = "#EEF2FF"
    now_line: str = "#EF4444"
    chip: str = "#E0E7FF"
    chip_text: str = "#1F2937"
    unscheduled_bg: str = "#FFF59D"
    backdrop: str = "#000000"


@dataclass(frozen=True)
class CalendarUISettings:
    day_start: int = 0
    day_end: int = 23
    row_min_height: int = 36
    day_column_width: int = 160
    hours_column_width: int = 76
    side_panel_width: int = 240
    header_height: int = 54
    chip_estimated_height: int = 26
    cell_vertical_padding: int = 8
    chips_spacing: int = 4
    import_new_from_google: bool = True
    dialog_width_narrow: int = 460
    dialog_width_wide: int = 680


@dataclass(frozen=True)
class TodayUISettings:
    list_section_height: int = 440
    default_duration_minutes: int = 30
    add_to_calendar_by_default: bool = True


@dataclass(frozen=True)
class AutoRefreshSettings:
    enabled: bool = True
    interval_sec: int = 60


@dataclass(frozen=True)
class UISettings:
    app_title: str = APP_NAME
    theme_mode: str = "system"
    color_scheme_seed: str = "#4F46E5"
    dark_mode_default: bool = False
    window_min_width: int = 900
    window_min_height: int = 600
    theme: ThemeColors = ThemeColors()
    calendar: CalendarUISettings = CalendarUISettings()
    today: TodayUISettings = TodayUISettings()
    auto_refresh: AutoRefreshSettings = AutoRefreshSettings()


UI = UISettings()


@dataclass(frozen=True)
class GoogleSyncSettings:
    enabled: bool = True
    auto_pull_interval_sec: int = 60
    auto_push_on_edit: bool = True
    scopes: tuple[str, ...] = (
        "https://www.googleapis.com/auth/calendar",
        "https://www.googleapis.com/auth/tasks",
    )
    sync_token_path: Path = SYNC_TOKEN_PATH
    delete_on_google_cancel: bool = False
    tasks_tasklist_name: str = "Planner Inbox"
    tasks_pull_interval_sec: int = 90
    tasks_push_interval_sec: int = 90
    tasks_meta_filename: str = "planner-meta.json"


GOOGLE_SYNC = GoogleSyncSettings()


@dataclass(frozen=True)
class BackupSettings:
    enabled: bool = True
    directory: Path = BACKUP_DIR
    keep_days: int = 7


BACKUP = BackupSettings()


__all__ = [
    "APP_NAME",
    "DATA_DIR",
    "STORAGE_DIR",
    "SECRETS_DIR",
    "BACKUP_DIR",
    "DB_PATH",
    "TOKEN_PATH",
    "CLIENT_SECRET_PATH",
    "SYNC_TOKEN_PATH",
    "UI",
    "GOOGLE_SYNC",
    "BACKUP",
    "get_default_data_dir",
]


```

### datetime_utils.py
```python
from utils.datetime_utils import *  # noqa: F401,F403

```

### helpers/__init__.py
```python
"""Utility helpers for Planner UI and services."""

```

### helpers/datetime_utils.py
```python
"""Shared utilities for parsing and normalizing date/time input."""
from __future__ import annotations

from dataclasses import dataclass
from datetime import date, datetime, time, timedelta
from typing import Optional


@dataclass(frozen=True)
class ParsedDateTime:
    """Container for parsed date/time information."""

    date: Optional[date]
    time: Optional[time]

    @property
    def has_both(self) -> bool:
        return self.date is not None and self.time is not None

    def combine(self) -> Optional[datetime]:
        if self.date is None and self.time is None:
            return None
        base = self.date or date.today()
        t = self.time or time(0, 0)
        return datetime.combine(base, t)


def snap_minutes(value: int, *, step: int, direction: str = "forward") -> int:
    """Snap ``value`` to ``step`` minutes using the provided ``direction``.

    ``direction`` can be ``forward`` (ceil), ``nearest`` or ``backward``.
    """

    if step <= 0:
        return value
    if direction == "nearest":
        return int(round(value / step) * step)
    remainder = value % step
    if remainder == 0:
        return value
    if direction == "backward":
        return value - remainder
    # forward (ceil)
    return value + (step - remainder)


def _parse_int(value: str) -> Optional[int]:
    try:
        return int(value)
    except (TypeError, ValueError):
        return None


def parse_date_input(value: str | None) -> Optional[date]:
    """Parse ``DD.MM.YYYY`` or ISO ``YYYY-MM-DD`` string into a ``date`` object."""

    if not value:
        return None
    text = value.strip()
    if not text:
        return None

    for fmt in ("%d.%m.%Y", "%Y-%m-%d"):
        try:
            return datetime.strptime(text, fmt).date()
        except ValueError:
            continue
    # Accept dd.mm without year -> assume current year
    if len(text) == 5 and text[2] == ".":
        try:
            parsed = datetime.strptime(text, "%d.%m").date()
            return parsed.replace(year=date.today().year)
        except ValueError:
            return None
    return None


def parse_time_input(value: str | None, *, allow_relative: bool = True) -> Optional[time]:
    """Parse ``HH:MM`` strings or relative shortcuts like ``сейчас+30``."""

    if not value:
        return None
    text = value.strip().lower()
    if not text:
        return None

    if allow_relative and (text.startswith("сейчас") or text.startswith("now")):
        parts = text.split("+", 1)
        minutes = _parse_int(parts[1]) if len(parts) == 2 else 0
        minutes = max(minutes or 0, 0)
        base = datetime.now().replace(second=0, microsecond=0) + timedelta(minutes=minutes)
        return time(base.hour, base.minute)

    for fmt in ("%H:%M", "%H.%M"):
        try:
            dt = datetime.strptime(text, fmt)
            return time(dt.hour, dt.minute)
        except ValueError:
            continue

    # short hhmm (e.g. 930 -> 09:30)
    if len(text) in {3, 4} and text.isdigit():
        hours = _parse_int(text[:-2])
        minutes = _parse_int(text[-2:])
        if hours is not None and minutes is not None and 0 <= hours <= 23 and 0 <= minutes <= 59:
            return time(hours, minutes)

    return None


def smart_defaults(
    *,
    raw_date: str | None,
    raw_time: str | None,
    raw_duration: str | None,
    default_duration: int,
    step_minutes: int,
) -> tuple[date, time, int]:
    """Return sane defaults for date, time and duration based on user input."""

    parsed_date = parse_date_input(raw_date) or date.today()

    parsed_time = parse_time_input(raw_time)
    if parsed_time is None:
        now = datetime.now().replace(second=0, microsecond=0)
        minutes = now.hour * 60 + now.minute
        minutes = snap_minutes(minutes + 1, step=step_minutes, direction="forward")
        hours = (minutes // 60) % 24
        minutes = minutes % 60
        parsed_time = time(hours, minutes)

    duration_value = (raw_duration or "").strip()
    if not duration_value:
        duration = default_duration
    else:
        try:
            parsed_duration = int(duration_value)
            duration = max(parsed_duration, default_duration)
        except ValueError:
            duration = default_duration

    return parsed_date, parsed_time, duration


def build_start_datetime(
    raw_date: str | None,
    raw_time: str | None,
    *,
    step_minutes: int,
    default_to_future: bool = True,
) -> Optional[datetime]:
    """Combine date & time inputs into a datetime, snapping to the future if requested."""

    parsed_date = parse_date_input(raw_date)
    parsed_time = parse_time_input(raw_time)

    if parsed_date and parsed_time:
        result = datetime.combine(parsed_date, parsed_time)
    elif parsed_date and not parsed_time:
        result = datetime.combine(parsed_date, time(0, 0))
    elif parsed_time and not parsed_date:
        today = date.today()
        result = datetime.combine(today, parsed_time)
    else:
        return None

    if parsed_time and step_minutes > 0:
        total_minutes = result.hour * 60 + result.minute
        snapped = snap_minutes(total_minutes, step=step_minutes, direction="nearest")
        result = result.replace(hour=(snapped // 60) % 24, minute=snapped % 60)

    if default_to_future and parsed_time and not parsed_date:
        now = datetime.now()
        if result <= now:
            delta = (now - result).total_seconds() // 60
            add_minutes = snap_minutes(int(delta) + 1, step=step_minutes, direction="forward")
            result = result + timedelta(minutes=add_minutes)
    return result


__all__ = [
    "ParsedDateTime",
    "build_start_datetime",
    "parse_date_input",
    "parse_time_input",
    "smart_defaults",
    "snap_minutes",
]

```

### helpers/snooze.py
```python
"""Reusable snooze presets for tasks."""
from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime, timedelta, time
from typing import Protocol

from core.settings import UI
from helpers.datetime_utils import snap_minutes


@dataclass(frozen=True)
class SnoozeResult:
    start: datetime
    duration_minutes: int


class SupportsTask(Protocol):
    start: datetime | None
    duration_minutes: int | None


def _resolve_duration(task: SupportsTask) -> int:
    duration = getattr(task, "duration_minutes", None) or UI.today.default_duration_minutes
    duration = max(duration, UI.calendar.min_block_duration_minutes)
    return snap_minutes(duration, step=UI.calendar.grid_step_minutes, direction="nearest")


def minutes(task: SupportsTask, minutes_delta: int) -> SnoozeResult:
    base = getattr(task, "start", None) or datetime.now()
    start = base + timedelta(minutes=minutes_delta)
    return SnoozeResult(start=start, duration_minutes=_resolve_duration(task))


def tonight(task: SupportsTask) -> SnoozeResult:
    cfg = UI.snooze
    now = datetime.now()
    target_time = time(cfg.evening_hour, cfg.evening_minute)
    candidate = now.replace(hour=target_time.hour, minute=target_time.minute, second=0, microsecond=0)
    if candidate <= now:
        candidate = candidate + timedelta(days=1)
    return SnoozeResult(start=candidate, duration_minutes=_resolve_duration(task))


def tomorrow_morning(task: SupportsTask) -> SnoozeResult:
    cfg = UI.snooze
    now = datetime.now()
    base = now + timedelta(days=1)
    target = base.replace(hour=cfg.tomorrow_hour, minute=cfg.tomorrow_minute, second=0, microsecond=0)
    return SnoozeResult(start=target, duration_minutes=_resolve_duration(task))


__all__ = ["minutes", "tonight", "tomorrow_morning", "SnoozeResult"]

```

### main.py
```python
# planner/main.py
import os, sys
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
import flet as ft

from core.settings import APP_NAME, UI
from storage.db import init_db
from ui.app_shell import AppShell



def main(page: ft.Page):
    page.title = UI.app_title
    page.theme_mode = UI.theme_mode
    page.theme = ft.Theme(color_scheme_seed=UI.color_scheme_seed)
    page.appbar = ft.AppBar(title=ft.Text(APP_NAME), center_title=False)
    page.padding = 0
    page.window_min_width = UI.window_min_width
    page.window_min_height = UI.window_min_height

    init_db()
    shell = AppShell(page)
    shell.mount()

ft.app(target=main)

```

### migrate_descriptions.py
```python
"""Console utility to migrate embedded metadata from task descriptions."""
from __future__ import annotations

import argparse
import logging
from pathlib import Path
from typing import Optional

from core.settings import DATA_DIR
from services.appdata import AppDataClient
from services.google_auth import GoogleAuth
from services.tasks_bridge import GoogleTasksBridge


LOG_PATH = DATA_DIR / "migration.log"


def migrate_descriptions(
    *,
    auth: Optional[GoogleAuth] = None,
    bridge: Optional[GoogleTasksBridge] = None,
    appdata: Optional[AppDataClient] = None,
) -> int:
    """Run a migration that extracts metadata JSON from task descriptions."""

    auth = auth or GoogleAuth()
    if hasattr(auth, "ensure_credentials"):
        auth.ensure_credentials()
    appdata = appdata or AppDataClient(auth)
    bridge = bridge or GoogleTasksBridge(auth)

    appdata.ensure_files()
    index, etag = appdata.read_index()
    if not index:
        index = {"version": 1, "tasklist_id": None, "tasks": {}}

    tasklist_id = bridge.ensure_tasklist()
    index["tasklist_id"] = tasklist_id
    tasks_meta = index.setdefault("tasks", {})

    migrated = 0
    for item in bridge.fetch_all(tasklist_id):
        gtask_id = item.get("id")
        detected = item.get("detected_meta") or {}
        if not gtask_id or not detected:
            continue

        entry = dict(tasks_meta.get(gtask_id) or {})
        before = entry.copy()
        for key in ("task_id", "priority", "status", "updated_at", "device_id"):
            value = detected.get(key)
            if value in (None, ""):
                continue
            entry[key] = value
        if entry != before:
            tasks_meta[gtask_id] = entry
            migrated += 1
            logging.info("Migrated metadata for %s", gtask_id)

    if migrated:
        appdata.write_index(index, if_match=etag)

    logging.info("Migration completed; %d tasks updated", migrated)
    return migrated


def _setup_logging(log_path: Path) -> None:
    log_path.parent.mkdir(parents=True, exist_ok=True)
    logging.basicConfig(
        filename=str(log_path),
        filemode="a",
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
    )


def main() -> None:
    parser = argparse.ArgumentParser(description=__doc__ or "")
    parser.add_argument(
        "--log",
        type=Path,
        default=LOG_PATH,
        help="Path to a log file (default: %(default)s)",
    )
    args = parser.parse_args()

    _setup_logging(args.log)
    try:
        count = migrate_descriptions()
        print(f"Migration complete: {count} tasks processed.")
    except Exception as exc:  # pragma: no cover - defensive
        logging.exception("Migration failed: %s", exc)
        raise


if __name__ == "__main__":  # pragma: no cover - CLI entry point
    main()


```

### models/__init__.py
```python
from .task import Task

__all__ = ["Task"]

```

### models/pending_op.py
```python
"""SQLModel table for pending synchronization operations."""

from __future__ import annotations

from datetime import datetime
from typing import Optional

from sqlmodel import Field, SQLModel

from utils.datetime_utils import utc_now


class PendingOp(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True)
    op: str = Field(index=True)
    task_id: int = Field(index=True)
    payload: str
    attempts: int = Field(default=0)
    last_error: Optional[str] = None
    created_at: datetime = Field(default_factory=utc_now)
    next_try_at: datetime = Field(default_factory=utc_now, index=True)


__all__ = ["PendingOp"]

```

### models/sync_map_undated.py
```python
"""Mapping table for Google Tasks synchronization of undated items."""
from __future__ import annotations

from datetime import datetime, timezone
from typing import Optional

from sqlmodel import Field, SQLModel


class SyncMapUndated(SQLModel, table=True):
    """Keep mapping between local tasks and Google Tasks entities."""

    task_id: str = Field(primary_key=True, description="Local task identifier")
    gtask_id: Optional[str] = Field(
        default=None,
        index=True,
        description="Google Tasks task identifier",
    )
    tasklist_id: str = Field(description="Google Tasks tasklist identifier")
    updated_at_utc: datetime = Field(
        default_factory=lambda: datetime.now(timezone.utc),
        description="Last synchronization timestamp in UTC",
    )
    dirty_flag: int = Field(
        default=0,
        description="Dirty flag: 1 when local copy requires push",
    )


__all__ = ["SyncMapUndated"]

```

### models/tag.py
```python
# planner/models/tag.py
from __future__ import annotations

from datetime import datetime
from typing import Optional

from sqlmodel import Field, SQLModel

from utils.datetime_utils import utc_now


class Tag(SQLModel, table=True):
    __tablename__ = "tags"
    id: Optional[int] = Field(default=None, primary_key=True)
    name: str = Field(unique=True, index=True)
    color_hex: str
    created_at: datetime = Field(default_factory=utc_now)
    updated_at: datetime = Field(default_factory=utc_now)


class TaskTag(SQLModel, table=True):
    __tablename__ = "task_tags"

    task_id: int = Field(primary_key=True, foreign_key="task.id")
    tag_id: int = Field(primary_key=True, foreign_key="tags.id")


__all__ = ["Tag", "TaskTag"]

```

### models/task.py
```python
# planner/models/task.py
from typing import Optional
from datetime import datetime
import uuid

from utils.datetime_utils import utc_now
from sqlmodel import SQLModel, Field

class Task(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True)
    uid: str = Field(default_factory=lambda: str(uuid.uuid4()), index=True, unique=True)
    title: str
    notes: Optional[str] = None
    start: Optional[datetime] = None
    due: Optional[datetime] = None
    duration_minutes: Optional[int] = None
    priority: int = 0
    status: str = "todo"          # todo / doing / done
    gcal_event_id: Optional[str] = None
    gcal_etag: Optional[str] = None
    gcal_updated: Optional[datetime] = None
    gtasks_id: Optional[str] = None
    gtasks_updated: Optional[datetime] = None
    created_at: datetime = Field(default_factory=utc_now)
    updated_at: datetime = Field(default_factory=utc_now)

```

### models/task_sync.py
```python
"""SQLModel tables for Google Tasks synchronization metadata."""

from __future__ import annotations

from datetime import datetime
from typing import Optional

from sqlmodel import Field, SQLModel


class TaskSyncMapping(SQLModel, table=True):
    """Mapping between local Planner tasks and Google Tasks identifiers."""

    local_id: int = Field(primary_key=True, foreign_key="task.id")
    google_task_id: Optional[str] = Field(default=None, index=True)
    tasklist_id: Optional[str] = None
    etag: Optional[str] = None
    updated_at_utc: datetime = Field(default_factory=datetime.utcnow)


class TaskSyncMeta(SQLModel, table=True):
    """Holds sync anchors and auxiliary metadata for Google Tasks sync."""

    id: int = Field(default=1, primary_key=True)
    tasklist_id: Optional[str] = None
    updated_min: Optional[str] = None
    last_pull_at: Optional[datetime] = None
    last_push_at: Optional[datetime] = None
    drive_snapshot_at: Optional[datetime] = None
    drive_file_id: Optional[str] = None


__all__ = ["TaskSyncMapping", "TaskSyncMeta"]

```

### push_to_github.py
```python
# -*- coding: utf-8 -*-
"""
push_to_github.py — инициализация git-репозитория и пуш на GitHub.
Теперь поддерживает перезапись удалённой истории.

Примеры:
  # Перезаписать ветку main удалённо (без удаления чужих веток/тэгов):
  python push_to_github.py --remote https://github.com/<user>/<repo>.git --name "Your Name" --email you@example.com --overwrite

  # Полная синхронизация (зеркалирование всех веток/тэгов, удалит лишнее на GitHub):
  python push_to_github.py --remote https://github.com/<user>/<repo>.git --mirror

  # Явный путь к git.exe:
  python push_to_github.py --remote ... --git "C:\\Program Files\\Git\\cmd\\git.exe"
"""

import argparse
import os
import shutil
import subprocess
import sys
from pathlib import Path
from textwrap import dedent

DEFAULT_GITIGNORE = dedent("""\
    # Byte-compiled / cache
    __pycache__/
    *.py[cod]
    *$py.class

    # Environments
    .env
    .venv/
    venv/

    # Editors/IDE
    .idea/
    .vscode/
    *.iml

    # Build artifacts
    build/
    dist/
    *.egg-info/

    # Logs
    *.log

    # OS junk
    .DS_Store
    Thumbs.db

    # Project data (ignore by default)
    data/*.db
    *.sqlite
    *.sqlite3
    *.tsv
    *.csv
    *.tmp
""")

DEFAULT_GITATTRIBUTES_LFS = dedent("""\
    *.db filter=lfs diff=lfs merge=lfs -text
    *.sqlite filter=lfs diff=lfs merge=lfs -text
    *.sqlite3 filter=lfs diff=lfs merge=lfs -text
    *.tsv filter=lfs diff=lfs merge=lfs -text
    *.csv filter=lfs diff=lfs merge=lfs -text
    *.bin filter=lfs diff=lfs merge=lfs -text
""")

def find_git(explicit: str | None) -> str:
    for candidate in [explicit, os.environ.get("GIT_EXE"), os.environ.get("GIT")]:
        if candidate and Path(candidate).exists():
            return str(Path(candidate))
    which = shutil.which("git")
    if which:
        return which
    common_paths = [
        r"C:\Users\V.Pyatakov\AppData\Local\Programs\Git\cmd\git.exe",
        r"C:\Program Files\Git\cmd\git.exe",
        r"C:\Program Files (x86)\Git\bin\git.exe",
        r"C:\Program Files (x86)\Git\cmd\git.exe",
    ]
    for p in common_paths:
        if Path(p).exists():
            return p
    raise FileNotFoundError("git не найден. Установите Git for Windows или укажите путь параметром --git.")

def run(cmd, cwd=None, check=True):
    result = subprocess.run(cmd, cwd=cwd, text=True, capture_output=True, shell=False)
    if check and result.returncode != 0:
        raise RuntimeError(f"Command failed: {' '.join(cmd)}\nSTDOUT:\n{result.stdout}\nSTDERR:\n{result.stderr}")
    return result

def run_git(git_exe: str, args: list[str], cwd: Path, check=True):
    return run([git_exe] + args, cwd=cwd, check=check)

def ensure_in_repo(git: str, project_dir: Path, branch: str):
    git_dir = project_dir / ".git"
    if git_dir.exists():
        run_git(git, ["rev-parse", "--is-inside-work-tree"], project_dir)
    else:
        run_git(git, ["init"], project_dir)
        run_git(git, ["branch", "-M", branch], project_dir)

def git_config(git: str, project_dir: Path, name: str | None, email: str | None):
    if name:
        run_git(git, ["config", "user.name", name], project_dir)
    if email:
        run_git(git, ["config", "user.email", email], project_dir)
    run_git(git, ["config", "core.autocrlf", "true"], project_dir)
    run_git(git, ["config", "core.longpaths", "true"], project_dir)

def ensure_file_contains(path: Path, content: str):
    if path.exists():
        existing = path.read_text(encoding="utf-8", errors="ignore")
        to_add = []
        have = set(line.rstrip() for line in existing.splitlines())
        for line in content.splitlines():
            if line.rstrip() not in have:
                to_add.append(line)
        if to_add:
            with path.open("a", encoding="utf-8") as f:
                f.write(("\n" if not existing.endswith("\n") else "") + "\n".join(to_add) + "\n")
    else:
        path.write_text(content, encoding="utf-8")

def setup_ignores(git: str, project_dir: Path, apply_lfs: bool):
    gi = project_dir / ".gitignore"
    ensure_file_contains(gi, DEFAULT_GITIGNORE)
    if apply_lfs:
        try:
            run_git(git, ["lfs", "install"], project_dir, check=False)
        except Exception:
            pass
        ga = project_dir / ".gitattributes"
        ensure_file_contains(ga, DEFAULT_GITATTRIBUTES_LFS)

def ensure_readme(project_dir: Path):
    readme = project_dir / "README.md"
    if not readme.exists():
        readme.write_text("# Project\n\nОписание проекта.\n", encoding="utf-8")

def initial_commit_if_needed(git: str, project_dir: Path, message: str):
    run_git(git, ["add", "."], project_dir)
    status = run_git(git, ["status", "--porcelain"], project_dir)
    if status.stdout.strip():
        run_git(git, ["commit", "-m", message], project_dir)
    else:
        print("Нет изменений для коммита — пропускаю commit.")

def set_remote(git: str, project_dir: Path, remote_url: str, remote_name: str = "origin"):
    remotes = run_git(git, ["remote"], project_dir)
    if remote_name in remotes.stdout.split():
        run_git(git, ["remote", "set-url", remote_name, remote_url], project_dir)
    else:
        run_git(git, ["remote", "add", remote_name, remote_url], project_dir)

def push(git: str, project_dir: Path, branch: str, remote_name: str = "origin",
         overwrite: bool = False, mirror: bool = False):
    # Если нужен полный зеркальный пуш (ОСТОРОЖНО: удалит лишние ветки/теги на GitHub)
    if mirror:
        print("[WARN] Выполняю зеркалирование: git push --mirror (все ветки/теги, с удалением лишних на удалённом).")
        run_git(git, ["push", "--mirror", remote_name], project_dir, check=True)
        return

    # Обычный пуш (или с перезаписью одной ветки)
    args = ["push", "-u", remote_name, branch]
    if overwrite:
        # Перезаписываем историю ветки на удалённом
        args.append("--force-with-lease")
    try:
        run_git(git, args, project_dir, check=True)
    except RuntimeError as e:
        # Если не указан overwrite — пробуем мягкий pull --rebase и повторный пуш
        if not overwrite:
            print("Первый push не удался. Пробую pull --rebase и повторный push ...", file=sys.stderr)
            run_git(git, ["pull", "--rebase", remote_name, branch], project_dir, check=False)
            run_git(git, ["push", "-u", remote_name, branch], project_dir, check=True)
        else:
            # В жёстком режиме даём пользователю подсказку про защиту ветки
            raise RuntimeError(
                f"Перезаписать ветку не получилось. Возможно, ветка защищена на GitHub.\n{e}"
            )

def main():
    parser = argparse.ArgumentParser(description="Подготовка и публикация проекта на GitHub (с опцией перезаписи).")
    parser.add_argument("--project-dir", default=".", help="Корень проекта (по умолчанию текущая папка).")
    parser.add_argument("--remote", required=True, help="URL удалённого репозитория, напр. https://github.com/user/repo.git")
    parser.add_argument("--branch", default="main", help="Имя основной ветки (по умолчанию main).")
    parser.add_argument("--name", default=None, help="Git user.name (необязательно).")
    parser.add_argument("--email", default=None, help="Git user.email (необязательно).")
    parser.add_argument("--message", default="Initial commit", help="Сообщение первого коммита.")
    parser.add_argument("--lfs", action="store_true", help="Включить Git LFS трекинг больших файлов.")
    parser.add_argument("--git", default=None, help="Полный путь к git.exe (если не в PATH).")
    parser.add_argument("--overwrite", action="store_true", help="Перезаписать удалённую ветку (--force-with-lease).")
    parser.add_argument("--mirror", action="store_true", help="Зеркалировать весь локальный репозиторий на удалённый (--mirror). ОПАСНО!")
    args = parser.parse_args()

    if args.overwrite and args.mirror:
        print("Нельзя одновременно использовать --overwrite и --mirror.", file=sys.stderr)
        sys.exit(2)

    project_dir = Path(args.project_dir).resolve()
    if not project_dir.exists():
        print(f"Папка не найдена: {project_dir}", file=sys.stderr)
        sys.exit(1)

    git_exe = find_git(args.git)
    print(f"Использую git: {git_exe}")

    ensure_in_repo(git_exe, project_dir, args.branch)
    git_config(git_exe, project_dir, args.name, args.email)
    setup_ignores(git_exe, project_dir, apply_lfs=args.lfs)
    ensure_readme(project_dir)
    initial_commit_if_needed(git_exe, project_dir, args.message)
    set_remote(git_exe, project_dir, args.remote)
    push(git_exe, project_dir, args.branch, overwrite=args.overwrite, mirror=args.mirror)

    print("\nГотово! Проект отправлен на GitHub.\nЕсли спросит логин/пароль — используйте GitHub-логин и Personal Access Token.")

if __name__ == "__main__":
    main()

```

### scrpt2txt.py
```python
# -*- coding: utf-8 -*-
"""
project_inventory.py
Инвентаризация проекта:
1) Полное дерево каталогов/файлов от корня (относительные пути).
2) Сборка указанных "скриптовых" файлов в единый Markdown с кодовыми блоками.

Пример:
  python project_inventory.py --root "D:/Work/BigProj" --out "Инвентарь.md" --ext .py .lua .sql -v
"""
from __future__ import annotations
import os
import sys
import argparse
import traceback
from pathlib import Path
from typing import Iterable, List, Tuple, Sequence
import datetime as _dt

HERE = Path(__file__).resolve().parent

# Автовыбор корня как в твоём примере (при желании поправь под себя)
if (HERE / "crm" / "scripts").is_dir():
    DEFAULT_ROOT = HERE / "crm" / "scripts"
else:
    DEFAULT_ROOT = HERE

DEFAULT_OUT = HERE / "Инвентарь_проекта.md"

IGNORE_DIRS = {
    "__pycache__", ".git", ".idea", ".vscode",
    "venv", ".venv", "env", ".mypy_cache", ".pytest_cache", ".ruff_cache",
    "dist", "build", "node_modules",
}

IGNORE_FILES = set()  # можно добавить маски или имена, если нужно

# ---------- утилиты ----------
def eprint(*a, **kw):
    print(*a, file=sys.stderr, flush=True, **kw)

def vprint(verbose: bool, *a, **kw):
    if verbose:
        print(*a, flush=True, **kw)

def _lang_for(path: str) -> str:
    p = path.lower()
    if p.endswith(".py"): return "python"
    if p.endswith(".lua"): return "lua"
    if p.endswith(".sql"): return "sql"
    if p.endswith(".js"): return "javascript"
    if p.endswith(".ts"): return "typescript"
    if p.endswith(".json"): return "json"
    if p.endswith(".sh"): return "bash"
    if p.endswith(".ps1"): return "powershell"
    if p.endswith(".bat") or p.endswith(".cmd"): return ""
    if p.endswith(".yml") or p.endswith(".yaml"): return "yaml"
    if p.endswith(".ini") or p.endswith(".cfg"): return ""
    return ""

def _safe_rel(path: Path, root: Path) -> str:
    rel = path.relative_to(root)
    return str(rel).replace("\\", "/")

# ---------- сбор дерева ----------
def build_tree_lines(root: Path,
                     ignore_dirs: Iterable[str],
                     ignore_files: Iterable[str],
                     verbose: bool = False) -> List[str]:
    """
    Возвращает "красивое" дерево (список строк) со всеми файлами/папками.
    """
    root = root.resolve()
    ignore_dirs = set(ignore_dirs)
    ignore_files = set(ignore_files)

    if not root.exists():
        raise FileNotFoundError(f"Папка не найдена: {root}")
    if not root.is_dir():
        raise NotADirectoryError(f"Это не папка: {root}")

    vprint(verbose, f"[tree] старт: {root}")
    lines: List[str] = [f"{root.name}/"]

    # Для детерминированности сортируем
    def dir_entries(p: Path) -> Tuple[List[Path], List[Path]]:
        dirs, files = [], []
        for child in p.iterdir():
            name = child.name
            if child.is_dir():
                if name in ignore_dirs:
                    vprint(verbose, f"  └─ skip dir: {child}")
                    continue
                dirs.append(child)
            else:
                if name in ignore_files:
                    vprint(verbose, f"  └─ skip file: {child}")
                    continue
                files.append(child)
        return sorted(dirs, key=lambda x: x.name.lower()), sorted(files, key=lambda x: x.name.lower())

    def walk(node: Path, prefix: str):
        dirs, files = dir_entries(node)
        total = len(dirs) + len(files)
        for i, d in enumerate(dirs):
            is_last = (i == len(dirs) - 1) and (len(files) == 0)
            branch = "└── " if is_last else "├── "
            lines.append(f"{prefix}{branch}{d.name}/")
            new_prefix = f"{prefix}{'    ' if is_last else '│   '}"
            walk(d, new_prefix)

        for j, f in enumerate(files):
            is_last_file = (j == len(files) - 1)
            branch = "└── " if is_last_file else "├── "
            try:
                size = f.stat().st_size
                size_note = f" ({size} B)"
            except OSError:
                size_note = ""
            lines.append(f"{prefix}{branch}{f.name}{size_note}")

    walk(root, "")
    vprint(verbose, f"[tree] готово: {len(lines)} строк")
    return lines

# ---------- сбор скриптов ----------
def collect_scripts(root: Path,
                    exts: Iterable[str],
                    ignore_dirs: Iterable[str],
                    max_size_mb: float | None = None,
                    verbose: bool = False) -> List[Tuple[str, str]]:
    """
    Рекурсивно собирает файлы расширений exts из root.
    Возвращает список (relative_path, code).
    """
    root = root.resolve()
    exts = tuple(e.lower() for e in exts)
    ignore = set(ignore_dirs)

    if not root.exists():
        raise FileNotFoundError(f"Папка не найдена: {root}")
    if not root.is_dir():
        raise NotADirectoryError(f"Это не папка: {root}")

    scripts: List[Tuple[str, str]] = []
    vprint(verbose, f"[collect] старт: {root}")

    for dirpath, dirnames, filenames in os.walk(root):
        before = list(dirnames)
        dirnames[:] = [d for d in dirnames if d not in ignore]
        dropped = set(before) - set(dirnames)
        if dropped and verbose:
            vprint(verbose, f"  └─ skip dirs: {', '.join(sorted(dropped))}")

        for fname in filenames:
            if not any(fname.lower().endswith(ext) for ext in exts):
                continue
            fpath = Path(dirpath) / fname

            try:
                if max_size_mb is not None and fpath.stat().st_size > max_size_mb * 1024 * 1024:
                    vprint(verbose, f"  └─ skip big file: {fpath}")
                    continue
            except OSError as ex:
                eprint(f"[warn] не удалось получить размер: {fpath} ({ex})")
                continue

            try:
                code = fpath.read_text(encoding="utf-8", errors="replace")
            except OSError as ex:
                eprint(f"[warn] не удалось прочитать: {fpath} ({ex})")
                continue

            rel_str = _safe_rel(fpath, root)
            scripts.append((rel_str, code))
            vprint(verbose, f"  + {rel_str}")

    scripts.sort(key=lambda x: x[0].lower())
    vprint(verbose, f"[collect] готово: файлов {len(scripts)}")
    return scripts

# ---------- запись отчёта ----------
def write_report(tree_lines: Sequence[str],
                 scripts: Sequence[Tuple[str, str]],
                 output_file: Path,
                 verbose: bool = False) -> None:
    output_file = output_file.resolve()
    output_file.parent.mkdir(parents=True, exist_ok=True)
    vprint(verbose, f"[write] -> {output_file}")

    ts = _dt.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open(output_file, "w", encoding="utf-8", newline="\n") as out:
        # Шапка
        out.write(f"# Инвентарь проекта\n")
        out.write(f"_Сгенерировано: {ts}_\n\n")

        # Раздел 1: Полная структура
        out.write("## 1. Полная структура (относительно корня)\n\n")
        out.write("```\n")
        for line in tree_lines:
            out.write(line)
            out.write("\n")
        out.write("```\n\n")

        # Раздел 2: Содержимое скриптов
        out.write(f"## 2. Скрипты (всего: {len(scripts)})\n\n")
        for relpath, code in scripts:
            lang = _lang_for(relpath)
            out.write(f"### {relpath}\n")
            out.write(f"```{lang}\n")
            out.write(code)
            out.write("\n```\n\n")

# ---------- CLI ----------
def main(argv: list[str] | None = None) -> int:
    ap = argparse.ArgumentParser(description="Инвентаризация проекта: дерево и сборка скриптов в Markdown.")
    ap.add_argument("--root", type=str, default=str(DEFAULT_ROOT),
                    help=f"Корневая папка (по умолчанию: {DEFAULT_ROOT})")
    ap.add_argument("--out", type=str, default=str(DEFAULT_OUT),
                    help=f"Итоговый Markdown-файл (по умолчанию: {DEFAULT_OUT})")
    ap.add_argument("--ext", nargs="+", default=[".py"],
                    help="Расширения скриптов (напр.: --ext .py .lua .sql .js .ts)")
    ap.add_argument("--max-size-mb", type=float, default=None,
                    help="Максимальный размер файла (МБ) для включения в сборку кода")
    ap.add_argument("-v", "--verbose", action="store_true", help="Подробный вывод")
    args = ap.parse_args(argv)

    root = Path(args.root)
    out = Path(args.out)

    print(f"[run] root={root}")
    print(f"[run] out ={out}")
    print(f"[run] ext ={', '.join(args.ext)}")
    if args.max_size_mb is not None:
        print(f"[run] max_size_mb={args.max_size_mb}")

    tree = build_tree_lines(root, IGNORE_DIRS, IGNORE_FILES, verbose=args.verbose)
    scripts = collect_scripts(root, exts=args.ext, ignore_dirs=IGNORE_DIRS,
                              max_size_mb=args.max_size_mb, verbose=args.verbose)
    write_report(tree, scripts, out, verbose=args.verbose)
    print(f"Строк в дереве: {len(tree)}")
    print(f"Скриптов собрано: {len(scripts)}")
    print(f"Готово: {out}")
    return 0

if __name__ == "__main__":
    try:
        sys.exit(main())
    except SystemExit:
        raise
    except Exception:
        # Всегда пишем трейсбек в лог, чтобы не «падать молча»
        log_path = Path(__file__).with_name("project_inventory_error.log")
        tb = traceback.format_exc()
        try:
            log_path.write_text(tb, encoding="utf-8")
        except Exception:
            pass
        eprint("[fatal] скрипт завершился с ошибкой. См. лог:", log_path)
        eprint(tb)
        if os.name == "nt" and not sys.stdin.isatty():
            os.system("pause")
        sys.exit(1)

```

### services/__init__.py
```python

```

### services/appdata.py
```python
"""Helpers for working with Google Drive ``appDataFolder`` storage."""
from __future__ import annotations

import io
import json
import time
from copy import deepcopy
from pathlib import Path
from typing import Any, Callable, Dict, Optional

from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from googleapiclient.http import MediaIoBaseDownload, MediaIoBaseUpload

from core.settings import GOOGLE_SYNC

try:  # pragma: no cover - optional dependency in tests
    from google.oauth2.credentials import Credentials
except Exception:  # pragma: no cover
    Credentials = None


_RETRYABLE_STATUS = {429, 500, 502, 503, 504}
_MAX_RETRIES = 5
_INITIAL_BACKOFF = 1.0
_MAX_BACKOFF = 32.0


class AppDataClient:
    """Wrapper around the Google Drive ``appDataFolder`` storage."""

    CONFIG_NAME = "planner_config.json"
    INDEX_NAME = "gtasks_index.json"

    def __init__(self, auth: Any):
        self.auth = auth
        self.service = None
        self._file_ids: Dict[str, str] = {}

    # ----- public helpers -----
    def ensure_files(self) -> Dict[str, str]:
        self._maybe_build_service(strict=True)
        existing = self._list_files()
        for name, default_payload in (
            (self.CONFIG_NAME, self._default_config()),
            (self.INDEX_NAME, self._default_index()),
        ):
            if name in existing:
                continue
            file_id = self._create_file(name, default_payload)
            existing[name] = file_id
        self._file_ids = existing
        return dict(existing)

    def read_config(self) -> tuple[Dict[str, Any], Optional[str]]:
        file_id = self._resolve_file_id(self.CONFIG_NAME)
        payload, etag = self._download_json(file_id)
        if not payload:
            payload = self._default_config()
        return payload, etag

    def write_config(
        self,
        data: Dict[str, Any],
        if_match: Optional[str] = None,
        *,
        on_conflict: Optional[Callable[[Dict[str, Any]], Dict[str, Any]]] = None,
    ) -> tuple[Dict[str, Any], str]:
        file_id = self._resolve_file_id(self.CONFIG_NAME)
        payload = deepcopy(data)
        etag = if_match
        attempt = 0
        last_error: Optional[Exception] = None
        while attempt < _MAX_RETRIES:
            try:
                new_etag = self._upload_json(file_id, payload, etag)
                return payload, new_etag
            except HttpError as exc:
                last_error = exc
                status = getattr(getattr(exc, "resp", None), "status", None)
                if status == 412 and on_conflict:
                    remote, etag = self.read_config()
                    payload = on_conflict(remote)
                    attempt += 1
                    continue
                raise
        if last_error:
            raise last_error
        raise RuntimeError("Failed to write config to appData")

    def read_index(self) -> tuple[Dict[str, Any], Optional[str]]:
        file_id = self._resolve_file_id(self.INDEX_NAME)
        payload, etag = self._download_json(file_id)
        if not payload:
            payload = self._default_index()
        payload.setdefault("version", 1)
        payload.setdefault("tasks", {})
        return payload, etag

    def write_index(
        self,
        data: Dict[str, Any],
        if_match: Optional[str] = None,
        *,
        on_conflict: Optional[Callable[[Dict[str, Any]], Dict[str, Any]]] = None,
    ) -> tuple[Dict[str, Any], str]:
        file_id = self._resolve_file_id(self.INDEX_NAME)
        payload = deepcopy(data)
        etag = if_match
        attempt = 0
        last_error: Optional[Exception] = None
        while attempt < _MAX_RETRIES:
            try:
                new_etag = self._upload_json(file_id, payload, etag)
                return payload, new_etag
            except HttpError as exc:
                last_error = exc
                status = getattr(getattr(exc, "resp", None), "status", None)
                if status == 412 and on_conflict:
                    remote, etag = self.read_index()
                    payload = on_conflict(remote)
                    attempt += 1
                    continue
                raise
        if last_error:
            raise last_error
        raise RuntimeError("Failed to write index to appData")

    # ----- internal helpers -----
    def _maybe_build_service(self, strict: bool = False) -> None:
        if self.service is not None:
            return
        creds = self._find_creds(DEFAULT_SCOPES())
        if creds and getattr(creds, "valid", False):
            self.service = build("drive", "v3", credentials=creds)
        elif strict:
            raise RuntimeError("AppDataClient: credentials are unavailable")

    def _find_creds(self, scopes: tuple[str, ...]):
        if hasattr(self.auth, "get_credentials"):
            try:
                creds = self.auth.get_credentials()
                if creds and getattr(creds, "valid", False):
                    return creds
            except Exception:  # pragma: no cover - defensive
                pass
        if hasattr(self.auth, "creds"):
            creds = getattr(self.auth, "creds")
            if creds and getattr(creds, "valid", False):
                return creds
        if hasattr(self.auth, "token_path") and Credentials:
            token_path = getattr(self.auth, "token_path")
            if token_path and Path(token_path).exists():
                try:
                    return Credentials.from_authorized_user_file(str(token_path), scopes)
                except Exception:  # pragma: no cover - defensive fallback
                    return None
        return None

    def _list_files(self) -> Dict[str, str]:
        results: Dict[str, str] = {}
        page_token: Optional[str] = None
        while True:
            response = self._call_with_backoff(
                self.service.files().list,
                spaces="appDataFolder",
                fields="nextPageToken, files(id, name)",
                pageToken=page_token,
            )
            for item in response.get("files", []):
                name = item.get("name")
                file_id = item.get("id")
                if name and file_id:
                    results[name] = file_id
            page_token = response.get("nextPageToken")
            if not page_token:
                break
        return results

    def _create_file(self, name: str, payload: Dict[str, Any]) -> str:
        body = {"name": name, "parents": ["appDataFolder"]}
        media = MediaIoBaseUpload(
            io.BytesIO(self._encode_json(payload)),
            mimetype="application/json",
            resumable=False,
        )
        response = self._call_with_backoff(
            self.service.files().create,
            body=body,
            media_body=media,
            fields="id",
        )
        return response.get("id")

    def _resolve_file_id(self, name: str) -> str:
        if name not in self._file_ids:
            self.ensure_files()
        file_id = self._file_ids.get(name)
        if not file_id:
            raise RuntimeError(f"AppData file {name!r} is unavailable")
        return file_id

    def _download_json(self, file_id: str) -> tuple[Dict[str, Any], Optional[str]]:
        request = self.service.files().get_media(fileId=file_id)
        buffer = io.BytesIO()
        downloader = MediaIoBaseDownload(buffer, request)
        done = False
        while not done:
            _, done = downloader.next_chunk()
        raw = buffer.getvalue()
        etag = None
        resp = getattr(request, "resp", None)
        if resp:
            etag = resp.get("etag") or resp.get("ETag")
        if not raw:
            return {}, etag
        try:
            decoded = raw.decode("utf-8")
            data = json.loads(decoded)
            if isinstance(data, dict):
                return data, etag
        except (UnicodeDecodeError, json.JSONDecodeError):
            pass
        return {}, etag

    def _upload_json(self, file_id: str, payload: Dict[str, Any], etag: Optional[str]) -> str:
        media = MediaIoBaseUpload(
            io.BytesIO(self._encode_json(payload)),
            mimetype="application/json",
            resumable=False,
        )
        request = self.service.files().update(fileId=file_id, media_body=media)
        if etag:
            request.headers["If-Match"] = etag
        response = self._call_with_backoff(lambda **_: request, execute_immediately=False)
        new_etag = None
        resp = getattr(request, "resp", None)
        if resp:
            new_etag = resp.get("etag") or resp.get("ETag")
        if not new_etag:
            metadata = self._call_with_backoff(
                self.service.files().get,
                fileId=file_id,
                fields="id, modifiedTime, version",
            )
            new_etag = metadata.get("version") or metadata.get("modifiedTime")
        return new_etag or ""

    def _call_with_backoff(
        self,
        method,
        *args,
        execute_immediately: bool = True,
        **kwargs,
    ) -> Dict[str, Any]:
        delay = _INITIAL_BACKOFF
        last_error: Optional[Exception] = None
        for attempt in range(_MAX_RETRIES):
            try:
                request = method(*args, **kwargs)
                if not execute_immediately:
                    request.execute()
                    return {}
                return request.execute()
            except HttpError as exc:
                last_error = exc
                status = getattr(getattr(exc, "resp", None), "status", None)
                if status not in _RETRYABLE_STATUS or attempt == _MAX_RETRIES - 1:
                    raise
            except Exception as exc:  # pragma: no cover - defensive fallback
                last_error = exc
                if attempt == _MAX_RETRIES - 1:
                    raise
            time.sleep(delay)
            delay = min(delay * 2, _MAX_BACKOFF)
        if last_error:
            raise last_error
        return {}

    @staticmethod
    def _encode_json(payload: Dict[str, Any]) -> bytes:
        text = json.dumps(payload, ensure_ascii=False, indent=2, sort_keys=True)
        return text.encode("utf-8")

    @staticmethod
    def _default_config() -> Dict[str, Any]:
        return {"version": 1, "tasklist_id": None, "last_full_sync": None}

    @staticmethod
    def _default_index() -> Dict[str, Any]:
        return {"version": 1, "tasklist_id": None, "tasks": {}}


def DEFAULT_SCOPES() -> tuple[str, ...]:
    return GOOGLE_SYNC.scopes


__all__ = ["AppDataClient"]


```

### services/appdata_store.py
```python
"""Google Drive appDataFolder helper for Planner synchronisation metadata."""

from __future__ import annotations

import json
from typing import Dict, Optional

from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from googleapiclient.http import MediaInMemoryUpload

CONFIG_FILENAME = "planner_config.json"
INDEX_FILENAME = "gtasks_index.json"
DEFAULT_CONFIG = {"version": 1, "tasklist_id": None, "last_full_sync": None}
DEFAULT_INDEX = {"version": 1, "tasks": {}}


class AppDataStore:
    def __init__(self, auth):
        self.auth = auth
        self.service = None
        self._files: Dict[str, Dict[str, Optional[str]]] = {}

    # ------------------------------------------------------------------
    # Public API
    def ensure_files(self) -> None:
        self._ensure_service()
        files = self._list_files()
        for name, default in (
            (CONFIG_FILENAME, DEFAULT_CONFIG),
            (INDEX_FILENAME, DEFAULT_INDEX),
        ):
            if name not in files:
                self._create_file(name, default)
                files = self._list_files()  # refresh to obtain metadata + etag
        self._files = files

    def read_config(self) -> Dict:
        return self._read_json(CONFIG_FILENAME, DEFAULT_CONFIG)

    def write_config(self, payload: Dict) -> None:
        self._write_json(CONFIG_FILENAME, payload, DEFAULT_CONFIG)

    def read_index(self) -> Dict:
        return self._read_json(INDEX_FILENAME, DEFAULT_INDEX)

    def write_index(self, payload: Dict) -> None:
        self._write_json(INDEX_FILENAME, payload, DEFAULT_INDEX)

    # ------------------------------------------------------------------
    # Service helpers
    def _ensure_service(self) -> None:
        if self.service is not None:
            return
        creds = None
        if hasattr(self.auth, "get_credentials") and callable(self.auth.get_credentials):
            creds = self.auth.get_credentials()
        elif hasattr(self.auth, "ensure_credentials") and callable(self.auth.ensure_credentials):
            if self.auth.ensure_credentials():  # type: ignore[misc]
                creds = getattr(self.auth, "creds", None) or getattr(
                    self.auth, "credentials", None
                )
        else:
            creds = getattr(self.auth, "creds", None) or getattr(
                self.auth, "credentials", None
            )
        if creds is None:
            raise RuntimeError("Google credentials are not available for appData access")
        self.service = build("drive", "v3", credentials=creds)

    def _list_files(self) -> Dict[str, Dict[str, Optional[str]]]:
        service = self.service
        if service is None:
            return {}
        files: Dict[str, Dict[str, Optional[str]]] = {}
        page_token: Optional[str] = None
        while True:
            response = (
                service.files()
                .list(
                    spaces="appDataFolder",
                    fields="nextPageToken, files(id, name, modifiedTime)",
                    pageToken=page_token,
                )
                .execute()
            )
            for entry in response.get("files", []):
                name = entry.get("name")
                if not name:
                    continue
                meta = self._fetch_metadata(entry.get("id"))
                if meta:
                    files[name] = meta
            page_token = response.get("nextPageToken")
            if not page_token:
                break
        return files

    def _fetch_metadata(self, file_id: Optional[str]) -> Optional[Dict[str, Optional[str]]]:
        if not file_id or self.service is None:
            return None
        request = self.service.files().get(
            fileId=file_id,
            fields="id, name, modifiedTime, size",
            supportsAllDrives=False,
        )
        metadata = request.execute()
        etag = None
        if hasattr(request, "resp") and request.resp is not None:
            etag = request.resp.get("ETag") or request.resp.get("etag")
        metadata["etag"] = etag
        return metadata

    def _create_file(self, name: str, payload: Dict) -> None:
        service = self.service
        if service is None:
            raise RuntimeError("Drive service is not initialised")
        media = MediaInMemoryUpload(
            json.dumps(payload, ensure_ascii=False).encode("utf-8"),
            mimetype="application/json",
            resumable=False,
        )
        service.files().create(
            body={"name": name, "parents": ["appDataFolder"]},
            media_body=media,
            fields="id, name",
        ).execute()

    # ------------------------------------------------------------------
    # JSON helpers
    def _ensure_cache(self) -> None:
        if not self._files:
            self.ensure_files()

    def _read_json(self, name: str, default: Dict) -> Dict:
        self._ensure_cache()
        info = self._files.get(name)
        if not info:
            return default.copy()
        file_id = info.get("id")
        if not file_id:
            return default.copy()
        request = self.service.files().get_media(fileId=file_id)
        try:
            content = request.execute()
        except HttpError as exc:
            status = getattr(exc, "resp", None) and getattr(exc.resp, "status", None)
            if status == 404:
                self._files.pop(name, None)
                return default.copy()
            raise
        if isinstance(content, bytes):
            text = content.decode("utf-8")
        else:
            text = str(content)
        if not text.strip():
            return default.copy()
        try:
            data = json.loads(text)
        except json.JSONDecodeError:
            return default.copy()
        metadata = self._fetch_metadata(file_id)
        if metadata:
            self._files[name] = metadata
        return data if isinstance(data, dict) else default.copy()

    def _write_json(self, name: str, payload: Dict, default: Dict) -> None:
        self._ensure_cache()
        info = self._files.get(name)
        if not info:
            self.ensure_files()
            info = self._files.get(name)
        if not info:
            raise RuntimeError(f"Failed to locate {name} in appDataFolder")
        file_id = info.get("id")
        if not file_id:
            raise RuntimeError(f"Invalid file id for {name}")

        data = json.dumps(payload or default, ensure_ascii=False).encode("utf-8")
        media = MediaInMemoryUpload(data, mimetype="application/json", resumable=False)
        etag = info.get("etag")

        for attempt in range(2):
            request = self.service.files().update(
                fileId=file_id,
                media_body=media,
                fields="id, modifiedTime",
            )
            if etag:
                request.headers["If-Match"] = etag
            try:
                request.execute()
                refreshed = self._fetch_metadata(file_id)
                if refreshed:
                    self._files[name] = refreshed
                return
            except HttpError as exc:
                status = getattr(exc, "resp", None) and getattr(exc.resp, "status", None)
                if status == 412 and attempt == 0:
                    refreshed = self._fetch_metadata(file_id)
                    if refreshed:
                        etag = refreshed.get("etag")
                        self._files[name] = refreshed
                        continue
                raise


__all__ = ["AppDataStore", "CONFIG_FILENAME", "INDEX_FILENAME"]

```

### services/google_auth.py
```python
# planner/services/google_auth.py
from pathlib import Path
from typing import Optional
import logging

from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request

from core.settings import CLIENT_SECRET_PATH, TOKEN_PATH


LOGGER = logging.getLogger(__name__)

SCOPES = [
    "https://www.googleapis.com/auth/calendar",
    "https://www.googleapis.com/auth/calendar.events",
    "https://www.googleapis.com/auth/tasks",
    "https://www.googleapis.com/auth/drive.appdata",
]


def _has_all_scopes(creds: Optional[Credentials]) -> bool:
    if not creds:
        return False
    current = set(creds.scopes or [])
    return all(scope in current for scope in SCOPES)


def _log_scopes(creds: Optional[Credentials]) -> None:
    if not logging.getLogger().handlers:
        logging.basicConfig(level=logging.INFO)
    scopes = sorted(creds.scopes) if creds and creds.scopes else []
    LOGGER.info("Active Google credentials scopes: %s", scopes)


class GoogleAuth:
    def __init__(
        self,
        secrets_path: str | Path = CLIENT_SECRET_PATH,
        token_path: str | Path = TOKEN_PATH,
    ):
        self.secrets_path = Path(secrets_path)
        self.token_path = Path(token_path)
        self.secrets_path.parent.mkdir(parents=True, exist_ok=True)
        self.token_path.parent.mkdir(parents=True, exist_ok=True)
        self.creds: Optional[Credentials] = None

    def ensure_credentials(self) -> bool:
        if self.creds and self.creds.valid and _has_all_scopes(self.creds):
            _log_scopes(self.creds)
            return True

        if self.token_path.exists():
            try:
                self.creds = Credentials.from_authorized_user_file(
                    str(self.token_path), SCOPES
                )
            except Exception:
                self.creds = None

        if self.creds and not _has_all_scopes(self.creds):
            try:
                self.token_path.unlink(missing_ok=True)
            except FileNotFoundError:
                pass
            self.creds = None

        if not self.creds or not self.creds.valid:
            if self.creds and self.creds.expired and self.creds.refresh_token:
                self.creds.refresh(Request())
            else:
                if not self.secrets_path.exists():
                    raise FileNotFoundError(
                        f"Не найден {self.secrets_path}. "
                        "Создайте OAuth-клиент (Desktop) в Google Cloud и скачайте JSON."
                    )
                flow = InstalledAppFlow.from_client_secrets_file(
                    str(self.secrets_path), SCOPES
                )
                # Откроет браузер и поднимет локальный сервер для callback
                self.creds = flow.run_local_server(
                    port=0, access_type="offline", prompt="consent"
                )

            # Сохраняем полученный токен
            self.token_path.parent.mkdir(parents=True, exist_ok=True)
            self.token_path.write_text(self.creds.to_json(), encoding="utf-8")

        if not _has_all_scopes(self.creds):
            try:
                self.token_path.unlink(missing_ok=True)
            except FileNotFoundError:
                pass
            self.creds = None
            return self.ensure_credentials()

        _log_scopes(self.creds)
        return True

    def get_credentials(self) -> Optional[Credentials]:
        if not self.creds or not self.creds.valid:
            try:
                if not self.ensure_credentials():
                    return None
            except Exception:
                return None
        return self.creds

```

### services/google_calendar.py
```python
from __future__ import annotations

import os
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, List, Optional

from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from core.settings import GOOGLE_SYNC
from utils.datetime_utils import to_rfc3339_utc

try:
    from google.oauth2.credentials import Credentials
except Exception:
    Credentials = None

DEFAULT_SCOPES = list(GOOGLE_SYNC.scopes)

def _ensure_utc(dt: datetime) -> datetime:
    if dt.tzinfo is None:
        return dt.replace(tzinfo=timezone.utc)
    return dt.astimezone(timezone.utc)


def _to_rfc3339(dt: datetime) -> str:
    result = to_rfc3339_utc(_ensure_utc(dt))
    if result is None:
        raise ValueError("Failed to convert datetime to RFC3339")
    return result

def _path_exists(p) -> bool:
    try:
        return os.path.exists(os.fspath(p))
    except Exception:
        return False

# ---------- извлечение сервиса из auth ----------
def _build_service_from_creds(creds) -> Any:
    if creds is None:
        return None
    return build("calendar", "v3", credentials=creds)

def _find_creds_in_auth(auth, scopes: Optional[List[str]] = None):
    for name in ("get_credentials", "credentials", "creds"):
        val = getattr(auth, name, None)
        if callable(val):
            try:
                val = val()
            except Exception:
                val = None
        if val is not None and hasattr(val, "valid"):
            return val

    token_path = None
    for attr in ("token_path", "token_file", "token", "token_json"):
        p = getattr(auth, attr, None)
        if p and _path_exists(p):
            token_path = os.fspath(p)
            break
    if token_path and Credentials:
        try:
            return Credentials.from_authorized_user_file(token_path, scopes or DEFAULT_SCOPES)
        except Exception:
            pass
    return None

def _find_service_in_auth(auth) -> Any:
    for attr in ("calendar_service", "calendar", "service", "svc", "calendar_v3"):
        svc = getattr(auth, attr, None)
        if svc and hasattr(svc, "events"):
            return svc
    for meth in ("get_calendar_service", "build_calendar_service", "create_calendar_service"):
        if hasattr(auth, meth) and callable(getattr(auth, meth)):
            svc = getattr(auth, meth)()
            if svc and hasattr(svc, "events"):
                return svc
    for meth in ("get_service", "service_for", "build_service"):
        if hasattr(auth, meth) and callable(getattr(auth, meth)):
            try:
                svc = getattr(auth, meth)("calendar", "v3")
            except TypeError:
                svc = getattr(auth, meth)("calendar")
            if svc and hasattr(svc, "events"):
                return svc
    return None

# ---------- основной класс ----------
class GoogleCalendar:
    """Thin wrapper around Google Calendar service."""
    def __init__(self, auth, calendar_id: str = "primary"):
        self.auth = auth
        self.calendar_id = getattr(auth, "calendar_id", None) or calendar_id
        self.service = None
        self._maybe_build_service()

    def connect(self):
        if hasattr(self.auth, "ensure_credentials") and callable(getattr(self.auth, "ensure_credentials")):
            self.auth.ensure_credentials()
        self._maybe_build_service(strict=True)
        return True

    def _maybe_build_service(self, strict: bool = False):
        if self.service and hasattr(self.service, "events"):
            return
        svc = _find_service_in_auth(self.auth)
        if svc:
            self.service = svc
            return
        creds = _find_creds_in_auth(self.auth, DEFAULT_SCOPES)
        if creds:
            self.service = _build_service_from_creds(creds)
            return
        if strict:
            raise RuntimeError(
                "GoogleCalendar: не удалось собрать сервис из auth. Нужен token.json "
                "или ensure_credentials(), или get_credentials()/credentials/creds, "
                "или готовый service в auth."
            )

    # ----- операции -----
    def list_range(self, start_dt: datetime, end_dt: datetime, show_deleted: bool = False) -> List[Dict[str, Any]]:
        self._maybe_build_service(strict=True)
        params = dict(
            calendarId=self.calendar_id,
            timeMin=_to_rfc3339(start_dt),
            timeMax=_to_rfc3339(end_dt),
            singleEvents=True,
            orderBy="startTime",
            maxResults=2500,
        )
        if show_deleted:
            params["showDeleted"] = True
        res = self.service.events().list(**params).execute()
        return res.get("items", [])

    def create_event_for_task(self, task, start_dt: datetime, duration_minutes: int) -> Dict[str, Any]:
        self._maybe_build_service(strict=True)
        end_dt = _ensure_utc(start_dt) + timedelta(minutes=duration_minutes)
        notes = (getattr(task, "notes", None) or "").strip()
        body = {
            "summary": getattr(task, "title", "Задача"),
            "start": {"dateTime": _to_rfc3339(start_dt)},
            "end": {"dateTime": _to_rfc3339(end_dt)},
        }
        if notes:
            body["description"] = notes
        return self.service.events().insert(calendarId=self.calendar_id, body=body).execute()

    def update_event_for_task(self, event_id: str, task, start_dt: datetime, duration_minutes: int) -> Dict[str, Any]:
        self._maybe_build_service(strict=True)
        end_dt = _ensure_utc(start_dt) + timedelta(minutes=duration_minutes)
        notes = (getattr(task, "notes", None) or "").strip()
        body = {
            "summary": getattr(task, "title", "Задача"),
            "start": {"dateTime": _to_rfc3339(start_dt)},
            "end": {"dateTime": _to_rfc3339(end_dt)},
        }
        if notes:
            body["description"] = notes
        return self.service.events().patch(
            calendarId=self.calendar_id, eventId=event_id, body=body
        ).execute()

    def delete_event_by_id(self, event_id: str) -> None:
        self._maybe_build_service(strict=True)
        try:
            self.service.events().delete(calendarId=self.calendar_id, eventId=event_id).execute()
        except HttpError as e:
            if getattr(e, "resp", None) and getattr(e.resp, "status", None) == 404:
                return
            raise

```

### services/google_sync.py
```python
"""Utility helpers shared between sync services."""

from __future__ import annotations

from datetime import datetime, timedelta
from typing import Any, Dict, Optional, Tuple

from utils.datetime_utils import ensure_utc, parse_rfc3339, to_rfc3339_utc


def build_event_payload(task) -> Dict[str, Any]:
    start = ensure_utc(getattr(task, "start", None))
    duration = getattr(task, "duration_minutes", None)
    if start is None or not duration:
        raise ValueError("Scheduled task must have start and duration")

    end = start + timedelta(minutes=int(duration))
    notes = (getattr(task, "notes", None) or "").strip()

    body: Dict[str, Any] = {
        "summary": getattr(task, "title", "Задача"),
        "start": {"dateTime": to_rfc3339_utc(start)},
        "end": {"dateTime": to_rfc3339_utc(end)},
    }
    if notes:
        body["description"] = notes
    return body


def parse_event_datetime(payload: Dict[str, Any]) -> Optional[datetime]:
    if not payload:
        return None
    if "dateTime" in payload:
        return ensure_utc(parse_rfc3339(payload.get("dateTime")))
    if "date" in payload:
        try:
            raw = datetime.strptime(payload["date"], "%Y-%m-%d")
        except ValueError:
            return None
        return ensure_utc(raw)
    return None


def extract_event_times(event: Dict[str, Any]) -> Tuple[Optional[datetime], Optional[datetime]]:
    start = parse_event_datetime(event.get("start", {}))
    end = parse_event_datetime(event.get("end", {}))
    return start, end


def extract_notes(event: Dict[str, Any]) -> str:
    description = event.get("description") or ""
    return description.strip()


def event_updated(event: Dict[str, Any]) -> Optional[datetime]:
    return ensure_utc(parse_rfc3339(event.get("updated")))


def task_due_datetime(task) -> Optional[datetime]:
    start = getattr(task, "start", None)
    if start is None:
        return None
    return ensure_utc(start)


__all__ = [
    "build_event_payload",
    "event_updated",
    "extract_event_times",
    "extract_notes",
    "parse_event_datetime",
    "task_due_datetime",
]

```

### services/google_tasks.py
```python
"""Minimal Google Tasks client used by the synchronisation service."""

from __future__ import annotations

from datetime import datetime
from typing import Any, Dict, List, Optional

from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

from core.settings import GOOGLE_SYNC
from utils.datetime_utils import ensure_utc, to_rfc3339_utc


class GoogleTasks:
    def __init__(self, auth, tasklist_name: str | None = None) -> None:
        self.auth = auth
        self.tasklist_name = tasklist_name or GOOGLE_SYNC.tasks_tasklist_name or "Planner"
        self.service = None
        self.tasklist_id: Optional[str] = None

    # ------------------------------------------------------------------
    # Initialisation helpers
    def connect(self) -> None:
        self._ensure_service(strict=True)
        self.ensure_tasklist()

    def _ensure_service(self, strict: bool = False) -> None:
        if self.service is not None:
            return

        creds = None
        if hasattr(self.auth, "get_credentials") and callable(self.auth.get_credentials):
            creds = self.auth.get_credentials()
        elif hasattr(self.auth, "ensure_credentials") and callable(self.auth.ensure_credentials):
            if self.auth.ensure_credentials():  # type: ignore[misc]
                creds = getattr(self.auth, "creds", None) or getattr(self.auth, "credentials", None)
        else:
            creds = getattr(self.auth, "creds", None) or getattr(self.auth, "credentials", None)

        if not creds and strict:
            raise RuntimeError("Google credentials are not available")
        if not creds:
            return

        self.service = build("tasks", "v1", credentials=creds)

    def ensure_tasklist(self) -> str:
        self._ensure_service(strict=True)
        if self.tasklist_id:
            return self.tasklist_id

        service = self.service
        if service is None:  # pragma: no cover - defensive, should not happen
            raise RuntimeError("Google Tasks service is not initialised")

        page_token: Optional[str] = None
        while True:
            response = (
                service.tasklists()
                .list(maxResults=100, pageToken=page_token)
                .execute()
            )
            for item in response.get("items", []):
                if item.get("title") == self.tasklist_name:
                    self.tasklist_id = item.get("id")
                    if self.tasklist_id:
                        return self.tasklist_id
            page_token = response.get("nextPageToken")
            if not page_token:
                break

        created = (
            service.tasklists()
            .insert(body={"title": self.tasklist_name})
            .execute()
        )
        self.tasklist_id = created.get("id")
        if not self.tasklist_id:
            raise RuntimeError("Failed to create Google Tasks list")
        return self.tasklist_id

    # ------------------------------------------------------------------
    # CRUD helpers
    def list(self, updated_min: Optional[datetime] = None) -> List[Dict]:
        self.connect()
        service = self.service
        tasklist_id = self.tasklist_id
        if service is None or tasklist_id is None:  # pragma: no cover - defensive
            return []

        params: Dict[str, Any] = {
            "tasklist": tasklist_id,
            "showDeleted": True,
            "showHidden": True,
            "maxResults": 100,
        }
        if updated_min:
            params["updatedMin"] = to_rfc3339_utc(ensure_utc(updated_min)) or ""

        items: List[Dict] = []
        page_token: Optional[str] = None
        while True:
            response = (
                service.tasks()
                .list(pageToken=page_token, **params)
                .execute()
            )
            items.extend(response.get("items", []))
            page_token = response.get("nextPageToken")
            if not page_token:
                break
        return items

    def insert(self, title: str, notes: Optional[str], due: Optional[datetime]) -> Dict:
        self.connect()
        service = self.service
        tasklist_id = self.tasklist_id
        if service is None or tasklist_id is None:  # pragma: no cover - defensive
            raise RuntimeError("Google Tasks service is not initialised")

        body: Dict[str, Optional[str]] = {"title": title.strip() or "Задача"}
        notes_value = (notes or "").strip()
        if notes_value:
            body["notes"] = notes_value
        due_value = _format_due(due)
        if due_value:
            body["due"] = due_value
        return service.tasks().insert(tasklist=tasklist_id, body=body).execute()

    def patch(
        self,
        task_id: str,
        *,
        title: Optional[str] = None,
        notes: Optional[str] = None,
        due: Optional[datetime] = None,
        status: Optional[str] = None,
    ) -> Dict:
        self.connect()
        service = self.service
        tasklist_id = self.tasklist_id
        if service is None or tasklist_id is None:  # pragma: no cover - defensive
            raise RuntimeError("Google Tasks service is not initialised")

        body: Dict[str, Optional[str]] = {}
        if title is not None:
            body["title"] = title.strip() or "Задача"
        if notes is not None:
            notes_value = notes.strip()
            body["notes"] = notes_value or None
        if due is not None:
            body["due"] = _format_due(due)
        if status is not None:
            body["status"] = status

        return service.tasks().patch(tasklist=tasklist_id, task=task_id, body=body).execute()

    def delete(self, task_id: str) -> None:
        self.connect()
        service = self.service
        tasklist_id = self.tasklist_id
        if service is None or tasklist_id is None:  # pragma: no cover - defensive
            return
        try:
            service.tasks().delete(tasklist=tasklist_id, task=task_id).execute()
        except HttpError as exc:
            status = getattr(exc, "resp", None) and getattr(exc.resp, "status", None)
            if status and int(status) == 404:
                return
            raise


def _format_due(value: Optional[datetime]) -> Optional[str]:
    if value is None:
        return None
    normalized = ensure_utc(value)
    normalized = normalized.replace(hour=0, minute=0, second=0, microsecond=0)
    return to_rfc3339_utc(normalized)


__all__ = ["GoogleTasks"]

```

### services/pending_ops_queue.py
```python
from __future__ import annotations

import json
from dataclasses import dataclass
from datetime import timedelta
from typing import Iterable, List, Optional

from sqlmodel import select
from sqlalchemy import func

from utils.datetime_utils import utc_now
from models.pending_op import PendingOp
from storage.db import get_session


VALID_OPS = {
    "gcal_create",
    "gcal_update",
    "gcal_delete",
    "gtasks_create",
    "gtasks_update",
    "gtasks_delete",
}


def _next_try(attempts: int) -> datetime:
    delay = min(30, 2 ** max(attempts, 0))
    return utc_now() + timedelta(seconds=delay)


@dataclass
class PendingOperation:
    id: int
    op: str
    task_id: int
    payload: dict
    attempts: int
    last_error: Optional[str]
    next_try_at: datetime


class PendingOpsQueue:
    def enqueue(self, op: str, task_id: int, payload: dict) -> None:
        if op not in VALID_OPS:
            raise ValueError(f"Unsupported op: {op}")
        record = PendingOp(
            op=op,
            task_id=task_id,
            payload=json.dumps(payload, ensure_ascii=False),
            created_at=utc_now(),
            next_try_at=utc_now(),
        )
        with get_session() as session:
            session.add(record)
            session.commit()

    def requeue(self, op_id: int, error: str) -> None:
        with get_session() as session:
            record = session.get(PendingOp, op_id)
            if not record:
                return
            record.attempts += 1
            record.last_error = error[:1000]
            record.next_try_at = _next_try(record.attempts)
            session.add(record)
            session.commit()

    def remove(self, op_id: int) -> None:
        with get_session() as session:
            record = session.get(PendingOp, op_id)
            if record:
                session.delete(record)
                session.commit()

    def due(self, limit: int = 10) -> List[PendingOperation]:
        now = utc_now()
        with get_session() as session:
            stmt = (
                select(PendingOp)
                .where(PendingOp.next_try_at <= now)
                .order_by(PendingOp.next_try_at.asc())
                .limit(limit)
            )
            rows = list(session.exec(stmt))

        result: List[PendingOperation] = []
        for row in rows:
            try:
                payload = json.loads(row.payload)
            except json.JSONDecodeError:
                payload = {}
            result.append(
                PendingOperation(
                    id=row.id,
                    op=row.op,
                    task_id=row.task_id,
                    payload=payload,
                    attempts=row.attempts,
                    last_error=row.last_error,
                    next_try_at=row.next_try_at,
                )
            )
        return result

    def count(self) -> int:
        with get_session() as session:
            return int(session.exec(select(func.count()).select_from(PendingOp)).one())


__all__ = ["PendingOpsQueue", "PendingOperation"]

```

### services/sync.py
```python
# services/sync.py
from __future__ import annotations

import json
import re
from pathlib import Path
from typing import Optional
from datetime import datetime, timezone, timedelta

from datetime_utils import parse_rfc3339, to_rfc3339

from services.tasks import TaskService
from core.settings import GOOGLE_SYNC

DELETE_ON_GOOGLE_CANCEL = GOOGLE_SYNC.delete_on_google_cancel  # True — удалять задачу; False — только снимать расписание (как сейчас)
_MARKER_RE = re.compile(r"planner_task_id\s*:\s*(\d+)", re.I)


class JsonTokenStore:
    """Простейшее хранение syncToken в файле (чтобы получать только изменения)."""
    def __init__(self, path: str | Path = GOOGLE_SYNC.sync_token_path):
        self.path = Path(path)

    def get_sync_token(self) -> Optional[str]:
        try:
            data = json.loads(self.path.read_text(encoding="utf-8"))
            return data.get("syncToken")
        except Exception:
            return None

    def set_sync_token(self, token: str):
        self.path.parent.mkdir(parents=True, exist_ok=True)
        self.path.write_text(json.dumps({"syncToken": token}), encoding="utf-8")


def _parse_marker(description: str | None) -> Optional[int]:
    if not description:
        return None
    m = _MARKER_RE.search(description)
    if not m:
        return None
    try:
        return int(m.group(1))
    except Exception:
        return None


def _strip_marker(description: str | None) -> str:
    if not description:
        return ""
    lines = [ln for ln in description.splitlines() if not _MARKER_RE.search(ln)]
    return "\n".join(lines).strip()


def _parse_g_datetime(obj: dict | None) -> Optional[datetime]:
    """start/end из Google: либо {'dateTime': '...Z'}, либо {'date': 'YYYY-MM-DD'}."""
    if not obj:
        return None
    if "dateTime" in obj and obj["dateTime"]:
        return parse_rfc3339(str(obj["dateTime"]))
    if "date" in obj and obj["date"]:
        # all-day -> в полночь локального дня (без tz; дальше ты сам решаешь как отображать)
        try:
            d = datetime.strptime(str(obj["date"]).strip(), "%Y-%m-%d")
            return d
        except Exception:
            # некоторые клиенты присылают 'YYYY-MM-DD' -> отработает
            try:
                y, m, dd = str(obj["date"]).split("-")
                return datetime(int(y), int(m), int(dd))
            except Exception:
                return None
    return None


class GoogleSync:
    """
    Двусторонняя связка:
      - Если событие в Google помечено marker'ом planner_task_id:NN — обновляем соответствующую локальную задачу.
      - Если marker'а нет, но мы видим event_id == Task.gcal_event_id — обновляем эту задачу.
      - Если marker'а нет и event_id незнаком — создаём новую локальную задачу и обратно проставляем marker в событие.
      - Если событие в Google отменено (status=cancelled) — снимаем расписание у соответствующей задачи (не удаляем).
    """
    def __init__(self, gcal_service, calendar_id: str, token_store: JsonTokenStore | None = None):
        self.service = gcal_service
        self.calendar_id = calendar_id
        self.store = token_store or JsonTokenStore()
        self.svc = TaskService()

    def pull(self) -> bool:
        """Возвращает True, если что-то изменилось в локальной базе."""
        if not self.service or not self.calendar_id:
            return False

        changed = False
        token = self.store.get_sync_token()

        params = dict(
            calendarId=self.calendar_id,
            singleEvents=True,
            showDeleted=True,
            maxResults=250,
        )
        if token:
            # инкрементальные изменения
            params["syncToken"] = token
        else:
            # первичная выгрузка за последние 6 мес.
            params["timeMin"] = to_rfc3339(datetime.now(timezone.utc) - timedelta(days=180))

        while True:
            resp = self.service.events().list(**params).execute()
            items = resp.get("items", [])

            for ev in items:
                ev_id = ev.get("id")
                status = ev.get("status")
                summary = ev.get("summary") or "Без названия"
                description = ev.get("description") or ""

                # cancelled -> снять расписание у связанной задачи (если есть)
                if status == "cancelled":
                    tid = _parse_marker(description)
                    target_task = self.svc.get(tid) if tid else self.svc.get_by_event_id(ev_id)
                    if target_task:
                        if DELETE_ON_GOOGLE_CANCEL:
                            self.svc.delete(target_task.id)
                        else:
                            self.svc.unschedule(target_task.id)
                        changed = True
                    continue

                # обычное событие
                dt_start = _parse_g_datetime(ev.get("start"))
                dt_end   = _parse_g_datetime(ev.get("end"))
                duration = None
                if dt_start and dt_end and dt_end > dt_start:
                    duration = int((dt_end - dt_start).total_seconds() // 60)

                # ищем задачу
                task = None
                tid = _parse_marker(description)
                if tid:
                    task = self.svc.get(tid)
                if task is None:
                    task = self.svc.get_by_event_id(ev_id)

                # текст заметок без служебного маркера
                notes = _strip_marker(description)

                if task:
                    # обновляем локально
                    self.svc.update(task.id, title=summary, notes=notes, start=dt_start, duration_minutes=duration)
                    if task.gcal_event_id != ev_id:
                        self.svc.set_event_id(task.id, ev_id)
                    changed = True

                    # убедимся, что в событии есть marker
                    if tid != task.id:
                        # аккуратно дописываем marker в описание, не трогая время
                        try:
                            new_desc = (notes + ("\n" if notes else "") + f"planner_task_id:{task.id}").strip()
                            self.service.events().patch(
                                calendarId=self.calendar_id,
                                eventId=ev_id,
                                body={"description": new_desc},
                            ).execute()
                        except Exception:
                            pass
                else:
                    # это новое событие «со стороны Google» — создаём задачу
                    new_task = self.svc.add(title=summary, start=dt_start, duration_minutes=duration, notes=notes)
                    self.svc.set_event_id(new_task.id, ev_id)
                    changed = True

                    # и проставим marker обратно в событии
                    try:
                        new_desc = (notes + ("\n" if notes else "") + f"planner_task_id:{new_task.id}").strip()
                        self.service.events().patch(
                            calendarId=self.calendar_id,
                            eventId=ev_id,
                            body={"description": new_desc},
                        ).execute()
                    except Exception:
                        pass

            # пагинация + syncToken
            if "nextPageToken" in resp:
                params["pageToken"] = resp["nextPageToken"]
                # не нужна timeMin/syncToken при пагинации
                params.pop("timeMin", None)
                params.pop("syncToken", None)
                continue

            if "nextSyncToken" in resp:
                self.store.set_sync_token(resp["nextSyncToken"])
            break

        return changed

```

### services/sync_service.py
```python
from __future__ import annotations
import logging
from logging.handlers import RotatingFileHandler
from pathlib import Path
from datetime import datetime, timedelta
from typing import Optional

from googleapiclient.errors import HttpError

from core.settings import GOOGLE_SYNC
from utils.datetime_utils import ensure_utc, parse_rfc3339, to_rfc3339_utc, utc_now
from models.task import Task
from services.google_calendar import GoogleCalendar
from services.google_tasks import GoogleTasks
from services.google_sync import (
    build_event_payload,
    event_updated,
    extract_event_times,
    extract_notes,
)
from services.pending_ops_queue import PendingOpsQueue
from services.sync_token_storage import SyncTokenStorage
from services.tasks import TaskService


RETRYABLE_STATUS = {409, 412, 429, 500, 502, 503, 504}
SYNC_LOG_PATH = "logs/sync.log"


def _ensure_logger() -> logging.Logger:
    logger = logging.getLogger("planner.sync")
    if not logger.handlers:
        Path(SYNC_LOG_PATH).parent.mkdir(parents=True, exist_ok=True)
        handler = RotatingFileHandler(SYNC_LOG_PATH, maxBytes=1_000_000, backupCount=3, encoding="utf-8")
        formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")
        handler.setFormatter(formatter)
        logger.addHandler(handler)
    logger.setLevel(logging.INFO)
    return logger


def _is_scheduled(task: Task) -> bool:
    return bool(task.start and task.duration_minutes)


def _due_datetime(task: Task) -> Optional[datetime]:
    if task.start is None:
        return None
    dt = ensure_utc(task.start)
    return dt.replace(hour=0, minute=0, second=0, microsecond=0)


def _duration_minutes(start: Optional[datetime], end: Optional[datetime]) -> Optional[int]:
    if not start or not end:
        return None
    delta = end - start
    minutes = int(delta.total_seconds() // 60)
    return minutes if minutes > 0 else None


class SyncService:
    def __init__(
        self,
        gcal: GoogleCalendar,
        gtasks: GoogleTasks,
        repo: TaskService,
        token_store: SyncTokenStorage,
        queue: Optional[PendingOpsQueue] = None,
    ) -> None:
        self.gcal = gcal
        self.gtasks = gtasks
        self.repo = repo
        self.tokens = token_store
        self.queue = queue or PendingOpsQueue()
        self.logger = _ensure_logger()

    # ------------------------------------------------------------------
    # Event hooks from TaskService
    def on_task_created(self, task_id: int) -> None:
        if not GOOGLE_SYNC.enabled:
            return
        task = self.repo.get(task_id)
        if not task:
            return
        self.logger.debug("Task created: %s", task_id)
        if _is_scheduled(task):
            self._ensure_tasks_delete(task)
            self._queue_calendar_sync(task)
        else:
            self._ensure_calendar_delete(task)
            self._queue_tasks_sync(task)

    def on_task_updated(self, task_id: int) -> None:
        if not GOOGLE_SYNC.enabled:
            return
        task = self.repo.get(task_id)
        if not task:
            return
        self.logger.debug("Task updated: %s", task_id)
        if _is_scheduled(task):
            self._ensure_tasks_delete(task)
            self._queue_calendar_sync(task)
        else:
            self._ensure_calendar_delete(task)
            self._queue_tasks_sync(task)

    def on_task_deleted(self, task_id: int) -> None:
        if not GOOGLE_SYNC.enabled:
            return
        task = self.repo.get(task_id)
        if not task:
            return
        self.logger.debug("Task deleted: %s", task_id)
        if task.gcal_event_id:
            self.queue.enqueue("gcal_delete", task_id, {"eventId": task.gcal_event_id})
        if task.gtasks_id:
            self.queue.enqueue("gtasks_delete", task_id, {"taskId": task.gtasks_id})

    # ------------------------------------------------------------------
    # Public API
    def pull_all(self) -> bool:
        if not GOOGLE_SYNC.enabled:
            return False
        changed = False
        try:
            changed |= self._pull_calendar()
        except HttpError as exc:
            status = getattr(exc, "resp", None) and getattr(exc.resp, "status", None)
            if status == 410:
                self.logger.warning("Calendar sync token expired, triggering full resync")
                self.reset_calendar_sync_token()
                changed |= self._pull_calendar()
            else:
                self.logger.error("Calendar pull failed: %s", exc)
                raise
        except Exception as exc:  # pragma: no cover - defensive
            self.logger.error("Calendar pull error: %s", exc)
            raise

        try:
            changed |= self._pull_tasks()
        except Exception as exc:  # pragma: no cover - defensive
            self.logger.error("Tasks pull error: %s", exc)
            raise

        return changed

    def push_queue_worker(self) -> int:
        processed = 0
        for entry in self.queue.due():
            try:
                if self._execute_op(entry):
                    processed += 1
                    self.queue.remove(entry.id)
                    self.tokens.set_last_push_timestamp()
                else:
                    self.queue.requeue(entry.id, "invalid payload")
            except HttpError as exc:
                status = getattr(exc, "resp", None) and getattr(exc.resp, "status", None)
                code = int(status or 0)
                self.logger.warning("Push op %s failed with %s", entry.op, code)
                if code in RETRYABLE_STATUS:
                    self.queue.requeue(entry.id, str(exc))
                else:
                    self.queue.requeue(entry.id, str(exc))
            except Exception as exc:  # pragma: no cover - defensive
                self.logger.error("Push op %s crashed: %s", entry.op, exc)
                self.queue.requeue(entry.id, str(exc))
        return processed

    def force_full_resync(self) -> None:
        self.logger.info("Force full resync requested")
        self.tokens.clear_all()
        self.pull_all()

    def reset_calendar_sync_token(self) -> None:
        self.logger.info("Resetting calendar sync token")
        self.tokens.clear_calendar_token()

    def status(self) -> dict:
        return {
            "calendar": {
                "calendarId": getattr(self.gcal, "calendar_id", None),
                "syncToken": bool(self.tokens.get_calendar_token()),
                "lastPullAt": self.tokens.get_calendar_pull_timestamp(),
            },
            "tasks": {
                "tasklist": getattr(self.gtasks, "tasklist_id", None),
                "updatedMin": self.tokens.get_tasks_updated_min(),
                "lastPullAt": self.tokens.get_tasks_pull_timestamp(),
            },
            "lastPushAt": self.tokens.get_last_push_timestamp(),
            "queueSize": self.queue.count(),
        }

    # ------------------------------------------------------------------
    # Pull helpers
    def _pull_calendar(self) -> bool:
        self.logger.debug("Pulling Google Calendar")
        self.gcal.connect()
        service = getattr(self.gcal, "service", None)
        if service is None:
            return False

        params = dict(
            calendarId=self.gcal.calendar_id,
            singleEvents=True,
            showDeleted=True,
            maxResults=250,
        )
        token = self.tokens.get_calendar_token()
        if token:
            params["syncToken"] = token
        else:
            params["timeMin"] = to_rfc3339_utc(utc_now() - timedelta(days=90))

        changed = False
        while True:
            response = service.events().list(**params).execute()
            for event in response.get("items", []):
                if self._apply_calendar_event(event):
                    changed = True
            if "nextPageToken" in response:
                params.pop("syncToken", None)
                params.pop("timeMin", None)
                params["pageToken"] = response["nextPageToken"]
                continue
            if "nextSyncToken" in response:
                self.tokens.set_calendar_token(response["nextSyncToken"])
            break

        self.tokens.set_calendar_pull_timestamp()
        return changed

    def _apply_calendar_event(self, event: dict) -> bool:
        event_id = event.get("id")
        if not event_id:
            return False

        status = event.get("status")
        task = self.repo.get_by_event_id(event_id)
        remote_updated = event_updated(event) or utc_now()

        if status == "cancelled":
            if not task:
                return False
            self.logger.info("Calendar event deleted remotely for task %s", task.id)
            updated_task = self.repo.update_from_sync(
                task.id,
                start=None,
                duration_minutes=None,
                gcal_event_id=None,
                gcal_etag=None,
                gcal_updated=remote_updated,
                updated_at=remote_updated,
            )
            self._queue_tasks_sync(updated_task or task)
            return True

        start, end = extract_event_times(event)
        duration = _duration_minutes(start, end)
        notes = extract_notes(event)
        summary = event.get("summary") or "Без названия"

        if not task:
            self.logger.info("New calendar event -> creating task")
            self.repo.create_from_sync(
                title=summary,
                notes=notes,
                start=start,
                duration_minutes=duration,
                status="todo",
                gcal_event_id=event_id,
                gcal_etag=event.get("etag"),
                gcal_updated=remote_updated,
            )
            return True

        local_updated = ensure_utc(task.updated_at)
        known_remote = ensure_utc(task.gcal_updated)
        if known_remote and remote_updated <= known_remote:
            return False

        if remote_updated >= local_updated:
            self.logger.info("Calendar event %s newer than local task %s", event_id, task.id)
            self.repo.update_from_sync(
                task.id,
                title=summary,
                notes=notes or None,
                start=start,
                duration_minutes=duration,
                gcal_event_id=event_id,
                gcal_etag=event.get("etag"),
                gcal_updated=remote_updated,
                updated_at=remote_updated,
            )
            return True

        self.logger.debug("Local task %s wins over calendar event %s", task.id, event_id)
        self._queue_calendar_sync(task)
        return False

    def _pull_tasks(self) -> bool:
        self.logger.debug("Pulling Google Tasks")
        self.gtasks.connect()
        updated_min = self.tokens.get_tasks_updated_min()
        items = self.gtasks.list(updated_min=updated_min)
        if not items:
            self.tokens.set_tasks_pull_timestamp()
            return False

        changed = False
        latest_remote: Optional[datetime] = updated_min
        for entry in items:
            if self._apply_task_entry(entry):
                changed = True
            remote_updated = ensure_utc(parse_rfc3339(entry.get("updated")))
            if remote_updated and (latest_remote is None or remote_updated > latest_remote):
                latest_remote = remote_updated

        if latest_remote:
            self.tokens.set_tasks_updated_min(latest_remote)
        self.tokens.set_tasks_pull_timestamp()
        return changed

    def _apply_task_entry(self, entry: dict) -> bool:
        task_id = entry.get("id")
        if not task_id:
            return False
        deleted = entry.get("deleted") or entry.get("status") == "deleted"
        remote_updated = ensure_utc(parse_rfc3339(entry.get("updated"))) or utc_now()
        title = entry.get("title") or "Без названия"
        notes = entry.get("notes") or None
        due_raw = entry.get("due")
        due_dt = ensure_utc(parse_rfc3339(due_raw)) if due_raw else None
        if due_dt:
            due_dt = due_dt.replace(hour=0, minute=0, second=0, microsecond=0)

        task = self.repo.get_by_gtasks_id(task_id)

        if deleted:
            if task:
                self.logger.info("Remote task deleted -> removing local task %s", task.id)
                self.repo.delete_from_sync(task.id)
                return True
            return False

        if not task:
            self.logger.info("New Google Task -> creating local task")
            self.repo.create_from_sync(
                title=title,
                notes=notes,
                start=due_dt,
                duration_minutes=None,
                status="todo",
                gtasks_id=task_id,
                gtasks_updated=remote_updated,
            )
            return True

        local_updated = ensure_utc(task.updated_at)
        known_remote = ensure_utc(task.gtasks_updated)
        if known_remote and remote_updated <= known_remote:
            return False

        if remote_updated >= local_updated:
            self.logger.info("Google Task %s newer than local task %s", task_id, task.id)
            self.repo.update_from_sync(
                task.id,
                title=title,
                notes=notes,
                start=due_dt,
                duration_minutes=None,
                gtasks_id=task_id,
                gtasks_updated=remote_updated,
                gcal_event_id=None if not _is_scheduled(task) else task.gcal_event_id,
                updated_at=remote_updated,
            )
            return True

        self.logger.debug("Local task %s wins over Google Task %s", task.id, task_id)
        self._queue_tasks_sync(task)
        return False

    # ------------------------------------------------------------------
    # Queue helpers
    def _queue_calendar_sync(self, task: Task) -> None:
        if task.gcal_event_id:
            self.queue.enqueue("gcal_update", task.id, {"eventId": task.gcal_event_id})
        else:
            self.queue.enqueue("gcal_create", task.id, {})

    def _queue_tasks_sync(self, task: Optional[Task]) -> None:
        if not task:
            return
        if task.gtasks_id:
            self.queue.enqueue("gtasks_update", task.id, {"taskId": task.gtasks_id})
        else:
            self.queue.enqueue("gtasks_create", task.id, {})

    def _ensure_calendar_delete(self, task: Task) -> None:
        if task.gcal_event_id:
            self.queue.enqueue("gcal_delete", task.id, {"eventId": task.gcal_event_id})

    def _ensure_tasks_delete(self, task: Task) -> None:
        if task.gtasks_id:
            self.queue.enqueue("gtasks_delete", task.id, {"taskId": task.gtasks_id})

    # ------------------------------------------------------------------
    def _execute_op(self, entry) -> bool:
        op = entry.op
        payload = entry.payload or {}

        if op == "gcal_create":
            task = self.repo.get(entry.task_id)
            if not task or not _is_scheduled(task):
                return True
            self.gcal.connect()
            service = getattr(self.gcal, "service", None)
            if service is None:
                return False
            body = build_event_payload(task)
            response = service.events().insert(calendarId=self.gcal.calendar_id, body=body).execute()
            updated = event_updated(response) or utc_now()
            self.repo.update_from_sync(
                task.id,
                gcal_event_id=response.get("id"),
                gcal_etag=response.get("etag"),
                gcal_updated=updated,
                updated_at=updated,
            )
            return True

        if op == "gcal_update":
            task = self.repo.get(entry.task_id)
            if not task or not _is_scheduled(task):
                return True
            event_id = payload.get("eventId") or task.gcal_event_id
            if not event_id:
                return True
            self.gcal.connect()
            service = getattr(self.gcal, "service", None)
            if service is None:
                return False
            body = build_event_payload(task)
            response = service.events().patch(
                calendarId=self.gcal.calendar_id, eventId=event_id, body=body
            ).execute()
            updated = event_updated(response) or utc_now()
            self.repo.update_from_sync(
                task.id,
                gcal_event_id=response.get("id", event_id),
                gcal_etag=response.get("etag"),
                gcal_updated=updated,
                updated_at=updated,
            )
            return True

        if op == "gcal_delete":
            event_id = payload.get("eventId")
            task = self.repo.get(entry.task_id)
            if not event_id and task:
                event_id = task.gcal_event_id
            if not event_id:
                return True
            self.gcal.connect()
            service = getattr(self.gcal, "service", None)
            if service is None:
                return False
            try:
                service.events().delete(calendarId=self.gcal.calendar_id, eventId=event_id).execute()
            except HttpError as exc:
                status = getattr(exc, "resp", None) and getattr(exc.resp, "status", None)
                if status and int(status) == 404:
                    pass
                else:
                    raise
            if task:
                self.repo.update_from_sync(
                    task.id,
                    gcal_event_id=None,
                    gcal_etag=None,
                    gcal_updated=utc_now(),
                )
            return True

        if op == "gtasks_create":
            task = self.repo.get(entry.task_id)
            if not task or _is_scheduled(task):
                return True
            due = _due_datetime(task)
            response = self.gtasks.insert(task.title, task.notes, due)
            remote_updated = ensure_utc(parse_rfc3339(response.get("updated"))) or utc_now()
            self.repo.update_from_sync(
                task.id,
                gtasks_id=response.get("id"),
                gtasks_updated=remote_updated,
                updated_at=remote_updated,
            )
            return True

        if op == "gtasks_update":
            task = self.repo.get(entry.task_id)
            if not task:
                return True
            task_id = payload.get("taskId") or task.gtasks_id
            if not task_id:
                return True
            due = _due_datetime(task)
            self.gtasks.patch(
                task_id,
                title=task.title,
                notes=task.notes,
                due=due,
            )
            self.repo.update_from_sync(
                task.id,
                gtasks_id=task_id,
                gtasks_updated=utc_now(),
            )
            return True

        if op == "gtasks_delete":
            task_id = payload.get("taskId")
            task = self.repo.get(entry.task_id)
            if not task_id and task:
                task_id = task.gtasks_id
            if not task_id:
                return True
            try:
                self.gtasks.delete(task_id)
            except HttpError as exc:
                status = getattr(exc, "resp", None) and getattr(exc.resp, "status", None)
                if status and int(status) == 404:
                    pass
                else:
                    raise
            if task:
                self.repo.update_from_sync(
                    task.id,
                    gtasks_id=None,
                    gtasks_updated=utc_now(),
                )
            return True

        return False


__all__ = ["SyncService", "SYNC_LOG_PATH"]

```

### services/sync_token_storage.py
```python
from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, Optional

from utils.datetime_utils import ensure_utc, to_rfc3339_utc, utc_now
from core.settings import GOOGLE_SYNC


def _parse_datetime(value: Optional[str]):
    from utils.datetime_utils import parse_rfc3339

    return ensure_utc(parse_rfc3339(value)) if value else None


class SyncTokenStorage:
    def __init__(self, path: Path | str | None = None):
        self.path = Path(path or GOOGLE_SYNC.sync_token_path)

    # ------------------------------------------------------------------
    # generic helpers
    def _load(self) -> Dict[str, Any]:
        try:
            data = json.loads(self.path.read_text(encoding="utf-8"))
        except FileNotFoundError:
            return {}
        except json.JSONDecodeError:
            return {}
        if isinstance(data, str):
            return {"calendar": {"syncToken": data}}
        if isinstance(data, dict):
            return data
        return {}

    def _save(self, data: Dict[str, Any]) -> None:
        self.path.parent.mkdir(parents=True, exist_ok=True)
        self.path.write_text(json.dumps(data), encoding="utf-8")

    # ------------------------------------------------------------------
    # Calendar token helpers
    def get_calendar_token(self) -> Optional[str]:
        data = self._load()
        calendar = data.get("calendar", {})
        if isinstance(calendar, dict):
            token = calendar.get("syncToken")
            if token:
                return str(token)
        if "syncToken" in data:
            return str(data["syncToken"])
        return None

    def set_calendar_token(self, token: str) -> None:
        data = self._load()
        calendar = data.setdefault("calendar", {})
        if isinstance(calendar, dict):
            calendar["syncToken"] = token
        else:
            data["calendar"] = {"syncToken": token}
        self._save(data)

    def clear_calendar_token(self) -> None:
        data = self._load()
        calendar = data.get("calendar")
        if isinstance(calendar, dict) and "syncToken" in calendar:
            calendar.pop("syncToken", None)
        if "syncToken" in data:
            data.pop("syncToken", None)
        self._save(data)

    def set_calendar_pull_timestamp(self, moment=None) -> None:
        data = self._load()
        calendar = data.setdefault("calendar", {})
        if isinstance(calendar, dict):
            calendar["lastPullAt"] = to_rfc3339_utc(ensure_utc(moment) if moment else utc_now())
        self._save(data)

    def get_calendar_pull_timestamp(self):
        data = self._load()
        calendar = data.get("calendar", {})
        if isinstance(calendar, dict):
            return _parse_datetime(calendar.get("lastPullAt"))
        return None

    # ------------------------------------------------------------------
    # Tasks helpers
    def get_tasks_updated_min(self):
        data = self._load()
        tasks = data.get("tasks", {})
        if isinstance(tasks, dict):
            value = tasks.get("updatedMin")
            return _parse_datetime(value)
        return None

    def set_tasks_updated_min(self, value) -> None:
        data = self._load()
        tasks = data.setdefault("tasks", {})
        if isinstance(tasks, dict):
            tasks["updatedMin"] = to_rfc3339_utc(ensure_utc(value)) if value else None
        self._save(data)

    def set_tasks_pull_timestamp(self, moment=None) -> None:
        data = self._load()
        tasks = data.setdefault("tasks", {})
        if isinstance(tasks, dict):
            tasks["lastPullAt"] = to_rfc3339_utc(ensure_utc(moment) if moment else utc_now())
        self._save(data)

    def get_tasks_pull_timestamp(self):
        data = self._load()
        tasks = data.get("tasks", {})
        if isinstance(tasks, dict):
            return _parse_datetime(tasks.get("lastPullAt"))
        return None

    # ------------------------------------------------------------------
    # Push helpers
    def set_last_push_timestamp(self, moment=None) -> None:
        data = self._load()
        data["lastPushAt"] = to_rfc3339_utc(ensure_utc(moment) if moment else utc_now())
        self._save(data)

    def get_last_push_timestamp(self):
        data = self._load()
        return _parse_datetime(data.get("lastPushAt"))

    # ------------------------------------------------------------------
    def clear_all(self) -> None:
        if self.path.exists():
            self.path.unlink()


__all__ = ["SyncTokenStorage"]

```

### services/tags.py
```python
# planner/services/tags.py
from __future__ import annotations

import re
from typing import List, Optional

from sqlmodel import select

from models.tag import Tag, TaskTag
from storage.db import get_session
from utils.datetime_utils import utc_now


NAME_RE = re.compile(r"^.{1,40}$")
COLOR_RE = re.compile(r"^#[0-9A-Fa-f]{6}$")


class TagService:
    def list(self) -> List[Tag]:
        with get_session() as session:
            stmt = select(Tag).order_by(Tag.name.asc())
            return list(session.exec(stmt))

    def create(self, name: str, color_hex: str) -> Tag:
        name = name.strip()
        self._validate_inputs(name, color_hex)
        normalized_color = color_hex.upper()
        with get_session() as session:
            tag = Tag(name=name, color_hex=normalized_color)
            session.add(tag)
            session.commit()
            session.refresh(tag)
            return tag

    def rename(self, tag_id: int, new_name: str) -> Optional[Tag]:
        new_name = new_name.strip()
        self._validate_name(new_name)
        with get_session() as session:
            tag = session.get(Tag, tag_id)
            if not tag:
                return None
            tag.name = new_name
            tag.updated_at = utc_now()
            session.add(tag)
            session.commit()
            session.refresh(tag)
            return tag

    def recolor(self, tag_id: int, color_hex: str) -> Optional[Tag]:
        self._validate_color(color_hex)
        normalized_color = color_hex.upper()
        with get_session() as session:
            tag = session.get(Tag, tag_id)
            if not tag:
                return None
            tag.color_hex = normalized_color
            tag.updated_at = utc_now()
            session.add(tag)
            session.commit()
            session.refresh(tag)
            return tag

    def delete(self, tag_id: int) -> None:
        with get_session() as session:
            tag = session.get(Tag, tag_id)
            if not tag:
                return
            # Remove associations first due to composite PK
            stmt = select(TaskTag).where(TaskTag.tag_id == tag_id)
            for link in session.exec(stmt):
                session.delete(link)
            session.delete(tag)
            session.commit()

    def set_for_task(self, task_id: int, tag_ids: List[int]) -> None:
        unique_ids = set(tag_ids)
        with get_session() as session:
            # Remove old associations
            stmt = select(TaskTag).where(TaskTag.task_id == task_id)
            existing = list(session.exec(stmt))
            for link in existing:
                if link.tag_id not in unique_ids:
                    session.delete(link)
            # Add new links
            existing_ids = {link.tag_id for link in existing}
            for tag_id in unique_ids - existing_ids:
                session.add(TaskTag(task_id=task_id, tag_id=tag_id))
            session.commit()

    def add_to_task(self, task_id: int, tag_id: int) -> None:
        with get_session() as session:
            link = session.get(TaskTag, (task_id, tag_id))
            if link:
                return
            session.add(TaskTag(task_id=task_id, tag_id=tag_id))
            session.commit()

    def remove_from_task(self, task_id: int, tag_id: int) -> None:
        with get_session() as session:
            link = session.get(TaskTag, (task_id, tag_id))
            if link:
                session.delete(link)
                session.commit()

    def get_for_task(self, task_id: int) -> List[Tag]:
        with get_session() as session:
            stmt = (
                select(Tag)
                .join(TaskTag, Tag.id == TaskTag.tag_id)
                .where(TaskTag.task_id == task_id)
                .order_by(Tag.name.asc())
            )
            return list(session.exec(stmt))

    # ------------------------------------------------------------------
    def _validate_inputs(self, name: str, color_hex: str) -> None:
        self._validate_name(name)
        self._validate_color(color_hex)

    def _validate_name(self, name: str) -> None:
        if not NAME_RE.match(name):
            raise ValueError("Tag name must be between 1 and 40 characters")

    def _validate_color(self, color_hex: str) -> None:
        if not COLOR_RE.match(color_hex):
            raise ValueError("Color must be in #RRGGBB format")


__all__ = ["TagService"]

```

### services/task_repository.py
```python
from __future__ import annotations

from datetime import datetime
from typing import Optional

from sqlmodel import select

from utils.datetime_utils import ensure_utc, utc_now
from models.task import Task
from storage.db import get_session


class TaskRepository:
    def get(self, task_id: int) -> Optional[Task]:
        with get_session() as session:
            return session.get(Task, task_id)

    def get_by_event_id(self, event_id: str) -> Optional[Task]:
        if not event_id:
            return None
        with get_session() as session:
            stmt = select(Task).where(Task.gcal_event_id == event_id)
            return session.exec(stmt).first()

    def add(self, **fields) -> Task:
        with get_session() as session:
            task = Task(**fields)
            session.add(task)
            session.commit()
            session.refresh(task)
            return task

    def update(self, task: Task, **fields) -> Task:
        with get_session() as session:
            obj = session.get(Task, task.id)
            if not obj:
                raise ValueError("Task not found")
            for key, value in fields.items():
                if isinstance(value, datetime):
                    setattr(obj, key, ensure_utc(value))
                else:
                    setattr(obj, key, value)
            obj.updated_at = utc_now()
            session.add(obj)
            session.commit()
            session.refresh(obj)
            return obj

    def delete(self, task_id: int) -> None:
        with get_session() as session:
            obj = session.get(Task, task_id)
            if obj:
                session.delete(obj)
                session.commit()

    def mark_unscheduled(self, task_id: int) -> Optional[Task]:
        with get_session() as session:
            obj = session.get(Task, task_id)
            if not obj:
                return None
            obj.start = None
            obj.duration_minutes = None
            obj.gcal_event_id = None
            obj.gcal_etag = None
            obj.gcal_updated = None
            obj.updated_at = utc_now()
            session.add(obj)
            session.commit()
            session.refresh(obj)
            return obj


__all__ = ["TaskRepository"]

```

### services/task_sync_store.py
```python
"""Persistence helpers for Google Tasks synchronization state."""

from __future__ import annotations

from datetime import datetime
from typing import Iterable, List, Optional

from sqlalchemy import func, select

from models.task_sync import TaskSyncMapping, TaskSyncMeta
from storage.db import get_session


class TaskSyncStore:
    """Wrapper around SQLModel session for sync mappings and metadata."""

    def get_mapping(self, local_id: int) -> Optional[TaskSyncMapping]:
        with get_session() as session:
            return session.get(TaskSyncMapping, local_id)

    def get_mapping_by_google(self, google_task_id: str) -> Optional[TaskSyncMapping]:
        if not google_task_id:
            return None
        with get_session() as session:
            stmt = select(TaskSyncMapping).where(TaskSyncMapping.google_task_id == google_task_id)
            return session.exec(stmt).first()

    def list_mappings(self) -> List[TaskSyncMapping]:
        with get_session() as session:
            stmt = select(TaskSyncMapping)
            return list(session.exec(stmt))

    def upsert_mapping(
        self,
        local_id: int,
        *,
        google_task_id: Optional[str],
        tasklist_id: Optional[str],
        etag: Optional[str],
        updated_at_utc: Optional[datetime] = None,
    ) -> TaskSyncMapping:
        updated_at_utc = updated_at_utc or datetime.utcnow()
        with get_session() as session:
            mapping = session.get(TaskSyncMapping, local_id)
            if mapping is None:
                mapping = TaskSyncMapping(
                    local_id=local_id,
                    google_task_id=google_task_id,
                    tasklist_id=tasklist_id,
                    etag=etag,
                    updated_at_utc=updated_at_utc,
                )
            else:
                mapping.google_task_id = google_task_id
                mapping.tasklist_id = tasklist_id
                mapping.etag = etag
                mapping.updated_at_utc = updated_at_utc
            session.add(mapping)
            session.commit()
            session.refresh(mapping)
            return mapping

    def delete_mapping(self, local_id: int) -> None:
        with get_session() as session:
            mapping = session.get(TaskSyncMapping, local_id)
            if mapping:
                session.delete(mapping)
                session.commit()

    def replace_mappings(self, entries: Iterable[TaskSyncMapping]) -> None:
        with get_session() as session:
            existing = session.exec(select(TaskSyncMapping)).all()
            for obj in existing:
                session.delete(obj)
            for entry in entries:
                session.add(entry)
            session.commit()

    # ----- metadata -----
    def get_meta(self) -> TaskSyncMeta:
        with get_session() as session:
            meta = session.get(TaskSyncMeta, 1)
            if meta is None:
                meta = TaskSyncMeta(id=1)
                session.add(meta)
                session.commit()
                session.refresh(meta)
            return meta

    def update_meta(self, **fields) -> TaskSyncMeta:
        with get_session() as session:
            meta = session.get(TaskSyncMeta, 1)
            if meta is None:
                meta = TaskSyncMeta(id=1)
            for key, value in fields.items():
                setattr(meta, key, value)
            session.add(meta)
            session.commit()
            session.refresh(meta)
            return meta

    def max_mapping_updated_at(self) -> Optional[datetime]:
        with get_session() as session:
            stmt = select(func.max(TaskSyncMapping.updated_at_utc))
            return session.exec(stmt).one()


__all__ = ["TaskSyncStore"]

```

### services/tasks.py
```python
# planner/services/tasks.py
from __future__ import annotations

import json
import re
from datetime import datetime, date, timedelta
from typing import Iterable, List, Optional

from sqlmodel import select
from sqlalchemy import and_, or_, case

from storage.db import get_session
from models.task import Task
from core.priorities import normalize_priority
from utils.datetime_utils import ensure_utc, utc_now


class TaskService:
    _listeners = {
        "after_create": set(),
        "after_update": set(),
        "after_delete": set(),
    }

    @classmethod
    def subscribe(cls, event: str, callback):
        if event not in cls._listeners:
            raise ValueError(f"Unsupported event: {event}")
        cls._listeners[event].add(callback)

    @classmethod
    def unsubscribe(cls, event: str, callback):
        if event not in cls._listeners:
            return
        cls._listeners[event].discard(callback)

    @classmethod
    def _emit(cls, event: str, task_id: int):
        listeners = list(cls._listeners.get(event, []))
        for listener in listeners:
            try:
                listener(task_id)
            except Exception:
                pass

    def add(
        self,
        title: str,
        notes: Optional[str] = None,
        start: Optional[datetime] = None,
        duration_minutes: Optional[int] = None,
        priority: int = 0,
        *,
        emit: bool = True,
    ) -> Task:
        with get_session() as s:
            t = Task(
                title=title.strip(),
                notes=notes or None,
                start=ensure_utc(start),
                duration_minutes=duration_minutes or None,
                priority=normalize_priority(priority),
            )
            s.add(t)
            s.commit()
            s.refresh(t)
            if emit:
                try:
                    self._emit("after_create", t.id)
                except Exception:
                    pass
            return t

    def get(self, task_id: int) -> Optional[Task]:
        with get_session() as s:
            return s.get(Task, task_id)

    def update(
        self,
        task_id: int,
        *,
        title: Optional[str] = None,
        notes: Optional[str] = None,
        start: Optional[datetime] = None,
        duration_minutes: Optional[int] = None,
        priority: Optional[int] = None,
        emit: bool = True,
    ) -> Optional[Task]:
        with get_session() as s:
            t = s.get(Task, task_id)
            if not t:
                return None
            if title is not None:
                t.title = title.strip()
            if notes is not None:
                t.notes = notes or None
            if start is not None or start is None:
                t.start = ensure_utc(start)
            if duration_minutes is not None or duration_minutes is None:
                t.duration_minutes = duration_minutes
            if priority is not None:
                t.priority = normalize_priority(priority)
            t.updated_at = utc_now()
            s.add(t)
            s.commit()
            s.refresh(t)
            if emit:
                try:
                    self._emit("after_update", t.id)
                except Exception:
                    pass
            return t

    def set_event_id(self, task_id: int, event_id: Optional[str]):
        with get_session() as s:
            t = s.get(Task, task_id)
            if t:
                t.gcal_event_id = event_id
                t.updated_at = utc_now()
                s.add(t)
                s.commit()

    def set_status(self, task_id: int, status: str):
        with get_session() as s:
            t = s.get(Task, task_id)
            if t:
                t.status = status
                t.updated_at = utc_now()
                s.add(t)
                s.commit()

    def delete(self, task_id: int, *, emit: bool = True):
        with get_session() as s:
            t = s.get(Task, task_id)
            if t:
                if emit:
                    try:
                        self._emit("after_delete", task_id)
                    except Exception:
                        pass
                s.delete(t)
                s.commit()

    def list_for_day(self, d: date) -> Iterable[Task]:
        start = datetime(d.year, d.month, d.day, 0, 0, 0)
        end = start + timedelta(days=1)
        with get_session() as s:
            stmt = (
                select(Task)
                .where(and_(Task.status != "done", Task.start >= start, Task.start < end))
                .order_by(Task.start.asc(), Task.priority.desc(), Task.created_at.desc())
            )
            return list(s.exec(stmt))

    def list_unscheduled(self) -> Iterable[Task]:
        with get_session() as s:
            status_order = case(
                (Task.status == "todo", 0),
                (Task.status == "doing", 1),
                (Task.status == None, 2),  # noqa: E711
                (Task.status == "", 2),
                else_=3,
            )
            stmt = (
                select(Task)
                .where(and_(Task.status != "done", Task.start == None))  # noqa: E711
                .order_by(Task.priority.desc(), status_order, Task.created_at.desc())
            )
            return list(s.exec(stmt))

    def list_unscheduled_updated_since(self, since: Optional[datetime]) -> Iterable[Task]:
        with get_session() as s:
            stmt = select(Task).where(Task.start == None)  # noqa: E711
            if since is not None:
                stmt = stmt.where(Task.updated_at > since)
            stmt = stmt.where(Task.status != "done").order_by(Task.updated_at.desc())
            return list(s.exec(stmt))

    def get_by_event_id(self, gcal_event_id: str | None):
        if not gcal_event_id:
            return None
        with get_session() as s:
            stmt = select(Task).where(Task.gcal_event_id == gcal_event_id)
            return s.exec(stmt).first()

    def get_by_gtasks_id(self, gtasks_id: str | None):
        if not gtasks_id:
            return None
        with get_session() as s:
            stmt = select(Task).where(Task.gtasks_id == gtasks_id)
            return s.exec(stmt).first()

    def create_from_sync(
        self,
        *,
        title: str,
        notes: Optional[str] = None,
        start: Optional[datetime] = None,
        duration_minutes: Optional[int] = None,
        priority: int = 0,
        status: Optional[str] = None,
        gcal_event_id: Optional[str] = None,
        gcal_etag: Optional[str] = None,
        gcal_updated: Optional[datetime] = None,
        gtasks_id: Optional[str] = None,
        gtasks_updated: Optional[datetime] = None,
    ) -> Task:
        with get_session() as s:
            task = Task(
                title=title.strip() or "Задача",
                notes=notes or None,
                start=ensure_utc(start),
                duration_minutes=duration_minutes,
                priority=normalize_priority(priority),
                status=status or "todo",
                gcal_event_id=gcal_event_id,
                gcal_etag=gcal_etag,
                gcal_updated=ensure_utc(gcal_updated),
                gtasks_id=gtasks_id,
                gtasks_updated=ensure_utc(gtasks_updated),
            )
            if task.start is None:
                task.duration_minutes = None
            s.add(task)
            s.commit()
            s.refresh(task)
            return task

    def update_from_sync(
        self,
        task_id: int,
        *,
        updated_at: Optional[datetime] = None,
        **fields,
    ) -> Optional[Task]:
        with get_session() as s:
            task = s.get(Task, task_id)
            if not task:
                return None
            for key, value in fields.items():
                if hasattr(task, key):
                    if isinstance(value, datetime):
                        setattr(task, key, ensure_utc(value))
                    else:
                        setattr(task, key, value)
            if updated_at is not None:
                task.updated_at = ensure_utc(updated_at)
            else:
                task.updated_at = utc_now()
            s.add(task)
            s.commit()
            s.refresh(task)
            return task

    def delete_from_sync(self, task_id: int) -> None:
        self.delete(task_id, emit=False)

    def unschedule(self, task_id: int):
        """Снять расписание и отвязать от Google-события (но задачу не удалять)."""
        with get_session() as s:
            t = s.get(Task, task_id)
            if not t:
                return None
            t.start = None
            t.duration_minutes = None
            t.gcal_event_id = None
            s.add(t)
            s.commit()
            s.refresh(t)
            return t

    # ---------- History & search ----------
    def search_history(
        self,
        *,
        query: str = "",
        start_date: Optional[date] = None,
        end_date: Optional[date] = None,
        status: Optional[str] = None,
        priority: Optional[int] = None,
    ) -> List[Task]:
        """Return tasks filtered by the provided parameters.

        The text search is performed in Python so we can support
        transliteration-aware matching (Cyrillic/Latin/translit).
        """

        with get_session() as s:
            stmt = select(Task)

            if start_date:
                start_dt = datetime(start_date.year, start_date.month, start_date.day, 0, 0, 0)
                stmt = stmt.where(
                    or_(
                        and_(Task.start != None, Task.start >= start_dt),  # noqa: E711
                        and_(Task.start == None, Task.created_at >= start_dt),  # noqa: E711
                    )
                )

            if end_date:
                end_dt = datetime(end_date.year, end_date.month, end_date.day, 23, 59, 59)
                stmt = stmt.where(
                    or_(
                        and_(Task.start != None, Task.start <= end_dt),  # noqa: E711
                        and_(Task.start == None, Task.created_at <= end_dt),  # noqa: E711
                    )
                )

            if status and status not in ("all", ""):
                stmt = stmt.where(Task.status == status)

            if priority is not None and priority >= 0:
                stmt = stmt.where(Task.priority == normalize_priority(priority))

            stmt = stmt.order_by(
                case((Task.start == None, 1), else_=0),  # noqa: E711
                Task.start.desc(),
                Task.updated_at.desc(),
            )

            tasks = list(s.exec(stmt))

        if not query or not query.strip():
            return tasks

        return [t for t in tasks if self._match_query(query, f"{t.title} {t.notes or ''}")]

    # ---------- Metadata helpers ----------
    def clean_notes_metadata(self) -> int:
        """Strip JSON metadata blocks from notes. Returns number of tasks changed."""

        changed = 0
        with get_session() as s:
            stmt = select(Task).where(Task.notes != None)  # noqa: E711
            tasks = list(s.exec(stmt))
            for task in tasks:
                original = task.notes or ""
                cleaned = self._strip_metadata(original)
                if cleaned != original:
                    task.notes = cleaned or None
                    task.updated_at = datetime.utcnow()
                    s.add(task)
                    changed += 1
            if changed:
                s.commit()
        return changed

    def _strip_metadata(self, notes: str) -> str:
        candidate = (notes or "").strip()
        if not candidate:
            return ""

        # Fast path: JSON on a single line
        try:
            parsed = json.loads(candidate)
            if isinstance(parsed, dict):
                user_note = parsed.get("note") or parsed.get("text") or parsed.get("user_notes")
                if isinstance(user_note, str):
                    return user_note.strip()
                return ""
        except Exception:
            pass

        # Remove leading JSON block if present on the first line
        lines = notes.splitlines()
        if lines:
            first = lines[0].strip()
            if first.startswith("{") and first.endswith("}"):
                try:
                    parsed = json.loads(first)
                    rest = "\n".join(lines[1:]).strip()
                    user_note = parsed.get("note") or parsed.get("text") or parsed.get("user_notes")
                    if isinstance(user_note, str):
                        return user_note.strip()
                    return rest
                except Exception:
                    return "\n".join(lines[1:]).strip()
        return notes

    # --- text helpers -------------------------------------------------
    _RE_SPACES = re.compile(r"\s+")
    _RE_ALLOWED = re.compile(r"[^0-9a-zа-яё\s]")

    _RU_TO_LAT = {
        "а": "a",
        "б": "b",
        "в": "v",
        "г": "g",
        "д": "d",
        "е": "e",
        "ё": "yo",
        "ж": "zh",
        "з": "z",
        "и": "i",
        "й": "y",
        "к": "k",
        "л": "l",
        "м": "m",
        "н": "n",
        "о": "o",
        "п": "p",
        "р": "r",
        "с": "s",
        "т": "t",
        "у": "u",
        "ф": "f",
        "х": "kh",
        "ц": "ts",
        "ч": "ch",
        "ш": "sh",
        "щ": "shch",
        "ъ": "",
        "ы": "y",
        "ь": "",
        "э": "e",
        "ю": "yu",
        "я": "ya",
    }

    _LAT_MULTI = [
        ("shch", "щ"),
        ("zh", "ж"),
        ("kh", "х"),
        ("ts", "ц"),
        ("ch", "ч"),
        ("sh", "ш"),
        ("yo", "ё"),
        ("yu", "ю"),
        ("ya", "я"),
        ("ye", "е"),
    ]

    _LAT_SINGLE = {
        "a": "а",
        "b": "б",
        "c": "к",
        "d": "д",
        "e": "е",
        "f": "ф",
        "g": "г",
        "h": "х",
        "i": "и",
        "j": "ж",
        "k": "к",
        "l": "л",
        "m": "м",
        "n": "н",
        "o": "о",
        "p": "п",
        "q": "к",
        "r": "р",
        "s": "с",
        "t": "т",
        "u": "у",
        "v": "в",
        "w": "в",
        "x": "кс",
        "y": "й",
        "z": "з",
    }

    def _normalize_base(self, text: str) -> str:
        cleaned = self._RE_ALLOWED.sub(" ", (text or "").lower())
        cleaned = cleaned.replace("ё", "е")
        return self._RE_SPACES.sub(" ", cleaned).strip()

    def _variants(self, text: str) -> List[str]:
        base = self._normalize_base(text)
        if not base:
            return [""]
        ru_to_lat = self._normalize_base(self._translit_ru_to_lat(base))
        lat_to_ru = self._normalize_base(self._translit_lat_to_ru(base))
        variants = {base}
        if ru_to_lat:
            variants.add(ru_to_lat)
        if lat_to_ru:
            variants.add(lat_to_ru)
        return list(variants)

    def _match_query(self, query: str, haystack: str) -> bool:
        tokens = [tok for tok in self._RE_SPACES.split(self._normalize_base(query)) if tok]
        if not tokens:
            return True
        haystack_variants = self._variants(haystack)
        for token in tokens:
            token_variants = self._variants(token)
            if not any(tv and tv in hv for hv in haystack_variants for tv in token_variants):
                return False
        return True

    def _translit_ru_to_lat(self, text: str) -> str:
        return "".join(self._RU_TO_LAT.get(ch, ch) for ch in text)

    def _translit_lat_to_ru(self, text: str) -> str:
        res: List[str] = []
        i = 0
        while i < len(text):
            matched = False
            for seq, repl in self._LAT_MULTI:
                if text.startswith(seq, i):
                    res.append(repl)
                    i += len(seq)
                    matched = True
                    break
            if matched:
                continue
            ch = text[i]
            res.append(self._LAT_SINGLE.get(ch, ch))
            i += 1
        return "".join(res)

```

### services/tasks_bridge.py
```python
"""Google Tasks bridge for synchronizing undated Planner tasks."""
from __future__ import annotations

import json
import time
from datetime import datetime, timezone
from typing import Any, Callable, Dict, Iterable, Optional, Tuple

from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

from core.settings import GOOGLE_SYNC

try:  # pragma: no cover - optional dependency when running tests without Google SDK
    from google.oauth2.credentials import Credentials
except Exception:  # pragma: no cover
    Credentials = None

DEFAULT_SCOPES = list(GOOGLE_SYNC.scopes)
_RETRYABLE_STATUS = {429, 500, 502, 503, 504}
_MAX_RETRIES = 5
_INITIAL_BACKOFF = 1.0
_MAX_BACKOFF = 32.0
_TASKLIST_TITLE = "Planner Inbox"


def _ensure_datetime(value: Any) -> Optional[str]:
    if value is None:
        return None
    if isinstance(value, datetime):
        if value.tzinfo is None:
            value = value.replace(tzinfo=timezone.utc)
        else:
            value = value.astimezone(timezone.utc)
        return value.isoformat()
    return str(value)


def _path_exists(path: Any) -> bool:
    try:
        import os

        return os.path.exists(os.fspath(path))
    except Exception:
        return False


def _find_creds_in_auth(auth: Any, scopes: Optional[Iterable[str]] = None):
    for name in ("get_credentials", "credentials", "creds"):
        val = getattr(auth, name, None)
        if callable(val):
            try:
                val = val()
            except Exception:
                val = None
        if val is not None and hasattr(val, "valid"):
            return val

    token_path = None
    for attr in ("token_path", "token_file", "token", "token_json"):
        pth = getattr(auth, attr, None)
        if pth and _path_exists(pth):
            token_path = pth
            break

    if token_path and Credentials:
        try:
            return Credentials.from_authorized_user_file(token_path, scopes or DEFAULT_SCOPES)
        except Exception:
            return None
    return None


def _build_service(creds: Any):
    if creds is None:
        return None
    return build("tasks", "v1", credentials=creds)


def _split_notes(raw_notes: Optional[str]) -> Tuple[Dict[str, Any], str, bool]:
    if not raw_notes:
        return {}, "", False

    original = raw_notes or ""
    stripped = original.lstrip()
    leading = original[: len(original) - len(stripped)]
    decoder = json.JSONDecoder()
    try:
        parsed, offset = decoder.raw_decode(stripped)
        if isinstance(parsed, dict):
            remainder = stripped[offset:]
            cleaned = (leading + remainder).lstrip("\r\n")
            return parsed, cleaned.strip(), True
    except json.JSONDecodeError:
        pass

    if "\"task_id\"" in original:
        try:
            start = original.index("{")
            end = original.rindex("}") + 1
            parsed = json.loads(original[start:end])
            if isinstance(parsed, dict):
                cleaned = (original[:start] + original[end:]).lstrip("\r\n")
                return parsed, cleaned.strip(), True
        except (ValueError, json.JSONDecodeError):
            pass

    return {}, original.strip(), False


def _parse_timestamp(value: Any) -> Optional[datetime]:
    if not value:
        return None
    try:
        text = str(value).replace("Z", "+00:00")
        parsed = datetime.fromisoformat(text)
        if parsed.tzinfo is None:
            parsed = parsed.replace(tzinfo=timezone.utc)
        return parsed
    except Exception:
        return None


def _status_payload(local_task: Dict[str, Any]) -> Tuple[str, Optional[str]]:
    status = str(local_task.get("status") or "").lower()
    if status == "done":
        completed_at = _ensure_datetime(local_task.get("updated_at")) or datetime.now(timezone.utc).isoformat()
        return "completed", completed_at
    return "needsAction", None


class GoogleTasksBridge:
    """Lightweight wrapper over Google Tasks API with retry/backoff."""

    def __init__(self, auth: Any):
        self.auth = auth
        self.service = None
        self._maybe_build_service()

    @property
    def tasklist_title(self) -> str:
        return _TASKLIST_TITLE

    # ----- public API -----
    def ensure_tasklist(self) -> str:
        self._maybe_build_service(strict=True)
        page_token = None
        while True:
            response = self._call_with_backoff(
                self.service.tasklists().list,
                maxResults=100,
                pageToken=page_token,
            )
            for item in response.get("items", []):
                if (item.get("title") or "").strip().lower() == self.tasklist_title.lower():
                    return item.get("id")
            page_token = response.get("nextPageToken")
            if not page_token:
                break

        created = self._call_with_backoff(
            self.service.tasklists().insert,
            body={"title": self.tasklist_title},
        )
        return created.get("id")

    def fetch_all(self, tasklist_id: str) -> list[Dict[str, Any]]:
        self._maybe_build_service(strict=True)
        page_token = None
        results: list[Dict[str, Any]] = []
        while True:
            response = self._call_with_backoff(
                self.service.tasks().list,
                tasklist=tasklist_id,
                maxResults=100,
                showCompleted=True,
                showDeleted=False,
                pageToken=page_token,
            )
            for item in response.get("items", []):
                if item.get("deleted"):
                    continue
                raw_notes = item.get("notes") or ""
                meta_from_notes, body, had_meta = _split_notes(raw_notes)
                timestamp = _parse_timestamp(item.get("updated"))
                if had_meta and raw_notes.strip() != body:
                    try:
                        self._call_with_backoff(
                            self.service.tasks().patch,
                            tasklist=tasklist_id,
                            task=item.get("id"),
                            body={"notes": body},
                        )
                    except Exception:
                        pass
                info = {
                    "id": item.get("id"),
                    "title": item.get("title") or "",
                    "notes": body,
                    "metadata": {},
                    "detected_meta": meta_from_notes,
                    "updated": item.get("updated"),
                    "status": item.get("status"),
                    "raw": item,
                }
                results.append(info)
            page_token = response.get("nextPageToken")
            if not page_token:
                break
        return results

    def find_task_by_local_id(self, tasklist_id: str, local_task_id: str) -> Optional[Dict[str, Any]]:
        for item in self.fetch_all(tasklist_id):
            metadata = item.get("metadata") or {}
            if str(metadata.get("task_id")) == str(local_task_id):
                return item
        return None

    def upsert_task(self, tasklist_id: str, local_task: Dict[str, Any]) -> str:
        if not local_task.get("task_id"):
            raise ValueError("local_task must contain task_id")
        self._maybe_build_service(strict=True)

        gtask_id = local_task.get("gtask_id")
        if not gtask_id:
            existing = self.find_task_by_local_id(tasklist_id, str(local_task["task_id"]))
            if existing:
                gtask_id = existing.get("id")

        notes = (local_task.get("notes") or "").strip()
        status, completed_ts = _status_payload(local_task)
        payload = {
            "title": local_task.get("title") or "",
            "notes": notes,
            "status": status,
        }
        if completed_ts:
            payload["completed"] = completed_ts
        elif gtask_id:
            # Explicitly clear "completed" if task switches back to needsAction
            payload["completed"] = None

        if gtask_id:
            payload["id"] = gtask_id
            response = self._call_with_backoff(
                self.service.tasks().update,
                tasklist=tasklist_id,
                task=gtask_id,
                body=payload,
            )
        else:
            response = self._call_with_backoff(
                self.service.tasks().insert,
                tasklist=tasklist_id,
                body=payload,
            )

        return response.get("id")

    def delete_task(self, tasklist_id: str, gtask_id: str) -> None:
        if not gtask_id:
            return
        self._maybe_build_service(strict=True)
        try:
            self._call_with_backoff(
                self.service.tasks().delete,
                tasklist=tasklist_id,
                task=gtask_id,
            )
        except HttpError as exc:
            status = getattr(getattr(exc, "resp", None), "status", None)
            if status == 404:
                return
            raise

    # ----- internal helpers -----
    def _maybe_build_service(self, strict: bool = False) -> None:
        if self.service is not None:
            return
        creds = _find_creds_in_auth(self.auth, DEFAULT_SCOPES)
        if creds and getattr(creds, "valid", False):
            self.service = _build_service(creds)
        elif strict:
            raise RuntimeError("GoogleTasksBridge: credentials are unavailable")

    def _call_with_backoff(self, method: Callable[..., Any], **kwargs) -> Dict[str, Any]:
        delay = _INITIAL_BACKOFF
        last_error: Optional[Exception] = None
        for attempt in range(_MAX_RETRIES):
            try:
                request = method(**kwargs)
                return request.execute()
            except HttpError as exc:
                last_error = exc
                status = getattr(getattr(exc, "resp", None), "status", None)
                if status not in _RETRYABLE_STATUS or attempt == _MAX_RETRIES - 1:
                    raise
            except Exception as exc:  # pragma: no cover - defensive fallback
                last_error = exc
                if attempt == _MAX_RETRIES - 1:
                    raise
            time.sleep(delay)
            delay = min(delay * 2, _MAX_BACKOFF)
        if last_error:
            raise last_error
        return {}


__all__ = ["GoogleTasksBridge"]

```

### services/undated_tasks_sync.py
```python
"""Synchronization of undated Planner tasks with Google Tasks."""
from __future__ import annotations

import copy
from dataclasses import dataclass
from datetime import datetime, timezone
from typing import Dict, Iterable, Optional

from sqlmodel import select

from core.priorities import DEFAULT_PRIORITY, normalize_priority
from core.settings import GOOGLE_SYNC
from models import SyncMapUndated, Task
from services.appdata import AppDataClient
from services.tasks_bridge import GoogleTasksBridge
from storage.db import get_session
from storage.device import get_device_id


def _utcnow() -> datetime:
    return datetime.now(timezone.utc)


def _isoformat(value: Optional[datetime]) -> str:
    if value is None:
        value = _utcnow()
    if value.tzinfo is None:
        value = value.replace(tzinfo=timezone.utc)
    return value.isoformat()


def _parse_google_timestamp(value: Optional[str]) -> Optional[datetime]:
    if not value:
        return None
    try:
        parsed = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
        if parsed.tzinfo is None:
            parsed = parsed.replace(tzinfo=timezone.utc)
        return parsed
    except Exception:
        return None


def _parse_meta_timestamp(value: Optional[str]) -> Optional[datetime]:
    if not value:
        return None
    try:
        parsed = datetime.fromisoformat(str(value).replace("Z", "+00:00"))
        if parsed.tzinfo is None:
            parsed = parsed.replace(tzinfo=timezone.utc)
        return parsed
    except Exception:
        return None


def _normalise_status(value: Optional[str], fallback: str = "todo") -> str:
    if not value:
        return fallback
    lowered = str(value).strip().lower()
    if lowered in {"todo", "doing", "done"}:
        return lowered
    if lowered in {"completed", "complete", "finished"}:
        return "done"
    if lowered in {"needsaction", "needs_action"}:
        return "todo"
    return fallback


def _normalise_priority(value: Optional[int]) -> int:
    if value is None:
        return DEFAULT_PRIORITY
    try:
        return normalize_priority(int(value))
    except Exception:
        return DEFAULT_PRIORITY


@dataclass
class _SyncResult:
    pulled: bool = False
    pushed: bool = False

    def changed(self) -> bool:
        return self.pulled or self.pushed


class UndatedTasksSync:
    """Encapsulates Google Tasks synchronisation for undated Planner tasks."""

    def __init__(
        self,
        auth,
        *,
        bridge: GoogleTasksBridge | None = None,
        session_factory=get_session,
        appdata: AppDataClient | None = None,
        device_id: Optional[str] = None,
    ) -> None:
        self.auth = auth
        self.bridge = bridge or GoogleTasksBridge(auth)
        self.appdata = appdata or AppDataClient(auth)
        self._session_factory = session_factory
        self.device_id = device_id or get_device_id()

        self._tasklist_id: Optional[str] = None
        self._config_cache: Optional[Dict[str, object]] = None
        self._config_etag: Optional[str] = None
        self._index_cache: Optional[Dict[str, object]] = None
        self._index_etag: Optional[str] = None
        self._index_dirty = False

    # ----- public helpers -----
    @property
    def tasklist_title(self) -> str:
        return self.bridge.tasklist_title if self.bridge else "Planner Inbox"

    def status_text(self) -> str:
        if not GOOGLE_SYNC.enabled:
            return "Tasks: синхронизация отключена"
        if not self.bridge:
            return "Tasks: недоступны"
        tasklist_id = self._tasklist_id or self._load_config().get("tasklist_id")
        if not tasklist_id:
            return "Tasks: не подключено"
        return f"Tasks: подключено, список: {self.tasklist_title}"

    def reset_cache(self) -> None:
        self._tasklist_id = None
        self._config_cache = None
        self._config_etag = None
        self._index_cache = None
        self._index_etag = None
        self._index_dirty = False

    def sync(self) -> bool:
        result = _SyncResult()
        result.pulled = self.pull()
        result.pushed = self.push_dirty()
        return result.changed()

    # ----- high level operations -----
    def pull(self) -> bool:
        if not self._can_sync():
            return False

        tasklist_id = self._ensure_tasklist_id()
        if not tasklist_id:
            return False

        try:
            remote_tasks = self.bridge.fetch_all(tasklist_id)
        except Exception:
            return False

        index = self._get_index()
        changed = False
        now = datetime.utcnow()

        with self._session_factory() as session:
            mappings = {
                (mapping.gtask_id or ""): mapping
                for mapping in session.exec(
                    select(SyncMapUndated).where(SyncMapUndated.tasklist_id == tasklist_id)
                ).all()
            }

            for item in remote_tasks:
                gtask_id = item.get("id")
                if not gtask_id:
                    continue

                entry = self._ensure_index_entry(gtask_id, allow_create=True)
                detected_meta = item.get("detected_meta") or {}
                self._merge_detected_meta(entry, detected_meta, item)

                mapping = mappings.get(gtask_id)
                local_task = None
                if mapping:
                    local_task = self._load_task(session, mapping.task_id)

                if local_task is None and entry.get("task_id"):
                    local_task = self._load_task(session, entry.get("task_id"))

                if local_task is None:
                    local_task = self._create_local_task_from_remote(session, item, entry)
                    session.flush()
                    mapping = SyncMapUndated(
                        task_id=str(local_task.id),
                        gtask_id=gtask_id,
                        tasklist_id=tasklist_id,
                        dirty_flag=0,
                        updated_at_utc=_utcnow(),
                    )
                    session.add(mapping)
                    mappings[gtask_id] = mapping
                    changed = True
                else:
                    if not mapping:
                        mapping = SyncMapUndated(
                            task_id=str(local_task.id),
                            gtask_id=gtask_id,
                            tasklist_id=tasklist_id,
                            dirty_flag=0,
                            updated_at_utc=_utcnow(),
                        )
                        session.add(mapping)
                        mappings[gtask_id] = mapping

                    if not mapping.dirty_flag:
                        if self._apply_remote_payload(local_task, item):
                            changed = True
                    mapping.updated_at_utc = _utcnow()
                    session.add(mapping)

                if self._apply_meta_to_task(local_task, entry, item):
                    changed = True

                if entry.get("task_id") != str(local_task.id):
                    entry["task_id"] = str(local_task.id)
                    self._index_dirty = True

                session.add(local_task)

            session.commit()

        if changed:
            self._persist_index_if_dirty()
            self._update_last_sync()
        else:
            # We may still have cleaned up metadata from migration.
            self._persist_index_if_dirty()
        return changed

    def push_dirty(self) -> bool:
        if not self._can_sync():
            return False

        tasklist_id = self._ensure_tasklist_id()
        if not tasklist_id:
            return False

        index = self._get_index()
        changed = False

        with self._session_factory() as session:
            tasks: Iterable[Task] = session.exec(
                select(Task).where(Task.start == None)  # noqa: E711
            ).all()

            for task in tasks:
                mapping = session.get(SyncMapUndated, str(task.id))
                if mapping is None:
                    mapping = SyncMapUndated(
                        task_id=str(task.id),
                        gtask_id=None,
                        tasklist_id=tasklist_id,
                        dirty_flag=1,
                        updated_at_utc=_utcnow(),
                    )
                elif mapping.tasklist_id != tasklist_id:
                    mapping.tasklist_id = tasklist_id

                entry = None
                if mapping.gtask_id:
                    entry = index["tasks"].get(mapping.gtask_id)

                if not mapping.dirty_flag and mapping.gtask_id:
                    continue

                payload = {
                    "gtask_id": mapping.gtask_id,
                    "title": task.title,
                    "notes": task.notes,
                    "status": task.status,
                    "updated_at": task.updated_at,
                }

                try:
                    gtask_id = self.bridge.upsert_task(tasklist_id, payload)
                except Exception:
                    continue

                if mapping.gtask_id and mapping.gtask_id != gtask_id:
                    index["tasks"].pop(mapping.gtask_id, None)
                    self._index_dirty = True

                mapping.gtask_id = gtask_id
                mapping.dirty_flag = 0
                mapping.updated_at_utc = _utcnow()
                session.add(mapping)

                entry = self._ensure_index_entry(gtask_id, allow_create=True)
                entry["task_id"] = str(task.id)
                entry["priority"] = _normalise_priority(task.priority)
                entry["status"] = _normalise_status(task.status)
                entry["updated_at"] = _isoformat(None)
                entry["device_id"] = self.device_id
                index["tasks"][gtask_id] = entry
                self._index_dirty = True
                changed = True

            session.commit()

        if changed:
            self._persist_index_if_dirty()
        else:
            self._persist_index_if_dirty()
        return changed

    def mark_dirty(self, task_id: int) -> None:
        if not GOOGLE_SYNC.enabled:
            return

        gtask_id = None
        task_snapshot: Optional[Task] = None

        with self._session_factory() as session:
            task = session.get(Task, task_id)
            if not task:
                return
            task_snapshot = copy.copy(task)

            mapping = session.get(SyncMapUndated, str(task_id))
            if mapping is None:
                mapping = SyncMapUndated(
                    task_id=str(task_id),
                    gtask_id=None,
                    tasklist_id=self._tasklist_id or "",
                    dirty_flag=1,
                    updated_at_utc=_utcnow(),
                )
            else:
                mapping.dirty_flag = 1
                mapping.updated_at_utc = _utcnow()
            gtask_id = mapping.gtask_id
            session.add(mapping)
            session.commit()

        if gtask_id and task_snapshot:
            entry = self._ensure_index_entry(gtask_id, allow_create=True)
            entry["task_id"] = str(task_snapshot.id)
            entry["priority"] = _normalise_priority(task_snapshot.priority)
            entry["status"] = _normalise_status(task_snapshot.status)
            entry["updated_at"] = _isoformat(None)
            entry["device_id"] = self.device_id
            self._index_dirty = True
            self._persist_index_if_dirty()

    def remove_mapping(self, task_id: int, *, delete_remote: bool = False) -> None:
        gtask_id = None
        tasklist_id = None

        with self._session_factory() as session:
            mapping = session.get(SyncMapUndated, str(task_id))
            if not mapping:
                return
            gtask_id = mapping.gtask_id
            tasklist_id = mapping.tasklist_id or self._tasklist_id
            session.delete(mapping)
            session.commit()

        if gtask_id:
            index = self._get_index()
            if gtask_id in index["tasks"]:
                index["tasks"].pop(gtask_id, None)
                self._index_dirty = True
                self._persist_index_if_dirty()

        if delete_remote and gtask_id and tasklist_id:
            try:
                self.bridge.delete_task(tasklist_id, gtask_id)
            except Exception:
                pass

    # ----- internal helpers -----
    def _can_sync(self) -> bool:
        return GOOGLE_SYNC.enabled and self.bridge is not None

    def _ensure_tasklist_id(self) -> Optional[str]:
        if self._tasklist_id:
            return self._tasklist_id
        if not self.bridge:
            return None

        try:
            if hasattr(self.auth, "ensure_credentials"):
                self.auth.ensure_credentials()
        except Exception:
            return None

        try:
            self.appdata.ensure_files()
            config = self._load_config()
            tasklist_id = config.get("tasklist_id")
            if not tasklist_id:
                tasklist_id = self.bridge.ensure_tasklist()

                def mutator(payload: Dict[str, object]) -> Dict[str, object]:
                    payload = self._normalise_config(payload)
                    payload["tasklist_id"] = tasklist_id
                    return payload

                self._update_config(mutator)

            self._tasklist_id = tasklist_id
            index = self._get_index()
            if index.get("tasklist_id") != tasklist_id:
                index["tasklist_id"] = tasklist_id
                self._index_dirty = True
                self._persist_index_if_dirty()
            return self._tasklist_id
        except Exception:
            self._tasklist_id = None
            return None

    def _load_config(self) -> Dict[str, object]:
        if self._config_cache is None:
            payload, etag = self.appdata.read_config()
            self._config_cache = self._normalise_config(payload)
            self._config_etag = etag
        return self._config_cache

    def _update_config(self, mutator) -> Dict[str, object]:
        base = copy.deepcopy(self._load_config())
        updated = mutator(base)
        result, etag = self.appdata.write_config(
            updated,
            if_match=self._config_etag,
            on_conflict=lambda remote: mutator(self._normalise_config(remote)),
        )
        self._config_cache = self._normalise_config(result)
        self._config_etag = etag
        return self._config_cache

    def _get_index(self) -> Dict[str, object]:
        if self._index_cache is None:
            payload, etag = self.appdata.read_index()
            self._index_cache = self._normalise_index(payload)
            self._index_etag = etag
        return self._index_cache

    def _persist_index_if_dirty(self) -> None:
        if not self._index_dirty or self._index_cache is None:
            return

        payload = copy.deepcopy(self._index_cache)
        result, etag = self.appdata.write_index(
            payload,
            if_match=self._index_etag,
            on_conflict=lambda remote: self._merge_index_payload(remote, payload),
        )
        self._index_cache = self._normalise_index(result)
        self._index_etag = etag
        self._index_dirty = False

    def _merge_index_payload(self, remote_payload, local_payload) -> Dict[str, object]:
        remote = self._normalise_index(remote_payload)
        local = self._normalise_index(local_payload)

        merged = copy.deepcopy(remote)
        merged["version"] = local.get("version", remote.get("version", 1))
        if local.get("tasklist_id"):
            merged["tasklist_id"] = local.get("tasklist_id")

        remote_tasks = remote.get("tasks", {})
        local_tasks = local.get("tasks", {})
        result_tasks: Dict[str, Dict[str, object]] = dict(remote_tasks)

        for gtask_id, local_entry in local_tasks.items():
            resolved = self._resolve_meta_entry(local_entry, remote_tasks.get(gtask_id))
            if resolved is None:
                result_tasks.pop(gtask_id, None)
            else:
                result_tasks[gtask_id] = resolved

        merged["tasks"] = result_tasks
        return merged

    def _resolve_meta_entry(self, local_entry, remote_entry):
        if local_entry is None and remote_entry is None:
            return None
        if remote_entry is None:
            return self._normalise_meta(local_entry)
        if local_entry is None:
            return self._normalise_meta(remote_entry)

        local_norm = self._normalise_meta(local_entry)
        remote_norm = self._normalise_meta(remote_entry)

        local_ts = _parse_meta_timestamp(local_norm.get("updated_at"))
        remote_ts = _parse_meta_timestamp(remote_norm.get("updated_at"))

        if local_ts and remote_ts:
            if local_ts > remote_ts:
                return local_norm
            if remote_ts > local_ts:
                return remote_norm
        elif local_ts:
            return local_norm
        elif remote_ts:
            return remote_norm

        local_device = str(local_norm.get("device_id", ""))
        remote_device = str(remote_norm.get("device_id", ""))
        if local_device > remote_device:
            return local_norm
        if remote_device > local_device:
            return remote_norm
        return local_norm

    def _normalise_meta(self, entry) -> Dict[str, object]:
        data = dict(entry or {})
        data.setdefault("task_id", None)
        data["priority"] = _normalise_priority(data.get("priority"))
        data["status"] = _normalise_status(data.get("status"))
        if not data.get("updated_at"):
            data["updated_at"] = _isoformat(None)
        if not data.get("device_id"):
            data["device_id"] = self.device_id
        return data

    def _normalise_config(self, payload) -> Dict[str, object]:
        data = dict(payload or {})
        data.setdefault("version", 1)
        data.setdefault("tasklist_id", None)
        data.setdefault("last_full_sync", None)
        return data

    def _normalise_index(self, payload) -> Dict[str, object]:
        data = dict(payload or {})
        data.setdefault("version", 1)
        data.setdefault("tasklist_id", None)
        tasks = data.get("tasks") or {}
        if not isinstance(tasks, dict):
            tasks = {}
        data["tasks"] = tasks
        return data

    def _ensure_index_entry(self, gtask_id: str, *, allow_create: bool) -> Dict[str, object]:
        index = self._get_index()
        tasks = index.setdefault("tasks", {})
        entry = tasks.get(gtask_id)
        if entry is None and allow_create:
            entry = {
                "task_id": None,
                "priority": DEFAULT_PRIORITY,
                "status": "todo",
                "updated_at": _isoformat(None),
                "device_id": self.device_id,
            }
            tasks[gtask_id] = entry
            self._index_dirty = True
        elif entry is None:
            entry = {}
        return entry

    def _merge_detected_meta(self, entry: Dict[str, object], detected: Dict[str, object], item) -> None:
        if not detected:
            return
        changed = False
        for key in ("task_id", "priority", "status", "updated_at", "device_id"):
            if key not in detected or detected[key] in (None, ""):
                continue
            if entry.get(key) != detected[key]:
                entry[key] = detected[key]
                changed = True
        if changed:
            if not entry.get("updated_at"):
                entry["updated_at"] = detected.get("updated_at") or item.get("updated") or _isoformat(None)
            if not entry.get("device_id"):
                entry["device_id"] = detected.get("device_id") or self.device_id
            self._index_dirty = True

    def _create_local_task_from_remote(self, session, item, entry: Dict[str, object]) -> Task:
        status = _normalise_status(entry.get("status"), _status_from_google(item.get("status")))
        priority = _normalise_priority(entry.get("priority"))
        notes = item.get("notes") or ""
        task = Task(
            title=item.get("title") or "",
            notes=notes or None,
            start=None,
            priority=priority,
            status=status,
        )
        session.add(task)
        return task

    def _apply_remote_payload(self, task: Task, item) -> bool:
        changed = False
        remote_title = item.get("title") or ""
        remote_notes = item.get("notes") or ""
        remote_updated = _parse_google_timestamp(item.get("updated"))
        local_updated = task.updated_at
        if local_updated and local_updated.tzinfo is None:
            local_updated = local_updated.replace(tzinfo=timezone.utc)

        should_update = True
        if remote_updated and local_updated:
            should_update = remote_updated >= local_updated

        if should_update:
            if task.title != remote_title:
                task.title = remote_title
                changed = True
            if (task.notes or "") != remote_notes:
                task.notes = remote_notes or None
                changed = True
            if changed:
                task.updated_at = datetime.utcnow()
        return changed

    def _apply_meta_to_task(self, task: Task, entry: Dict[str, object], item) -> bool:
        changed = False
        remote_status = _status_from_google(item.get("status"))
        status = "done" if remote_status == "done" else _normalise_status(entry.get("status"), remote_status)
        priority = _normalise_priority(entry.get("priority"))

        meta_ts = _parse_meta_timestamp(entry.get("updated_at"))
        remote_ts = _parse_google_timestamp(item.get("updated"))
        if remote_status != "done" and status == "done" and remote_ts and meta_ts:
            if remote_ts > meta_ts:
                status = remote_status

        if task.status != status:
            task.status = status
            changed = True
        if task.priority != priority:
            task.priority = priority
            changed = True
        if changed:
            task.updated_at = datetime.utcnow()
        return changed

    def _load_task(self, session, task_id: Optional[str]) -> Optional[Task]:
        if not task_id:
            return None
        try:
            numeric = int(task_id)
        except (TypeError, ValueError):
            return None
        return session.get(Task, numeric)

    def _update_last_sync(self) -> None:
        def mutator(data: Dict[str, object]) -> Dict[str, object]:
            data = self._normalise_config(data)
            data["last_full_sync"] = _isoformat(None)
            return data

        self._update_config(mutator)


def _status_from_google(value: Optional[str]) -> str:
    return "done" if str(value or "").lower() == "completed" else "todo"


__all__ = ["UndatedTasksSync"]


```

### storage/__init__.py
```python

```

### storage/backup.py
```python
"""Utilities for SQLite backups."""
from __future__ import annotations

from datetime import datetime, timedelta
from pathlib import Path
from shutil import copy2


def _parse_backup_date(path: Path, prefix: str) -> datetime | None:
    stem = path.stem
    if not stem.startswith(prefix):
        return None
    date_part = stem[len(prefix) :]
    try:
        return datetime.strptime(date_part, "%Y-%m-%d")
    except ValueError:
        return None


def ensure_daily_backup(
    db_path: str | Path,
    backup_dir: str | Path,
    *,
    keep_days: int = 7,
) -> Path | None:
    """Create a dated SQLite backup and rotate old copies."""

    db_file = Path(db_path)
    if not db_file.exists():
        return None

    backups = Path(backup_dir)
    backups.mkdir(parents=True, exist_ok=True)

    today = datetime.now().date()
    prefix = f"{db_file.stem}_"
    backup_name = f"{prefix}{today.strftime('%Y-%m-%d')}{db_file.suffix}"
    destination = backups / backup_name

    created_path: Path | None = None
    if not destination.exists():
        copy2(db_file, destination)
        created_path = destination

    if keep_days > 0:
        cutoff = today - timedelta(days=keep_days - 1)
        for file in backups.glob(f"{db_file.stem}_*{db_file.suffix}"):
            backup_date = _parse_backup_date(file, prefix)
            if backup_date and backup_date.date() < cutoff:
                try:
                    file.unlink()
                except OSError:
                    pass

    return created_path


__all__ = ["ensure_daily_backup"]

```

### storage/db.py
```python
# planner/storage/db.py
from sqlmodel import SQLModel, create_engine, Session

from core.settings import DB_PATH, BACKUP
from storage.backup import ensure_daily_backup

# Ensure SQLModel metadata is populated
import models.task  # noqa: F401
import models.pending_op  # noqa: F401
import models.tag  # noqa: F401
from storage import migrations


_engine = create_engine(f"sqlite:///{DB_PATH.as_posix()}", echo=False)


def init_db():
    DB_PATH.parent.mkdir(parents=True, exist_ok=True)
    SQLModel.metadata.create_all(_engine)
    migrations.run_all(_engine)
    if BACKUP.enabled:
        ensure_daily_backup(DB_PATH, BACKUP.directory, keep_days=BACKUP.keep_days)


def get_engine():
    return _engine


def get_session() -> Session:
    return Session(_engine)

```

### storage/device.py
```python
"""Helpers for generating and storing a stable device identifier."""
from __future__ import annotations

import os
import uuid
from pathlib import Path

from core.settings import DATA_DIR


_DEVICE_ID_PATH = DATA_DIR / "device_id.txt"


def _ensure_parent(path: Path) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)


def _read_existing(path: Path) -> str | None:
    try:
        if path.exists():
            value = path.read_text(encoding="utf-8").strip()
            if value:
                return value
    except OSError:
        return None
    return None


def _write_value(path: Path, value: str) -> None:
    tmp = path.with_suffix(".tmp")
    _ensure_parent(path)
    try:
        tmp.write_text(value, encoding="utf-8")
        os.replace(tmp, path)
    finally:
        if tmp.exists():
            try:
                tmp.unlink()
            except OSError:
                pass


def get_device_id() -> str:
    """Return a deterministic identifier for the current installation."""

    existing = _read_existing(_DEVICE_ID_PATH)
    if existing:
        return existing

    new_id = uuid.uuid4().hex.upper()
    try:
        _write_value(_DEVICE_ID_PATH, new_id)
    except OSError:
        # Best effort: even if we fail to persist, still return the value so the
        # caller can continue working. A new identifier will be generated next
        # time.
        return new_id
    return new_id


__all__ = ["get_device_id"]


```

### storage/migrations.py
```python
"""Ad-hoc database migrations for Planner."""

from __future__ import annotations

from sqlalchemy import text


def _column_exists(conn, table: str, column: str) -> bool:
    result = conn.execute(text(f"PRAGMA table_info('{table}')"))
    return any(row[1] == column for row in result)


def ensure_task_columns(conn) -> None:
    columns = {
        "gcal_event_id": "TEXT",
        "gcal_etag": "TEXT",
        "gcal_updated": "TEXT",
        "gtasks_id": "TEXT",
        "gtasks_updated": "TEXT",
    }
    for name, ddl_type in columns.items():
        if not _column_exists(conn, "task", name):
            conn.execute(text(f"ALTER TABLE task ADD COLUMN {name} {ddl_type}"))

    if _column_exists(conn, "task", "gcal_updated_utc"):
        conn.execute(
            text(
                """
                UPDATE task
                SET gcal_updated = COALESCE(gcal_updated, gcal_updated_utc)
                WHERE gcal_updated_utc IS NOT NULL
                """
            )
        )


def ensure_pending_ops_table(conn) -> None:
    conn.execute(
        text(
            """
            CREATE TABLE IF NOT EXISTS pendingop (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                op TEXT NOT NULL,
                task_id INTEGER NOT NULL,
                payload TEXT NOT NULL,
                attempts INTEGER NOT NULL DEFAULT 0,
                last_error TEXT,
                created_at TEXT NOT NULL,
                next_try_at TEXT NOT NULL
            )
            """
        )
    )
    conn.execute(
        text(
            """
            CREATE INDEX IF NOT EXISTS ix_pendingop_next_try_at
            ON pendingop (next_try_at)
            """
        )
    )


def ensure_task_uid(conn) -> None:
    if not _column_exists(conn, "task", "uid"):
        conn.execute(text("ALTER TABLE task ADD COLUMN uid TEXT"))
    conn.execute(
        text(
            """
            UPDATE task
            SET uid = lower(hex(randomblob(4)))||'-'||lower(hex(randomblob(2)))||'-'||lower(hex(randomblob(2)))||'-'||lower(hex(randomblob(2)))||'-'||lower(hex(randomblob(6)))
            WHERE uid IS NULL OR uid=''
            """
        )
    )
    conn.execute(text("CREATE UNIQUE INDEX IF NOT EXISTS ux_task_uid ON task(uid)"))


def ensure_tag_tables(conn) -> None:
    conn.execute(
        text(
            """
            CREATE TABLE IF NOT EXISTS tags (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL UNIQUE,
                color_hex TEXT NOT NULL,
                created_at TEXT NOT NULL,
                updated_at TEXT NOT NULL
            )
            """
        )
    )
    conn.execute(
        text(
            """
            CREATE TABLE IF NOT EXISTS task_tags (
                task_id INTEGER NOT NULL REFERENCES task(id) ON DELETE CASCADE,
                tag_id INTEGER NOT NULL REFERENCES tags(id) ON DELETE CASCADE,
                PRIMARY KEY (task_id, tag_id)
            )
            """
        )
    )
    conn.execute(text("CREATE INDEX IF NOT EXISTS ix_task_tags_task ON task_tags(task_id)"))
    conn.execute(text("CREATE INDEX IF NOT EXISTS ix_task_tags_tag ON task_tags(tag_id)"))


def run_all(engine) -> None:
    with engine.begin() as conn:
        ensure_task_columns(conn)
        ensure_task_uid(conn)
        ensure_tag_tables(conn)
        # SQLModel creates the pendingop table, but ensure indexes exist in legacy DBs
        ensure_pending_ops_table(conn)


__all__ = ["run_all"]

```

### storage/store.py
```python
"""Local metadata store for task synchronization."""
from __future__ import annotations

import json
from datetime import datetime, timezone
from typing import Any, Callable, Dict, Iterable, Optional

from sqlmodel import Field, SQLModel, Session, create_engine, select

from core.settings import STORE_DB_PATH


def _utcnow() -> datetime:
    return datetime.now(timezone.utc)


class ListRecord(SQLModel, table=True):
    """Representation of a remote list stored locally."""

    list_id: str = Field(primary_key=True)
    name: Optional[str] = None
    backend: Optional[str] = None
    last_sync: Optional[datetime] = None


class TaskMetadata(SQLModel, table=True):
    """Persisted service metadata for a remote task."""

    remote_task_id: str = Field(primary_key=True)
    list_id: str = Field(primary_key=True)
    meta_json: Optional[str] = None
    updated_at: datetime = Field(default_factory=_utcnow)


class SyncState(SQLModel, table=True):
    """Version information for synchronised entities."""

    entity_type: str = Field(primary_key=True)
    entity_id: str = Field(primary_key=True)
    version: Optional[str] = None
    last_pulled: Optional[datetime] = None
    last_pushed: Optional[datetime] = None


STORE_TABLES = [ListRecord.__table__, TaskMetadata.__table__, SyncState.__table__]

_store_engine = None


def get_store_engine():
    """Return (and lazily create) the SQLAlchemy engine for the metadata store."""

    global _store_engine
    if _store_engine is None:
        STORE_DB_PATH.parent.mkdir(parents=True, exist_ok=True)
        _store_engine = create_engine(f"sqlite:///{STORE_DB_PATH.as_posix()}", echo=False)
    return _store_engine


def init_store(engine=None) -> None:
    """Initialise the metadata store schema."""

    actual_engine = engine or get_store_engine()
    if engine is not None:
        actual_engine = engine
    SQLModel.metadata.create_all(actual_engine, tables=STORE_TABLES)


def get_store_session() -> Session:
    """Return a SQLModel session bound to the metadata store."""

    engine = get_store_engine()
    return Session(engine)


def _serialise_meta(meta: Dict[str, Any]) -> str:
    return json.dumps(meta, ensure_ascii=False, sort_keys=True)


def _deserialise_meta(payload: Optional[str]) -> Dict[str, Any]:
    if not payload:
        return {}
    try:
        data = json.loads(payload)
        if isinstance(data, dict):
            return data
    except json.JSONDecodeError:
        pass
    return {}


class MetadataStore:
    """High level helper around ``store.db`` tables."""

    def __init__(self, session_factory: Callable[[], Session] = get_store_session):
        self._session_factory = session_factory

    # ----- task metadata -----
    def load_task_meta(self, remote_task_id: str, list_id: str) -> Dict[str, Any]:
        with self._session_factory() as session:
            row = session.get(TaskMetadata, (remote_task_id, list_id))
            return _deserialise_meta(row.meta_json if row else None)

    def save_task_meta(
        self,
        remote_task_id: str,
        list_id: str,
        meta: Optional[Dict[str, Any]],
        updated_at: Optional[datetime] = None,
    ) -> None:
        with self._session_factory() as session:
            row = session.get(TaskMetadata, (remote_task_id, list_id))
            if not meta:
                if row is not None:
                    session.delete(row)
                    session.commit()
                return

            payload = _serialise_meta(meta)
            timestamp = updated_at or _utcnow()
            if row is None:
                row = TaskMetadata(
                    remote_task_id=remote_task_id,
                    list_id=list_id,
                    meta_json=payload,
                    updated_at=timestamp,
                )
            else:
                row.meta_json = payload
                row.updated_at = timestamp
            session.add(row)
            session.commit()

    def delete_task_meta(self, remote_task_id: str, list_id: str) -> None:
        self.save_task_meta(remote_task_id, list_id, None)

    # ----- lists -----
    def register_list(
        self,
        list_id: str,
        *,
        name: Optional[str] = None,
        backend: Optional[str] = None,
        last_sync: Optional[datetime] = None,
    ) -> None:
        with self._session_factory() as session:
            row = session.get(ListRecord, list_id)
            if row is None:
                row = ListRecord(list_id=list_id)
            if name is not None:
                row.name = name
            if backend is not None:
                row.backend = backend
            if last_sync is not None:
                row.last_sync = last_sync
            session.add(row)
            session.commit()

    def update_list_sync(self, list_id: str, timestamp: Optional[datetime]) -> None:
        with self._session_factory() as session:
            row = session.get(ListRecord, list_id)
            if row is None:
                row = ListRecord(list_id=list_id)
            row.last_sync = timestamp or _utcnow()
            session.add(row)
            session.commit()

    def iter_lists(self) -> Iterable[ListRecord]:
        with self._session_factory() as session:
            stmt = session.exec(select(ListRecord))
            yield from stmt


__all__ = [
    "ListRecord",
    "MetadataStore",
    "SyncState",
    "TaskMetadata",
    "get_store_session",
    "get_store_engine",
    "init_store",
    "STORE_TABLES",
]


```

### tests/test_datetime_utils.py
```python
from datetime import datetime, timedelta
from pathlib import Path
import sys

sys.path.append(str(Path(__file__).resolve().parents[1]))

from helpers.datetime_utils import (
    parse_date_input,
    parse_time_input,
    build_start_datetime,
    snap_minutes,
)


def test_parse_date_input_iso_and_russian():
    assert parse_date_input("2023-12-01").isoformat() == "2023-12-01"
    assert parse_date_input("01.12.2023").isoformat() == "2023-12-01"
def test_parse_time_input_relative_now():
    before = datetime.now()
    result = parse_time_input("сейчас+30")
    after = datetime.now()
    assert result is not None
    minutes_expected = ((before + timedelta(minutes=30)).hour * 60 + (before + timedelta(minutes=30)).minute) % (24 * 60)
    minutes_actual = result.hour * 60 + result.minute
    # allow a 1-minute drift due to processing time
    assert abs(minutes_actual - minutes_expected) <= 1 or abs(minutes_actual - minutes_expected + 24 * 60) <= 1


def test_build_start_datetime_future_auto_rolls_forward():
    now = datetime.now()
    earlier = (now - timedelta(minutes=30)).strftime("%H:%M")
    dt = build_start_datetime(None, earlier, step_minutes=30)
    assert dt is not None
    assert dt >= now
    assert dt.time().minute % 30 == 0


def test_snap_minutes_rounding():
    assert snap_minutes(17, step=15, direction="nearest") == 15
    assert snap_minutes(8, step=15, direction="forward") == 15
    assert snap_minutes(22, step=15, direction="backward") == 15

```

### tests/test_settings_paths.py
```python
from datetime import datetime, timedelta
from pathlib import Path
import sys

ROOT = Path(__file__).resolve().parent.parent
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from core import settings
from storage import backup as backup_module
from storage.backup import ensure_daily_backup


def test_linux_data_dir_with_xdg():
    env = {"XDG_DATA_HOME": "/tmp/xdg"}
    result = settings.get_default_data_dir(
        settings.APP_NAME,
        platform="linux",
        env=env,
        home=Path("/home/test"),
    )
    assert result == Path("/tmp/xdg") / settings.APP_NAME


def test_linux_data_dir_default_home():
    result = settings.get_default_data_dir(
        settings.APP_NAME,
        platform="linux",
        env={},
        home=Path("/home/test"),
    )
    assert result == Path("/home/test/.local/share") / settings.APP_NAME


def test_macos_data_dir():
    result = settings.get_default_data_dir(
        settings.APP_NAME,
        platform="darwin",
        env={},
        home=Path("/Users/test"),
    )
    expected = Path("/Users/test/Library/Application Support") / settings.APP_NAME
    assert result == expected


def test_windows_data_dir_appdata():
    env = {"APPDATA": "C:/Users/test/AppData/Roaming"}
    result = settings.get_default_data_dir(
        settings.APP_NAME,
        platform="win32",
        env=env,
        home=Path("C:/Users/test"),
    )
    expected = Path(env["APPDATA"]) / settings.APP_NAME
    assert result == expected


def test_runtime_paths_inside_data_dir():
    assert settings.DB_PATH.parent == settings.DATA_DIR
    assert settings.TOKEN_PATH.parent == settings.DATA_DIR
    assert settings.CLIENT_SECRET_PATH.parent == settings.SECRETS_DIR
    assert settings.SYNC_TOKEN_PATH.parent == settings.STORAGE_DIR


def test_backup_rotation(monkeypatch, tmp_path):
    db_path = tmp_path / "app.db"
    db_path.write_text("seed", encoding="utf-8")
    backup_dir = tmp_path / "backups"

    base = datetime(2024, 1, 1)

    for offset in range(5):
        db_path.write_text(f"content-{offset}", encoding="utf-8")

        class FakeDateTime(datetime):
            @classmethod
            def now(cls, tz=None):
                return base + timedelta(days=offset)

        monkeypatch.setattr(backup_module, "datetime", FakeDateTime)
        ensure_daily_backup(db_path, backup_dir, keep_days=3)

    monkeypatch.setattr(backup_module, "datetime", datetime)

    backups = sorted(p.name for p in backup_dir.iterdir())
    assert backups == [
        "app_2024-01-03.db",
        "app_2024-01-04.db",
        "app_2024-01-05.db",
    ]

```

### tests/test_undated_tasks_sync.py
```python
import json
from datetime import datetime
from typing import Dict, Tuple

import pytest
from sqlmodel import Session, SQLModel, create_engine

from core.priorities import DEFAULT_PRIORITY
from models import SyncMapUndated, Task
from services.appdata import AppDataClient
from services.tasks_bridge import _split_notes, _status_payload
from services.undated_tasks_sync import UndatedTasksSync


class FakeAppData(AppDataClient):  # type: ignore[misc]
    """In-memory stub of :class:`AppDataClient` for unit tests."""

    def __init__(self):
        # ``AppDataClient`` expects an ``auth`` object but we don't need one here.
        super().__init__(auth=None)
        self.config = {"version": 1, "tasklist_id": None, "last_full_sync": None}
        self.index = {"version": 1, "tasklist_id": None, "tasks": {}}
        self.config_etag = "cfg-0"
        self.index_etag = "idx-0"
        self.ensure_calls = 0

    # ``AppDataClient`` normally builds Drive services. Our stub skips that part.
    def ensure_files(self) -> Dict[str, str]:  # type: ignore[override]
        self.ensure_calls += 1
        return {self.CONFIG_NAME: "config", self.INDEX_NAME: "index"}

    def read_config(self) -> Tuple[Dict[str, object], str]:  # type: ignore[override]
        return (json.loads(json.dumps(self.config)), self.config_etag)

    def write_config(  # type: ignore[override]
        self,
        data,
        if_match=None,
        *,
        on_conflict=None,
    ):
        self.config = json.loads(json.dumps(data))
        major = int(self.config_etag.split("-")[1]) + 1
        self.config_etag = f"cfg-{major}"
        return json.loads(json.dumps(self.config)), self.config_etag

    def read_index(self) -> Tuple[Dict[str, object], str]:  # type: ignore[override]
        return (json.loads(json.dumps(self.index)), self.index_etag)

    def write_index(  # type: ignore[override]
        self,
        data,
        if_match=None,
        *,
        on_conflict=None,
    ):
        payload = json.loads(json.dumps(data))
        if on_conflict:
            payload = on_conflict(payload)
        self.index = payload
        major = int(self.index_etag.split("-")[1]) + 1
        self.index_etag = f"idx-{major}"
        return json.loads(json.dumps(self.index)), self.index_etag


class FakeBridge:
    tasklist_title = "Planner Inbox"

    def __init__(self, items=None):
        self.items = items or []
        self.inserted: list[tuple[str, dict]] = []
        self.deleted: list[tuple[str, str]] = []

    def ensure_tasklist(self):
        return "list-1"

    def fetch_all(self, tasklist_id):
        return list(self.items)

    def upsert_task(self, tasklist_id, local_task):
        self.inserted.append((tasklist_id, dict(local_task)))
        return "gtask-123"

    def delete_task(self, tasklist_id, gtask_id):
        self.deleted.append((tasklist_id, gtask_id))


@pytest.fixture()
def session_factory():
    engine = create_engine("sqlite:///:memory:")
    SQLModel.metadata.create_all(engine)

    def factory():
        return Session(engine)

    return factory


def _create_task(session_factory):
    with session_factory() as session:
        task = Task(title="Test", start=None)
        session.add(task)
        session.commit()
        session.refresh(task)
        return task.id


def test_push_dirty_creates_mapping_and_updates_index(session_factory):
    task_id = _create_task(session_factory)

    bridge = FakeBridge()
    appdata = FakeAppData()
    sync = UndatedTasksSync(
        auth=None,
        bridge=bridge,
        session_factory=session_factory,
        appdata=appdata,
        device_id="TEST-DEVICE",
    )

    assert sync.push_dirty() is True

    with session_factory() as session:
        mapping = session.get(SyncMapUndated, str(task_id))
        assert mapping is not None
        assert mapping.gtask_id == "gtask-123"
        assert mapping.dirty_flag == 0

    entry = appdata.index["tasks"].get("gtask-123")
    assert entry is not None
    assert entry["task_id"] == str(task_id)
    assert entry["status"] == "todo"
    assert entry["priority"] == DEFAULT_PRIORITY
    assert appdata.config["tasklist_id"] == "list-1"


def test_split_notes_extracts_metadata_and_body():
    meta = {"task_id": "42", "status": "todo"}
    body = "Hello\nWorld"
    combined = json.dumps(meta) + "\n\n" + body
    parsed_meta, parsed_body, had_meta = _split_notes(combined)
    assert parsed_meta == meta
    assert parsed_body == body
    assert had_meta is True


def test_status_done_completes_on_push_and_pull(session_factory):
    status, completed_at = _status_payload({"status": "done", "updated_at": datetime.utcnow()})
    assert status == "completed"
    assert completed_at is not None

    task_id = _create_task(session_factory)

    with session_factory() as session:
        mapping = SyncMapUndated(
            task_id=str(task_id),
            gtask_id="gtask-remote",
            tasklist_id="list-1",
            dirty_flag=0,
        )
        session.add(mapping)
        session.commit()

    remote_item = {
        "id": "gtask-remote",
        "title": "Remote",
        "notes": "Updated",
        "status": "completed",
        "updated": datetime.utcnow().isoformat(),
        "detected_meta": {},
    }

    bridge = FakeBridge(items=[remote_item])
    appdata = FakeAppData()
    appdata.index["tasks"]["gtask-remote"] = {
        "task_id": str(task_id),
        "priority": DEFAULT_PRIORITY,
        "status": "todo",
        "updated_at": datetime.utcnow().isoformat(),
        "device_id": "OTHER",
    }

    sync = UndatedTasksSync(
        auth=None,
        bridge=bridge,
        session_factory=session_factory,
        appdata=appdata,
        device_id="LOCAL",
    )

    assert sync.pull() is True

    with session_factory() as session:
        updated_task = session.get(Task, task_id)
        assert updated_task.status == "done"
        assert (updated_task.notes or "") == "Updated"


```

### ui/__init__.py
```python

```

### ui/app_shell.py
```python
# ui/app_shell.py
from __future__ import annotations

import asyncio
import flet as ft

from core.settings import UI, GOOGLE_SYNC

# страницы
from .pages.today import TodayPage
from .pages.calendar import CalendarPage
from .pages.settings import SettingsPage
from .pages.history import HistoryPage

# Google
from services.google_auth import GoogleAuth
from services.google_calendar import GoogleCalendar
from services.google_tasks import GoogleTasks
from services.sync_service import SyncService, SYNC_LOG_PATH
from services.pending_ops_queue import PendingOpsQueue
from services.sync_token_storage import SyncTokenStorage
from services.tasks import TaskService


class AppShell:
    def __init__(self, page: ft.Page):
        self.page = page

        # базовые настройки окна
        self.page.title = UI.app_title
        self.page.horizontal_alignment = ft.CrossAxisAlignment.STRETCH
        self.page.vertical_alignment = ft.MainAxisAlignment.START

        # --- Google Auth + Calendar (важно: до создания страниц) ---
        # при необходимости можно передать пути: GoogleAuth(secrets_path=..., token_path=...)
        self.auth = GoogleAuth()
        self.gcal = GoogleCalendar(self.auth, calendar_id="primary")
        self.gtasks = GoogleTasks(self.auth)
        self.sync_service = SyncService(
            self.gcal,
            self.gtasks,
            TaskService(),
            SyncTokenStorage(),
            PendingOpsQueue(),
        )
        TaskService.subscribe("after_create", self.sync_service.on_task_created)
        TaskService.subscribe("after_update", self.sync_service.on_task_updated)
        TaskService.subscribe("after_delete", self.sync_service.on_task_deleted)

        # --- страницы ---
        self._today = TodayPage(self)
        self._calendar = CalendarPage(self)
        self._history = HistoryPage(self)
        self._settings = SettingsPage(self)  # использует self.gcal

        # контейнер контента
        self.content = ft.Container(expand=True)

        # левое меню
        self.nav = ft.NavigationRail(
            selected_index=0,
            label_type=ft.NavigationRailLabelType.ALL,
            min_width=90,
            min_extended_width=200,
            group_alignment=-0.9,
            on_change=self.on_nav_change,
            destinations=[
                ft.NavigationRailDestination(
                    icon=ft.Icons.CHECK_CIRCLE_OUTLINE,
                    selected_icon=ft.Icons.CHECK_CIRCLE,
                    label="Сегодня",
                ),
                ft.NavigationRailDestination(
                    icon=ft.Icons.CALENDAR_MONTH_OUTLINED,
                    selected_icon=ft.Icons.CALENDAR_MONTH,
                    label="Календарь",
                ),
                ft.NavigationRailDestination(
                    icon=ft.Icons.HISTORY_EDU_OUTLINED,
                    selected_icon=ft.Icons.HISTORY,
                    label="История",
                ),
                ft.NavigationRailDestination(
                    icon=ft.Icons.SETTINGS_OUTLINED,
                    selected_icon=ft.Icons.SETTINGS,
                    label="Настройки",
                ),
            ],
        )

        # корневой лэйаут
        self.root = ft.Row(
            controls=[
                ft.Container(self.nav, width=88, bgcolor=UI.theme.safe_surface_bg),
                ft.VerticalDivider(width=1),
                self.content,
            ],
            expand=True,
            spacing=0,
        )

        # автообновление активной страницы
        self._auto_task: asyncio.Task | None = None
        self._active_view: str | None = None  # "today" | "calendar" | "history" | "settings"

    def cleanup_overlays(self):
        """Remove closed overlays (dialogs, pickers, backdrops) to avoid "ghost" windows."""
        overlays = getattr(self.page, "overlay", None) or []
        changed = False

        def _close_and_remove(ctrl):
            nonlocal changed
            try:
                if hasattr(ctrl, "open"):
                    ctrl.open = False
            except Exception:
                pass
            try:
                overlays.remove(ctrl)
                changed = True
            except Exception:
                pass

        for ctrl in list(overlays):
            if isinstance(ctrl, (ft.AlertDialog, ft.DatePicker, ft.TimePicker)):
                if not getattr(ctrl, "open", False):
                    _close_and_remove(ctrl)

        has_dialog = any(
            getattr(ctrl, "open", False) for ctrl in overlays if isinstance(ctrl, ft.AlertDialog)
        )

        if not has_dialog:
            for ctrl in list(overlays):
                if getattr(ctrl, "data", None) == "backdrop":
                    _close_and_remove(ctrl)

        if changed:
            self.page.update()

    # ---------- утилиты ----------
    def _has_open_overlay(self) -> bool:
        """Если открыт любой диалог/оверлей — пропускаем автообновление."""
        try:
            if getattr(self.page, "dialog", None) and getattr(self.page.dialog, "open", False):
                return True
        except Exception:
            pass
        try:
            return any(getattr(c, "open", False) for c in (self.page.overlay or []))
        except Exception:
            return False

    def _pull_from_google(self) -> bool:
        """
        Подтягиваем изменения из Google -> локально.
        Возвращает True, если локальная база изменилась (для логов/отладки).
        """
        try:
            return self.sync_service.pull_all()
        except Exception as e:
            print("Google sync error:", e)
            return False

    def _push_to_google(self):
        if not GOOGLE_SYNC.enabled:
            return
        try:
            self.sync_service.push_queue_worker()
        except Exception as e:
            print("Google Calendar push error:", e)

    def _start_auto_refresh(
        self, view_name: str, refresh_fn, period_sec: int | None = None
    ):
        """Периодически дергаем pull + refresh_fn, пока активен указанный view."""
        if not GOOGLE_SYNC.enabled or not UI.auto_refresh.enabled:
            refresh_fn()
            return
        self._stop_auto_refresh()
        self._active_view = view_name

        interval = period_sec or GOOGLE_SYNC.auto_pull_interval_sec or UI.auto_refresh.interval_sec

        async def _loop():
            # первый прогон — сразу: подтянуть изменения и перерисовать
            try:
                self._pull_from_google()
                refresh_fn()
                self._push_to_google()
            except Exception as e:
                print("auto refresh (initial):", e)

            while self._active_view == view_name:
                await asyncio.sleep(interval)
                if self._active_view != view_name:
                    break
                if self._has_open_overlay():
                    continue
                try:
                    self._pull_from_google()
                    refresh_fn()
                    self._push_to_google()
                except Exception as e:
                    print("auto refresh:", e)

        self._auto_task = self.page.run_task(_loop)

    def _stop_auto_refresh(self):
        try:
            if self._auto_task:
                self._auto_task.cancel()
        except Exception:
            pass
        self._auto_task = None
        self._active_view = None

    # ---------- монтаж ----------
    def mount(self):
        self.page.controls.clear()
        self.page.add(self.root)

        # стартуем со «Сегодня»
        self.content.content = self._today.view
        self.page.update()

        # 1) Подтянуть последние изменения из Google,
        # 2) отрисовать страницу,
        # 3) запустить автообновление.
        self._pull_from_google()
        self._today.activate_from_menu()
        self._start_auto_refresh("today", self._today.load)

    # ---------- переключение вкладок ----------
    def on_nav_change(self, e: ft.ControlEvent):
        idx = int(e.control.selected_index)

        if idx == 0:  # Сегодня
            self.content.content = self._today.view
            self._pull_from_google()
            self._today.activate_from_menu()
            self._start_auto_refresh("today", self._today.load)

        elif idx == 1:  # Календарь
            self.content.content = self._calendar.view
            self._pull_from_google()
            self._calendar.activate_from_menu()
            try:
                self._calendar.scroll_to_now()  # к текущему часу
            except Exception:
                pass
            self._start_auto_refresh("calendar", self._calendar.load)

        elif idx == 2:  # История
            self.content.content = self._history.view
            self._stop_auto_refresh()
            self._history.activate_from_menu()

        else:  # Настройки (используем полноценную страницу настроек)
            self.content.content = self._settings.view
            self._stop_auto_refresh()

        self.page.update()

    # ---------- ручной вызов синка (если где-то используете) ----------
    def current_page_auto_sync(self):
        if self._has_open_overlay():
            return
        self._pull_from_google()
        self._push_to_google()
        if self._active_view == "calendar":
            self._calendar.load()
        elif self._active_view == "today":
            self._today.load()

    # ---------- публичные утилиты для страниц ----------
    def push_tasks_to_google(self) -> None:
        """Expose push-to-Google routine for UI pages."""
        self._push_to_google()

    def connect_google_services(self) -> bool:
        try:
            self.auth.ensure_credentials()
            self.gcal.connect()
            self.gtasks.connect()
            return True
        except Exception as exc:
            print("Google connect error:", exc)
            raise

    def sync_status(self) -> dict:
        try:
            return self.sync_service.status()
        except Exception as exc:
            print("Sync status error:", exc)
            return {}

    def reset_calendar_sync(self) -> None:
        try:
            self.sync_service.reset_calendar_sync_token()
        except Exception as exc:
            print("Reset calendar token error:", exc)

    def force_full_resync(self) -> None:
        try:
            self.sync_service.force_full_resync()
        except Exception as exc:
            print("Full resync error:", exc)
            raise

    def read_sync_log(self, lines: int = 100) -> str:
        path = SYNC_LOG_PATH
        try:
            with open(path, "r", encoding="utf-8") as fh:
                content = fh.readlines()
        except FileNotFoundError:
            return "Лог синхронизации пока не создан."
        content = [line.rstrip("\n") for line in content[-lines:]]
        return "\n".join(content)

```

### ui/pages/__init__.py
```python

```

### ui/pages/calendar.py
```python
# ui/pages/calendar.py
from __future__ import annotations
import re

import json
import flet as ft
from datetime import datetime, date, timedelta, time as dt_time
from typing import Dict, Tuple, List, Optional

from services.tasks import TaskService
from core.priorities import (
    priority_options,
    priority_label,
    priority_color,
    priority_bgcolor,
    normalize_priority,
)
from core.settings import UI

# ===== настройки =====
CAL_UI = UI.calendar
THEME = UI.theme

DAY_START = CAL_UI.day_start
DAY_END = CAL_UI.day_end

ROW_MIN_H = CAL_UI.row_min_height  # минимальная высота строки часа
DAY_COL_W = CAL_UI.day_column_width
HOURS_COL_W = CAL_UI.hours_column_width
SIDE_PANEL_W = CAL_UI.side_panel_width
HEADER_H = CAL_UI.header_height

CHIP_EST_H = CAL_UI.chip_estimated_height  # ожидаемая высота «чипа»
CELL_VPAD = CAL_UI.cell_vertical_padding
CHIPS_SPACING = CAL_UI.chips_spacing

IMPORT_NEW_GCAL = CAL_UI.import_new_from_google

DIALOG_WIDTH_NARROW = CAL_UI.dialog_width_narrow
DIALOG_WIDTH_WIDE = CAL_UI.dialog_width_wide


def _color(value: str, fallback: str = "") -> str:
    try:
        return getattr(ft.Colors, value)
    except Exception:
        return value or fallback


CLR_OUTLINE = _color(THEME.outline, "#E5E7EB")
CLR_SURFVAR = _color(THEME.surface_variant, "#F1F5F9")
CLR_TEXTSUB = _color(THEME.text_subtle, "#6B7280")
CLR_TODAY_BG = THEME.today_bg
CLR_NOW_LINE = THEME.now_line
CLR_CHIP = THEME.chip
CLR_CHIP_TXT = THEME.chip_text
CLR_UNS_BG = THEME.unscheduled_bg
CLR_BACKDROP = THEME.backdrop  # для клика-вне

NOW_ANCHOR_KEY = "now-anchor"


class CalendarPage:
    """
    - Один тип сущности: задача.
    - Ячейки часа растягиваются по содержимому.
    - Вертикальный скролл только у тела; шапка закреплена.
    - Горизонтальный скролл синхронный (шапка↔тело), левый столбец времени закреплён.
    - ESC и клик мимо окна закрывают диалог. Никаких «призраков» в overlay.
    """

    def __init__(self, app):
        self.app = app
        self.svc = TaskService()
        self._priority_options = [ft.dropdown.Option(key, label) for key, label in priority_options().items()]

        self.week_start: date = self._monday_of(date.today())

        # индекс задач: (day_idx, hour) -> [task dicts]
        self.idx: Dict[Tuple[int, int], List[dict]] = {}
        # рассчитанные высоты строк по каждому часу
        self.row_h: Dict[int, int] = {}

        # DnD
        self.current_drag_task_id: Optional[int] = None

        # автопрокрутка к «сейчас» после построения
        self._need_scroll_now = True

        # ссылки для синхронизации скролла
        self._hrow_header_ref: ft.Ref[ft.Row] = ft.Ref[ft.Row]()
        self._hrow_body_ref: ft.Ref[ft.Row]   = ft.Ref[ft.Row]()
        self._vcol_ref: ft.Ref[ft.Column]     = ft.Ref[ft.Column]()

        # защита от петель при синхронизации скролла
        self._syncing_hscroll = False

        # текущая подложка (чтобы клик-вне закрывал окно и не оставался «призрак»)
        self._backdrop: Optional[ft.Control] = None

        # ---------- Шапка экрана ----------
        self.title_text = ft.Text("", size=24, weight=ft.FontWeight.BOLD)
        self.home_btn   = ft.IconButton(icon=ft.Icons.HOME,          tooltip="Текущая неделя",  on_click=lambda e: self.go_home())
        self.prev_btn   = ft.IconButton(icon=ft.Icons.CHEVRON_LEFT,  tooltip="Назад на неделю", on_click=lambda e: self.shift_week(-1))
        self.next_btn   = ft.IconButton(icon=ft.Icons.CHEVRON_RIGHT, tooltip="Вперёд на неделю",on_click=lambda e: self.shift_week(1))

        header = ft.Row(
            controls=[ft.Row([self.prev_btn, self.home_btn, self.next_btn], spacing=6),
                      self.title_text,
                      ft.Container()],  # пустой правый край
            alignment=ft.MainAxisAlignment.SPACE_BETWEEN,
        )

        # ---------- Без даты ----------
        self.unscheduled_list = ft.ListView(expand=True, spacing=6)
        self.side_panel = ft.Container(
            width=SIDE_PANEL_W,
            content=ft.Column(
                [ft.Text("Без даты", size=16, weight=ft.FontWeight.W_600),
                 ft.Divider(height=1),
                 self.unscheduled_list],
                expand=True, spacing=8),
            padding=10,
            border=ft.border.all(0.5, CLR_OUTLINE),
            border_radius=8,
        )

        # ---------- Область сетки ----------
        self.grid = ft.Container(expand=True)

        self.view = ft.Container(
            content=ft.Column(
                [header, ft.Divider(height=1), ft.Row([self.side_panel, self.grid], expand=True, spacing=12)],
                spacing=12, expand=True),
            expand=True, padding=20,
        )

        self.load()

    # ===== публичное: вызывать из бокового меню =====
    def activate_from_menu(self):
        self._close_any_dialog()
        self.week_start = self._monday_of(date.today())
        self._need_scroll_now = True
        self.load()

    # ===== Диалоги через overlay (как у тебя раньше) =====
    def _cleanup_backdrop(self):
        try:
            if self._backdrop and self._backdrop in self.app.page.overlay:
                self.app.page.overlay.remove(self._backdrop)
        except Exception:
            pass
        self._backdrop = None

    def _open_dialog(self, dlg: ft.AlertDialog):
        self._cleanup_backdrop()
        self._backdrop = ft.Container(
            expand=True,
            bgcolor=ft.Colors.with_opacity(0.001, CLR_BACKDROP),
            on_click=lambda e, d=dlg: self._close_dialog(d),
            data="backdrop",   # <<< метка, чтобы потом удалить
        )
        self.app.page.overlay.append(self._backdrop)

        dlg.modal = False
        dlg.on_dismiss = lambda e, d=dlg: self._close_dialog(d)
        if dlg not in self.app.page.overlay:
            self.app.page.overlay.append(dlg)
        dlg.open = True
        self.app.page.update()
        self._sweep_overlay()  # <<< сразу подчистить

    def _close_dialog(self, dlg: ft.AlertDialog | None):
        if not dlg:
            return
        cleanup_meta = getattr(dlg, "data", None)
        if isinstance(cleanup_meta, dict):
            fn = cleanup_meta.get("on_close")
            if callable(fn):
                try:
                    fn()
                finally:
                    cleanup_meta["on_close"] = None
        try:
            dlg.open = False
        except Exception:
            pass
        try:
            if dlg in self.app.page.overlay:
                self.app.page.overlay.remove(dlg)
        except Exception:
            pass
        self._cleanup_backdrop()
        self._sweep_overlay()
        self.app.page.update()
        self.app.cleanup_overlays()

    def _close_any_dialog(self):
        # на всякий случай закрыть всё
        try:
            overlays = list(self.app.page.overlay)
        except Exception:
            overlays = []

        for ctrl in overlays:
            if isinstance(ctrl, ft.AlertDialog):
                self._close_dialog(ctrl)

        self._cleanup_backdrop()
        self._sweep_overlay()
        self.app.page.update()
        self.app.cleanup_overlays()
    def _delete_task(self, task_id: int):
        t = self.svc.get(task_id)
        if not t:
            return self._toast("Задача не найдена")
        self.svc.delete(task_id)
        self.load()
        self._toast("Удалено")


    # ===== Даты / навигация =====
    def _monday_of(self, d: date) -> date:
        return d - timedelta(days=d.weekday())

    def _week_days(self) -> List[date]:
        return [self.week_start + timedelta(days=i) for i in range(7)]

    def go_home(self):
        self._close_any_dialog()
        self.week_start = self._monday_of(date.today())
        self._need_scroll_now = True
        self.load()

    def shift_week(self, delta_weeks: int):
        self._close_any_dialog()
        base = self.week_start or self._monday_of(date.today())
        self.week_start = self._monday_of(base + timedelta(days=7 * delta_weeks))
        self._need_scroll_now = True
        self.load()
    
    def _sweep_overlay(self):
        # убираем закрытые диалоги и осиротевшие подложки
        ov = self.app.page.overlay or []
        changed = False
        for c in list(ov):
            if isinstance(c, ft.AlertDialog) and not getattr(c, "open", False):
                try:
                    ov.remove(c); changed = True
                except Exception:
                    pass
            elif isinstance(c, ft.Container) and getattr(c, "data", None) == "backdrop":
                # оставляем подложку только если есть открытый AlertDialog
                if not any(getattr(d, "open", False) for d in ov if isinstance(d, ft.AlertDialog)):
                    try:
                        ov.remove(c); changed = True
                    except Exception:
                        pass
        if changed:
            self.app.page.update()
            self.app.cleanup_overlays()

    # ===== Загрузка =====
    def load(self):
        ws = self.week_start
        we = ws + timedelta(days=6)
        self.title_text.value = f"Неделя {ws.strftime('%d.%m')} — {we.strftime('%d.%m.%Y')}"
        self._sync_from_google(ws, we)


        # индекс задач за неделю
        self.idx.clear()
        for i in range(7):
            d = ws + timedelta(days=i)
            for t in self.svc.list_for_day(d):
                st = getattr(t, "start", None)
                if not isinstance(st, datetime):
                    continue
                dur = getattr(t, "duration_minutes", None) or 30
                di = (st.date() - ws).days
                if 0 <= di < 7:
                    self.idx.setdefault((di, st.hour), []).append(
                        {
                            "title": t.title,
                            "task_id": t.id,
                            "duration": dur,
                            "gcal_event_id": getattr(t, "gcal_event_id", None),
                            "priority": getattr(t, "priority", 0),
                        }
                    )

        # высоты строк
        self.row_h = {}
        for h in range(DAY_START, DAY_END + 1):
            max_n = 0
            for di in range(7):
                max_n = max(max_n, len(self.idx.get((di, h), [])))
            height = ROW_MIN_H if max_n <= 0 else max(ROW_MIN_H, CELL_VPAD + max_n * CHIP_EST_H + (max_n - 1) * CHIPS_SPACING)
            self.row_h[h] = height

        for key, tasks in self.idx.items():
            tasks.sort(key=lambda item: (-item.get("priority", 0), item.get("title", "").lower()))

        self._build_unscheduled()
        self.grid.content = self._build_week_grid()
        self.app.page.update()

        if self._need_scroll_now:
            self._need_scroll_now = False
            self._scroll_to_now()
        self.app.cleanup_overlays()
    def _sync_from_google(self, ws: date, we: date):
        try:
            self.app.sync_service.pull()
        except Exception as ex:
            self._toast(f"Google sync: {ex}")

    def _build_unscheduled(self):
        self.unscheduled_list.controls.clear()
        for t in self.svc.list_unscheduled():
            badge = self._priority_badge(t.priority)
            chip = ft.Container(
                content=ft.Row(
                    [badge, ft.Text(t.title, size=12, no_wrap=True, overflow=ft.TextOverflow.ELLIPSIS, color=CLR_CHIP_TXT)],
                    spacing=8,
                    vertical_alignment=ft.CrossAxisAlignment.CENTER,
                ),
                padding=8,
                bgcolor=priority_bgcolor(t.priority) if t.priority else CLR_UNS_BG,
                border=ft.border.all(0.5, CLR_OUTLINE), border_radius=8,
                width=SIDE_PANEL_W - 20,
            )
            drag = ft.Draggable(
                group="task",
                data=str(t.id),
                on_drag_start=lambda e, tid=t.id: self._remember_drag(tid),
                content=chip,
                content_feedback=ft.Container(
                    content=ft.Text(t.title, size=12),
                    padding=8, bgcolor="#ffffff", border_radius=6,
                    border=ft.border.all(0.5, CLR_OUTLINE),
                ),
            )
            self.unscheduled_list.controls.append(drag)

    def _remember_drag(self, task_id: int):
        self.current_drag_task_id = task_id
        self.app.page.update()

    # ===== Сетка =====
    def _build_week_grid(self) -> ft.Control:
        days = self._week_days()
        today = date.today()
        now = datetime.now()

        # --- Шапка дней (в собственном viewport) ---
        header_cells: List[ft.Control] = []
        for i, d in enumerate(days):
            header_cells.append(
                ft.Container(
                    width=DAY_COL_W, height=HEADER_H,
                    content=ft.Column(
                        [ft.Text(d.strftime("%a"), size=14, weight=ft.FontWeight.W_600),
                         ft.Text(d.strftime("%d.%m"), size=12, color=CLR_TEXTSUB)],
                        spacing=2, horizontal_alignment=ft.CrossAxisAlignment.CENTER),
                    alignment=ft.alignment.center,
                    bgcolor=CLR_TODAY_BG if d == today else None,
                    border=ft.border.only(right=ft.BorderSide(0.5, CLR_OUTLINE)) if i < 6 else None,
                )
            )
        hrow_header = ft.Row(controls=header_cells, spacing=0, ref=self._hrow_header_ref, scroll=ft.ScrollMode.ALWAYS)
        header_viewport = ft.Container(  # ограничиваем ширину, чтобы работал скролл
            height=HEADER_H, expand=True, content=hrow_header, clip_behavior=ft.ClipBehavior.HARD_EDGE
        )

        # --- Левый столбец часов (закреплён) ---
        hours_controls: List[ft.Control] = []
        for h in range(DAY_START, DAY_END + 1):
            hours_controls.append(
                ft.Container(
                    content=ft.Text(f"{h:02d}:00", size=12, color=CLR_TEXTSUB),
                    width=HOURS_COL_W, height=self.row_h[h],
                    alignment=ft.alignment.center_right,
                    padding=ft.padding.only(right=8),
                    border=ft.border.only(bottom=ft.BorderSide(0.6, CLR_OUTLINE)),
                )
            )
        hours_col = ft.Column(controls=hours_controls, spacing=0, width=HOURS_COL_W)

        # --- Колонки дней (тело), тоже в viewport по X ---
        day_cols: List[ft.Control] = []
        for di, d in enumerate(days):
            is_today_col = (d == today)
            col_rows: List[ft.Control] = []
            for h in range(DAY_START, DAY_END + 1):
                tasks = self.idx.get((di, h), [])
                is_now = is_today_col and (h == now.hour)
                slot = self._slot_body(tasks, is_now, d, h)
                drop = ft.DragTarget(group="task", content=slot,
                                     on_accept=lambda e, _d=d, _h=h: self._on_drop_accept(_d, _h, e))
                cell = ft.Container(
                    content=drop, width=DAY_COL_W, height=self.row_h[h],
                    bgcolor=CLR_TODAY_BG if is_today_col else None,
                    border=ft.border.only(
                        right=ft.BorderSide(0.5, CLR_OUTLINE) if di < 6 else None,
                        bottom=ft.BorderSide(0.6, CLR_OUTLINE),
                    ),
                )
                col_rows.append(cell)
            day_cols.append(ft.Container(content=ft.Column(col_rows, spacing=0), width=DAY_COL_W))

        hrow_body = ft.Row(controls=day_cols, spacing=0, ref=self._hrow_body_ref, scroll=ft.ScrollMode.ALWAYS)
        body_viewport = ft.Container(expand=True, content=hrow_body, clip_behavior=ft.ClipBehavior.HARD_EDGE)

        # --- синхронизация скролла шапки и тела ---
        hrow_header.on_scroll = self._on_header_hscroll
        hrow_body.on_scroll   = self._on_body_hscroll

        # --- вертикальный скролл: часы слева (фикс), тело справа (viewport по X) ---
        vscroll_body = ft.Column(
            controls=[ft.Row([hours_col, body_viewport], spacing=0)],
            spacing=0, expand=True, scroll=ft.ScrollMode.ALWAYS, ref=self._vcol_ref
        )

        # --- финальная сборка ---
        top_header = ft.Row(
            controls=[ft.Container(width=HOURS_COL_W, height=HEADER_H), header_viewport],
            spacing=0,
        )

        return ft.Container(
            content=ft.Column(
                controls=[top_header, ft.Divider(height=1, color=CLR_OUTLINE), vscroll_body],
                spacing=0, expand=True),
            expand=True,
            border_radius=8,
            border=ft.border.all(0.5, CLR_OUTLINE),
            padding=8,
            bgcolor="#fff",
        )

    # синхронизация горизонтального скролла (без «рывков»)
    def _on_body_hscroll(self, e: ft.OnScrollEvent):
        if self._syncing_hscroll:
            return
        try:
            self._syncing_hscroll = True
            hdr = self._hrow_header_ref.current
            if hdr:
                hdr.scroll_to(offset=e.pixels, duration=0)
        finally:
            self._syncing_hscroll = False

    def _on_header_hscroll(self, e: ft.OnScrollEvent):
        if self._syncing_hscroll:
            return
        try:
            self._syncing_hscroll = True
            body = self._hrow_body_ref.current
            if body:
                body.scroll_to(offset=e.pixels, duration=0)
        finally:
            self._syncing_hscroll = False

    def _slot_body(self, tasks: List[dict], is_now_hour: bool, day: date, hour: int) -> ft.Control:
        chips: List[ft.Control] = []
        if is_now_hour:
            chips.append(ft.Container(key=NOW_ANCHOR_KEY, height=1, width=1))
            chips.append(ft.Container(height=2, bgcolor=CLR_NOW_LINE))

        if tasks:
            for t in tasks:
                chips.append(self._build_chip(t, day, hour))
        else:
            # кликабельная площадь заполняет весь слот по высоте
            chips.append(
                ft.Container(
                    on_click=lambda e, d=day, h=hour: self.open_quick_add(d, h),
                    width=DAY_COL_W,
                    height=max(8, self.row_h.get(hour, ROW_MIN_H) - 8),
                )
            )

        return ft.Container(
            content=ft.Column(chips, spacing=CHIPS_SPACING),
            padding=ft.padding.only(left=6, right=6, top=4, bottom=4),
            width=DAY_COL_W, expand=True,
            bgcolor=CLR_SURFVAR if tasks else None,
        )

    def _build_chip(self, t: dict, day: date, hour: int) -> ft.Control:
        title = t.get("title", "")
        tid = t.get("task_id")
        dur = t.get("duration", 30)
        priority = t.get("priority", 0)

        chip_body = ft.Container(
            content=ft.Row(
                [
                    self._priority_badge(priority),
                    ft.Text(
                        title,
                        size=11,
                        color=CLR_CHIP_TXT,
                        no_wrap=True,
                        overflow=ft.TextOverflow.ELLIPSIS,
                    ),
                ],
                spacing=6,
                vertical_alignment=ft.CrossAxisAlignment.CENTER,
            ),
            bgcolor=priority_bgcolor(priority) if priority else CLR_CHIP,
            border=ft.border.all(0.5, CLR_OUTLINE),
            border_radius=8,
            padding=6, width=DAY_COL_W-12,
        )
        gd = ft.GestureDetector(
            content=chip_body,
            on_tap=lambda e, _tid=tid: self._open_edit_dialog(_tid, title, dur),
            on_secondary_tap=lambda e, _tid=tid, _title=title, _dur=dur, _d=day, _h=hour:
                self._open_chip_menu(_tid, _title, _dur, _d, _h),
        )
        return ft.Draggable(
            group="task",
            data=str(tid),
            on_drag_start=lambda e, t_id=tid: self._remember_drag(t_id),
            content=gd,
            content_feedback=ft.Container(
                content=ft.Text(title, size=12),
                padding=8, bgcolor="#ffffff", border_radius=6, border=ft.border.all(0.5, CLR_OUTLINE),
            ),
        )

    # ===== Контекстное меню чипа =====
    def _open_chip_menu(self, task_id: int, title: str, duration: int, day: date, hour: int):
        dlg = None

        def close(_=None):
            self._close_dialog(dlg)
            self._sweep_overlay()  

        def act_edit(_):
            close(); self._open_edit_dialog(task_id, title, duration)

        def act_move(_):
            close(); self._schedule_task(task_id, day, hour)

        def act_snooze30(_):
            close(); self._snooze_minutes(task_id, day, hour, duration, 30)

        def act_evening(_):
            close(); self._snooze_evening(task_id)

        def act_tomorrow(_):
            close(); self._snooze_tomorrow(task_id)

        def act_delete(_):
            close(); self._delete_task(task_id)

        content = ft.Column(
            controls=[
                ft.TextButton("Редактировать", on_click=act_edit),
                ft.TextButton("Перенести…", on_click=act_move),
                ft.Divider(height=1),
                ft.TextButton("Snooze +30 мин", on_click=act_snooze30),
                ft.TextButton("Сегодня вечером", on_click=act_evening),
                ft.TextButton("Завтра 10:00", on_click=act_tomorrow),
                ft.Divider(height=1),
                ft.TextButton("Удалить", icon=ft.Icons.DELETE_OUTLINE, on_click=act_delete),
            ],
            tight=True, spacing=4, width=240,
        )
        dlg = ft.AlertDialog(modal=False, title=ft.Text(title), content=content)
        self._open_dialog(dlg)

    # ===== DnD =====
    def _on_drop_accept(self, day: date, hour: int, e):
        task_id = self.current_drag_task_id
        if task_id is None:
            s = str(e.data or "").strip()
            if s.isdigit():
                task_id = int(s)
            else:
                try:
                    payload = json.loads(s)
                    if isinstance(payload, dict) and "task_id" in payload:
                        task_id = int(payload["task_id"])
                except Exception:
                    task_id = None
        self.current_drag_task_id = None
        if task_id is None:
            return self._toast("Не удалось определить задачу")
        self._schedule_task(task_id, day, hour)

    # ===== Планирование и быстрый блок =====
    def _schedule_task(self, task_id: int, day: date, hour: int):
        start_dt = datetime(day.year, day.month, day.day, hour, 0, 0)
        task = self.svc.get(task_id)
        if not task:
            return self._toast("Задача не найдена")
        dur_value = task.duration_minutes or 30
        dur_tf = ft.TextField(label="Длительность, мин", value=str(dur_value), width=140)
        priority_dd = ft.Dropdown(
            label="Приоритет",
            width=220,
            value=str(getattr(task, "priority", 0)),
            options=self._priority_options,
        )
        dlg = None

        def on_save(_):
            try:
                duration = int(dur_tf.value)
                if duration <= 0:
                    raise ValueError
            except Exception:
                return self._toast("Длительность должна быть > 0")

            priority = normalize_priority(priority_dd.value)

            self.svc.update(
                task_id,
                start=start_dt,
                duration_minutes=duration,
                priority=priority,
            )

            self._close_dialog(dlg)
            self._sweep_overlay()
            self.load()

        def on_cancel(_):
            self._close_dialog(dlg)
            self._sweep_overlay()

        dlg = ft.AlertDialog(
            modal=False,
            inset_padding=ft.padding.all(16),
            content_padding=ft.padding.all(12),
            title=ft.Text(f"Запланировать — {start_dt.strftime('%a, %d.%m %H:00')}"),
            content=ft.Container(
                width=DIALOG_WIDTH_NARROW,
                content=ft.Column([dur_tf, priority_dd], spacing=12, tight=True),
            ),
            actions=[
                ft.TextButton("Отмена", on_click=on_cancel),
                ft.FilledButton("Сохранить", icon=ft.Icons.SAVE, on_click=on_save),
            ],
            actions_alignment=ft.MainAxisAlignment.END,
        )

        self._open_dialog(dlg)

    def open_quick_add(self, day: date, hour: int):
        start_dt = datetime(day.year, day.month, day.day, hour, 0, 0)
        title_tf = ft.TextField(label="Название", width=DIALOG_WIDTH_NARROW - 40)
        dur_tf = ft.TextField(label="Длительность, мин", value="30", width=140)
        priority_dd = ft.Dropdown(
            label="Приоритет",
            width=180,
            value=str(0),
            options=self._priority_options,
        )
        dlg = None

        def on_save(_):
            title = (title_tf.value or "").strip()
            if not title:
                return self._toast("Введите название")
            try:
                duration = int(dur_tf.value)
                if duration <= 0:
                    raise ValueError
            except Exception:
                return self._toast("Длительность должна быть > 0")
            priority = normalize_priority(priority_dd.value)

            self.svc.add(title=title, start=start_dt, duration_minutes=duration, priority=priority)
            self._toast("Создано")

            self._close_dialog(dlg)
            self._sweep_overlay()
            self.load()

        def on_cancel(_):
            self._close_dialog(dlg)
            self._sweep_overlay()

        dlg = ft.AlertDialog(
            modal=False,
            inset_padding=ft.padding.all(16),
            content_padding=ft.padding.all(12),
            title=ft.Text(f"Быстрый блок — {start_dt.strftime('%a, %d.%m %H:00')}"),
            content=ft.Container(
                width=DIALOG_WIDTH_NARROW,
                content=ft.Column([title_tf, dur_tf, priority_dd], spacing=12, tight=True),
            ),
            actions=[
                ft.TextButton("Отмена", on_click=on_cancel),
                ft.FilledButton("Сохранить", icon=ft.Icons.SAVE, on_click=on_save),
            ],
            actions_alignment=ft.MainAxisAlignment.END,
        )
        self._open_dialog(dlg)

    # ===== Редактирование / Snooze / Удаление =====
    # ui/pages/calendar.py  (внутри класса CalendarPage)
    def _open_edit_dialog(
        self,
        task_id: int,
        current_title: str | None = None,
        current_duration: int | None = None,
    ):
        # --- берём актуальные данные задачи ---
        t = None
        try:
            t = self.svc.get(task_id)
        except Exception:
            pass
        if t is None:
            return self._toast("Задача не найдена")

        title_init = current_title if current_title is not None else (t.title or "")
        dur_init   = current_duration if current_duration is not None else (t.duration_minutes or 30)
        start_init = getattr(t, "start", None)

        date_str = start_init.strftime("%d.%m.%Y") if isinstance(start_init, datetime) else ""
        time_str = start_init.strftime("%H:%M")     if isinstance(start_init, datetime) else ""

        # --- поля формы (без expand) ---
        DATE_W, TIME_W, DUR_W = 140, 100, 120

        title_tf = ft.TextField(label="Название", value=title_init, width=DIALOG_WIDTH_WIDE - 80)
        date_tf  = ft.TextField(label="Дата",  value=date_str, width=DATE_W, read_only=True)
        time_tf  = ft.TextField(label="Время", value=time_str, width=TIME_W, read_only=True)
        dur_tf   = ft.TextField(label="Длительность, мин", value=str(dur_init), width=DUR_W)
        priority_dd = ft.Dropdown(
            label="Приоритет",
            width=200,
            value=str(getattr(t, "priority", 0)),
            options=self._priority_options,
        )

        # заметки (авто-увеличение по числу строк)
        notes_tf = ft.TextField(
            label="Заметки",
            value=(t.notes or ""),
            multiline=True,
            min_lines=3,
            max_lines=6,
        )
        def _autogrow(_=None):
            s = notes_tf.value or ""
            # считаем количество визуальных строк (по \n)
            lines = max(3, min(12, s.count("\n") + 1))
            if notes_tf.max_lines != lines:
                notes_tf.max_lines = lines
                self.app.page.update()
        notes_tf.on_change = _autogrow
        _autogrow()  # подстроиться под начальный текст

        # --- пикеры ---
        dp = ft.DatePicker(
            first_date=date(2000, 1, 1),
            last_date=date(2100, 12, 31),
            on_change=lambda e: self._set_tf_date(date_tf, e.data or e.control.value),
            on_dismiss=lambda e: self._set_tf_date(date_tf, e.control.value),
        )
        tp = self._new_time_picker()
        for p in (dp, tp):
            if p not in self.app.page.overlay:
                self.app.page.overlay.append(p)

        date_btn = ft.IconButton(
            icon=ft.Icons.CALENDAR_MONTH,
            tooltip="Выбрать дату",
            icon_size=18,
            on_click=lambda e, _dp=dp: self.app.page.open(_dp),
        )
        time_btn = ft.IconButton(
            icon=ft.Icons.SCHEDULE,
            tooltip="Выбрать время",
            icon_size=18,
            on_click=lambda e, _tp=tp: self._open_time_picker(_tp, time_tf),
        )

        # --- сохранение / отмена ---
        dlg = None

        def _remove_pickers():
            for ctrl in (dp, tp):
                try:
                    ctrl.open = False
                except Exception:
                    pass
                try:
                    if ctrl in self.app.page.overlay:
                        self.app.page.overlay.remove(ctrl)
                except Exception:
                    pass

        def on_save(_):
            new_title = (title_tf.value or "").strip()
            if not new_title:
                return self._toast("Введите название")

            if date_tf.value and self._parse_date_tf(date_tf.value) is None:
                return self._toast("Неверный формат даты. Пример: 10.10.2025")
            if time_tf.value and self._parse_time_tf(time_tf.value) is None:
                return self._toast("Неверный формат времени. Пример: 09:30")

            new_start = self._combine_dt(date_tf.value, time_tf.value)
            try:
                new_dur = int(dur_tf.value) if dur_tf.value.strip() else None
            except ValueError:
                return self._toast("Длительность должна быть числом (мин)")

            updated = self.svc.update(
                task_id,
                title=new_title,
                notes=notes_tf.value,
                start=new_start,
                duration_minutes=new_dur,
                priority=normalize_priority(priority_dd.value),
            )

            _remove_pickers()
            self._close_dialog(dlg)
            self._sweep_overlay()
            self.load()
            self._toast("Сохранено")

        def on_cancel(_=None):
            _remove_pickers()
            self._close_dialog(dlg)
            self._sweep_overlay()

        # --- компактная вёрстка (без Wrap) ---
        utils_row = ft.Row(
            [date_tf, date_btn, time_tf, time_btn, dur_tf, priority_dd],
            spacing=8,
            vertical_alignment=ft.CrossAxisAlignment.END,
        )
        buttons_row = ft.Row(
            [ft.TextButton("Отмена", on_click=on_cancel),
            ft.FilledButton("Сохранить", icon=ft.Icons.SAVE, on_click=on_save)],
            alignment=ft.MainAxisAlignment.END,
        )

        dlg = ft.AlertDialog(
            modal=False,
            inset_padding=ft.padding.all(16),
            content_padding=ft.padding.all(12),
            title=ft.Text("Редактировать задачу"),
            content=ft.Container(
                width=DIALOG_WIDTH_WIDE,
                content=ft.Column(
                    [title_tf, utils_row, notes_tf, buttons_row],
                    spacing=10,
                    tight=True,
                    scroll=ft.ScrollMode.ADAPTIVE,
                ),
            ),
        )

        dlg.data = {"on_close": _remove_pickers}
        self._open_dialog(dlg)



    def _snooze_minutes(self, task_id: int, day: date, hour: int, duration: int, add_minutes: int):
        base = datetime(day.year, day.month, day.day, hour, 0, 0) + timedelta(minutes=add_minutes)
        self._reschedule(task_id, base, duration)

    def _snooze_evening(self, task_id: int):
        now = datetime.now().astimezone()
        base = now.replace(hour=19, minute=0, second=0, microsecond=0)
        if base < now:
            base = base + timedelta(days=1)
        self._reschedule(task_id, base, 30)

    def _snooze_tomorrow(self, task_id: int):
        base = (datetime.now().astimezone() + timedelta(days=1)).replace(hour=10, minute=0, second=0, microsecond=0)
        self._reschedule(task_id, base, 30)

    def _reschedule(self, task_id: int, start_dt: datetime, duration: int):
        self.svc.update(task_id, start=start_dt, duration_minutes=duration)
        self.load()

    # ===== автопрокрутка к сегодняшнему дню и текущему часу =====
    def _scroll_to_now(self):
        # вертикаль
        try:
            now = datetime.now()
            top_offset = 0
            for h in range(DAY_START, min(now.hour, DAY_END + 1)):
                top_offset += self.row_h.get(h, 0)
            if self._vcol_ref.current:
                self._vcol_ref.current.scroll_to(offset=top_offset, duration=300)
        except Exception:
            pass

        # горизонталь
        try:
            day_idx = (date.today() - self.week_start).days
            if 0 <= day_idx < 7:
                offset_x = DAY_COL_W * day_idx
                if self._hrow_body_ref.current:
                    self._hrow_body_ref.current.scroll_to(offset=offset_x, duration=300)
                if self._hrow_header_ref.current:
                    self._hrow_header_ref.current.scroll_to(offset=offset_x, duration=300)
        except Exception:
            pass

    # публичная обёртка, чтобы дергать из AppShell    
    def scroll_to_now(self):
        self._scroll_to_now()

    # ===== Вспомогательное для форм =====
    def _new_time_picker(self) -> ft.TimePicker:
        picker = ft.TimePicker(help_text="Выберите время")
        picker.on_change = lambda e, _picker=picker: self._time_picker_on_change(_picker, e)
        picker.on_dismiss = lambda e, _picker=picker: self._time_picker_on_dismiss(_picker, e)
        return picker

    def _open_time_picker(self, picker: ft.TimePicker, tf: ft.TextField):
        prev = tf.value
        parsed = self._parse_time_tf(tf.value)
        if parsed:
            base_time = dt_time(parsed[0], parsed[1])
        else:
            now = datetime.now()
            base_time = dt_time(now.hour, now.minute)
        try:
            picker.value = base_time
        except Exception:
            pass
        picker.data = {"tf": tf, "prev": prev, "applied": False}
        if picker not in self.app.page.overlay:
            self.app.page.overlay.append(picker)
        self.app.page.open(picker)

    def _time_picker_on_change(self, picker: ft.TimePicker, e: ft.ControlEvent):
        data = picker.data or {}
        tf = data.get("tf")
        if not tf:
            return
        value = e.data or picker.value
        if value:
            self._set_tf_time(tf, value)
            data["applied"] = True
            picker.data = data

    def _time_picker_on_dismiss(self, picker: ft.TimePicker, e: ft.ControlEvent):
        data = picker.data or {}
        tf = data.get("tf")
        if not tf:
            picker.data = None
            return
        value = e.data
        if value:
            self._set_tf_time(tf, value)
            data["applied"] = True
        elif not data.get("applied"):
            tf.value = data.get("prev", tf.value)
            self.app.page.update()
        picker.data = None

    def _set_tf_date(self, tf: ft.TextField, value):
        from datetime import date as _date, datetime as _dt

        v = value
        if isinstance(v, _date):
            tf.value = v.strftime("%d.%m.%Y")
        elif isinstance(v, str) and v.strip():
            s = v.strip()
            try:
                tf.value = _dt.strptime(s, "%Y-%m-%d").strftime("%d.%m.%Y")
            except ValueError:
                if "T" in s:
                    try:
                        tf.value = _dt.strptime(s.split("T")[0], "%Y-%m-%d").strftime("%d.%m.%Y")
                    except ValueError:
                        pass
                else:
                    try:
                        _dt.strptime(s, "%d.%m.%Y")
                        tf.value = s
                    except ValueError:
                        return
        self.app.page.update()

    def _set_tf_time(self, tf: ft.TextField, value):
        if value in (None, ""):
            return
        try:
            tf.value = value.strftime("%H:%M")
            self.app.page.update()
            return
        except Exception:
            pass

        s = str(value or "").strip()
        m = re.match(r"^(\d{1,2}):(\d{2})(?::(\d{2}))?$", s)
        if m:
            h = int(m.group(1))
            mm = int(m.group(2))
            if 0 <= h <= 23 and 0 <= mm <= 59:
                tf.value = f"{h:02d}:{mm:02d}"
        self.app.page.update()

    def _parse_date_tf(self, s: str):
        s = (s or "").strip()
        m = re.match(r"^\s*(\d{1,2})\.(\d{1,2})\.(\d{4})\s*$", s)
        if not m:
            return None
        d, mth, y = int(m.group(1)), int(m.group(2)), int(m.group(3))
        try:
            return date(y, mth, d)
        except ValueError:
            return None

    def _parse_time_tf(self, s: str):
        s = (s or "").strip()
        m = re.match(r"^\s*(\d{1,2}):(\d{2})(?::\d{2})?\s*$", s)
        if not m:
            return None
        h, minute = int(m.group(1)), int(m.group(2))
        if 0 <= h <= 23 and 0 <= minute <= 59:
            return h, minute
        return None

    def _combine_dt(self, date_str: str, time_str: str):
        d = self._parse_date_tf(date_str)
        t = self._parse_time_tf(time_str)
        if d and t:
            return datetime(d.year, d.month, d.day, t[0], t[1])
        if d and not t:
            return datetime(d.year, d.month, d.day)
        if t and not d:
            today = date.today()
            return datetime(today.year, today.month, today.day, t[0], t[1])
        return None

    # авто-увеличение высоты многострочного TextField
    def _autogrow_textfield(self, tf: ft.TextField, *, min_lines=2, max_lines=14, wrap_at=60):
        text = tf.value or ""
        # грубо оцениваем количество строк с учётом переносов
        lines = text.splitlines() or [""]
        est = sum((len(l) // wrap_at) + 1 for l in lines)
        h = max(min_lines, min(est, max_lines))
        tf.min_lines = h
        tf.max_lines = h


    # ===== сервис =====
    def _priority_badge(self, priority: int) -> ft.Control:
        if priority <= 0:
            return ft.Container(width=0)
        return ft.Container(
            content=ft.Text(
                priority_label(priority, short=True),
                size=10,
                weight=ft.FontWeight.W_500,
                color=priority_color(priority),
            ),
            bgcolor=priority_bgcolor(priority),
            padding=ft.padding.symmetric(horizontal=6, vertical=2),
            border_radius=ft.border_radius.all(6),
        )

    def _toast(self, text: str):
        self.app.page.snack_bar = ft.SnackBar(ft.Text(text))
        self.app.page.snack_bar.open = True
        self.app.page.update()
    

```

### ui/pages/history.py
```python
# planner/ui/pages/history.py
from __future__ import annotations

from datetime import datetime, date
from typing import Optional, List

import flet as ft

from services.tasks import TaskService
from core.priorities import (
    priority_options,
    priority_label,
    priority_color,
    priority_bgcolor,
    normalize_priority,
)

_STATUS_LABELS = {
    "todo": "К выполнению",
    "doing": "В работе",
    "done": "Выполнено",
}


class HistoryPage:
    def __init__(self, app):
        self.app = app
        self.svc = TaskService()

        self.search_tf = ft.TextField(
            label="Поиск",
            hint_text="Введите текст для поиска по названию и заметкам",
            expand=True,
            prefix=ft.Icon(ft.Icons.SEARCH),
            on_submit=self._on_filters_changed,
            on_change=self._on_filters_changed,
        )

        self.start_tf = ft.TextField(label="Дата c", width=150)
        self.end_tf = ft.TextField(label="Дата по", width=150)

        self.start_picker = ft.DatePicker(
            first_date=date(2000, 1, 1),
            last_date=date(2100, 12, 31),
            on_change=lambda e: self._set_date(self.start_tf, e.data or e.control.value),
            on_dismiss=lambda e: self._set_date(self.start_tf, e.control.value),
        )
        self.end_picker = ft.DatePicker(
            first_date=date(2000, 1, 1),
            last_date=date(2100, 12, 31),
            on_change=lambda e: self._set_date(self.end_tf, e.data or e.control.value),
            on_dismiss=lambda e: self._set_date(self.end_tf, e.control.value),
        )

        for picker in (self.start_picker, self.end_picker):
            if picker not in self.app.page.overlay:
                self.app.page.overlay.append(picker)

        self.start_btn = ft.IconButton(
            icon=ft.Icons.CALENDAR_MONTH,
            tooltip="Выбрать дату",
            on_click=lambda e: self.app.page.open(self.start_picker),
        )
        self.end_btn = ft.IconButton(
            icon=ft.Icons.CALENDAR_MONTH,
            tooltip="Выбрать дату",
            on_click=lambda e: self.app.page.open(self.end_picker),
        )

        status_options = [
            ft.dropdown.Option("all", "Любой статус"),
            ft.dropdown.Option("todo", _STATUS_LABELS["todo"]),
            ft.dropdown.Option("doing", _STATUS_LABELS["doing"]),
            ft.dropdown.Option("done", _STATUS_LABELS["done"]),
        ]
        self.status_dd = ft.Dropdown(
            label="Статус",
            width=180,
            value="all",
            options=status_options,
            on_change=self._on_filters_changed,
        )

        priority_opts = [ft.dropdown.Option(key, label) for key, label in priority_options().items()]
        priority_opts.insert(0, ft.dropdown.Option("-1", "Любой приоритет"))
        self.priority_dd = ft.Dropdown(
            label="Приоритет",
            width=200,
            value="-1",
            options=priority_opts,
            on_change=self._on_filters_changed,
        )

        self.reset_btn = ft.TextButton("Сбросить", icon=ft.Icons.REFRESH, on_click=self._on_reset)

        filters_row = ft.Column(
            controls=[
                ft.Row([self.search_tf], alignment=ft.MainAxisAlignment.START),
                ft.Row(
                    [
                        ft.Row([self.start_tf, self.start_btn], spacing=6),
                        ft.Row([self.end_tf, self.end_btn], spacing=6),
                        self.status_dd,
                        self.priority_dd,
                        self.reset_btn,
                    ],
                    alignment=ft.MainAxisAlignment.START,
                    vertical_alignment=ft.CrossAxisAlignment.END,
                    spacing=12,
                ),
            ],
            spacing=12,
        )

        self.result_info = ft.Text("", size=12, color="#6B7280")
        self.result_list = ft.ListView(expand=True, spacing=8)

        self.view = ft.Container(
            content=ft.Column(
                [
                    ft.Text("История", size=24, weight=ft.FontWeight.BOLD),
                    filters_row,
                    self.result_info,
                    ft.Container(content=self.result_list, expand=True),
                ],
                spacing=16,
                expand=True,
            ),
            expand=True,
            padding=20,
        )

        self.run_search()

    def activate_from_menu(self):
        # Пересчитать результаты при возвращении на вкладку.
        self.run_search()

    # ---------- Filters ----------
    def _on_filters_changed(self, _):
        self.run_search()

    def _on_reset(self, _):
        self.search_tf.value = ""
        self.start_tf.value = ""
        self.end_tf.value = ""
        self.status_dd.value = "all"
        self.priority_dd.value = "-1"
        self.app.page.update()
        self.run_search()

    # ---------- Data ----------
    def run_search(self):
        start_date = self._parse_date(self.start_tf.value)
        end_date = self._parse_date(self.end_tf.value)

        priority_value = self.priority_dd.value
        priority = None if priority_value in (None, "-1") else normalize_priority(priority_value)

        tasks = self.svc.search_history(
            query=self.search_tf.value or "",
            start_date=start_date,
            end_date=end_date,
            status=self.status_dd.value,
            priority=priority,
        )

        self._render_results(tasks)
        self.app.page.update()

    def _render_results(self, tasks: List):
        total = len(tasks)
        if total == 0:
            self.result_info.value = "Ничего не найдено"
        else:
            self.result_info.value = f"Найдено {total} задач"

        self.result_list.controls.clear()
        for t in tasks:
            self.result_list.controls.append(self._task_card(t))

    # ---------- Helpers ----------
    def _task_card(self, task):
        title = task.title or "(без названия)"
        priority = getattr(task, "priority", 0)
        start = getattr(task, "start", None)
        created = getattr(task, "created_at", None)
        updated = getattr(task, "updated_at", None)
        duration = getattr(task, "duration_minutes", None)

        subtitle_parts: List[str] = []
        if start:
            if isinstance(start, datetime) and start.time() == datetime.min.time():
                subtitle_parts.append(start.strftime("Начало: %d.%m.%Y"))
            else:
                subtitle_parts.append(start.strftime("Начало: %d.%m.%Y %H:%M"))
        if duration:
            subtitle_parts.append(f"Длительность: {duration} мин")
        status_label = _STATUS_LABELS.get(getattr(task, "status", ""), "Неизвестно")
        subtitle_parts.append(f"Статус: {status_label}")
        subtitle_parts.append(f"Приоритет: {priority_label(priority, short=False)}")
        if created:
            subtitle_parts.append(f"Создано: {created.strftime('%d.%m.%Y %H:%M')}")
        if updated and (not created or updated != created):
            subtitle_parts.append(f"Обновлено: {updated.strftime('%d.%m.%Y %H:%M')}")

        note = (task.notes or "").strip()
        note_text = ft.Text(note, size=12, color="#6B7280")
        note_block = ft.Container()
        if note:
            note_block = ft.Container(
                content=note_text,
                padding=ft.padding.only(top=8),
            )

        badge = self._priority_badge(priority)

        body = ft.Column(
            [
                ft.Row(
                    [
                        badge,
                        ft.Text(title, size=16, weight=ft.FontWeight.W_600),
                    ],
                    spacing=12,
                    vertical_alignment=ft.CrossAxisAlignment.CENTER,
                ),
                ft.Text(" · ".join(subtitle_parts), size=12, color="#6B7280"),
                note_block,
            ],
            spacing=4,
        )

        bgcolor = ft.Colors.with_opacity(0.04, priority_color(priority)) if priority else "#F1F5F9"

        return ft.Card(
            content=ft.Container(
                content=body,
                padding=16,
                bgcolor=bgcolor,
            )
        )

    def _priority_badge(self, priority: int):
        if priority <= 0:
            return ft.Container(width=0)
        return ft.Container(
            content=ft.Text(
                priority_label(priority, short=True),
                size=11,
                weight=ft.FontWeight.W_600,
                color=priority_color(priority),
            ),
            bgcolor=priority_bgcolor(priority),
            padding=ft.padding.symmetric(horizontal=8, vertical=4),
            border_radius=ft.border_radius.all(8),
        )

    def _set_date(self, tf: ft.TextField, value):
        v = value
        if isinstance(v, date):
            tf.value = v.strftime("%d.%m.%Y")
        elif isinstance(v, str):
            try:
                tf.value = datetime.strptime(v[:10], "%Y-%m-%d").strftime("%d.%m.%Y")
            except ValueError:
                try:
                    tf.value = datetime.strptime(v, "%d.%m.%Y").strftime("%d.%m.%Y")
                except ValueError:
                    return
        self.app.page.update()

    def _parse_date(self, text: Optional[str]) -> Optional[date]:
        text = (text or "").strip()
        if not text:
            return None
        try:
            dt = datetime.strptime(text, "%d.%m.%Y")
            return dt.date()
        except ValueError:
            return None

```

### ui/pages/settings.py
```python
# ui/pages/settings.py
from datetime import timezone
import flet as ft


class SettingsPage:
    def __init__(self, app):
        self.app = app

        self.status_calendar = ft.Text()
        self.status_tasks = ft.Text()
        self.last_calendar_pull = ft.Text()
        self.last_tasks_pull = ft.Text()
        self.last_push = ft.Text()

        self.connect_btn = ft.ElevatedButton(
            "Переподключить Google",
            icon=ft.Icons.LINK,
            on_click=self.connect_google,
        )
        self.reset_token_btn = ft.OutlinedButton(
            "Сбросить syncToken",
            icon=ft.Icons.REMOVE_CIRCLE_OUTLINE,
            on_click=self.reset_sync_token,
        )
        self.resync_btn = ft.OutlinedButton(
            "Полная ресинхронизация",
            icon=ft.Icons.SYNC,
            on_click=self.full_resync,
        )
        self.refresh_log_btn = ft.TextButton(
            "Обновить лог",
            icon=ft.Icons.ARTICLE,
            on_click=self.refresh_log,
        )

        self.log_view = ft.Text("", selectable=True)

        content = ft.Column(
            controls=[
                ft.Text("Настройки", size=24, weight=ft.FontWeight.BOLD),
                self.status_calendar,
                self.status_tasks,
                self.last_calendar_pull,
                self.last_tasks_pull,
                self.last_push,
                ft.Row([self.connect_btn, self.reset_token_btn, self.resync_btn], spacing=12),
                ft.Column([
                    ft.Text("Лог синхронизации", size=18, weight=ft.FontWeight.W_600),
                    ft.Container(self.log_view, height=200, padding=10, bgcolor=ft.Colors.ON_SURFACE_VARIANT),
                    self.refresh_log_btn,
                ], spacing=8),
            ],
            expand=True,
            spacing=16,
        )

        self.view = ft.Container(content=content, expand=True, padding=20)
        self.refresh_status()

    def _format_dt(self, value) -> str:
        if not value:
            return "—"
        if getattr(value, "tzinfo", None) is None:
            value = value.replace(tzinfo=timezone.utc)
        return value.astimezone().strftime("%Y-%m-%d %H:%M:%S %Z")

    def refresh_status(self):
        status = self.app.sync_status() or {}
        calendar = status.get("calendar", {})
        tasks = status.get("tasks", {})

        calendar_id = calendar.get("calendarId") or "—"
        token_state = "да" if calendar.get("syncToken") else "нет"
        self.status_calendar.value = f"Google Calendar: {calendar_id} (syncToken: {token_state})"
        self.last_calendar_pull.value = (
            "Последний pull Calendar: " + self._format_dt(calendar.get("lastPullAt"))
        )

        tasklist = tasks.get("tasklist") or "—"
        self.status_tasks.value = f"Google Tasks: {tasklist}"
        updated_min = tasks.get("updatedMin")
        suffix = f" (updatedMin: {self._format_dt(updated_min)})" if updated_min else ""
        self.last_tasks_pull.value = (
            "Последний pull Tasks: " + self._format_dt(tasks.get("lastPullAt")) + suffix
        )
        self.last_push.value = "Последний push: " + self._format_dt(status.get("lastPushAt"))

        self.log_view.value = self.app.read_sync_log()

    def connect_google(self, _):
        try:
            self.app.connect_google_services()
            self.refresh_status()
            self.app.page.snack_bar = ft.SnackBar(ft.Text("Google подключён"))
            self.app.page.snack_bar.open = True
            self.app.page.update()
        except Exception as e:
            self.status_calendar.value = f"Ошибка: {e}"
            self.app.page.update()

    def reset_sync_token(self, _):
        try:
            self.app.reset_calendar_sync()
            self.refresh_status()
            self.app.page.snack_bar = ft.SnackBar(ft.Text("syncToken сброшен"))
            self.app.page.snack_bar.open = True
            self.app.page.update()
        except Exception as e:
            self.status_calendar.value = f"Ошибка сброса: {e}"
            self.app.page.update()

    def full_resync(self, _):
        try:
            self.app.force_full_resync()
            self.refresh_status()
            self.app.page.snack_bar = ft.SnackBar(ft.Text("Полная синхронизация завершена"))
            self.app.page.snack_bar.open = True
            self.app.page.update()
        except Exception as e:
            self.status_tasks.value = f"Ошибка: {e}"
            self.app.page.update()

    def refresh_log(self, _):
        self.log_view.value = self.app.read_sync_log()
        self.app.page.update()

```

### ui/pages/today.py
```python
# planner/ui/pages/today.py
import re
from datetime import datetime, date, timedelta, time as dt_time
import flet as ft

from services.tasks import TaskService
from core.priorities import (
    priority_options,
    priority_label,
    priority_color,
    normalize_priority,
)
from core.settings import UI, GOOGLE_SYNC


class TodayPage:
    LIST_SECTION_HEIGHT = UI.today.list_section_height

    def __init__(self, app):
        self.app = app
        self.svc = TaskService()
        self.edit_dialog: ft.AlertDialog | None = None

        # ---------- Быстрый ввод ----------
        self.title_tf = ft.TextField(
            label="Название задачи",
            hint_text="Например: Позвонить Ивану",
            expand=True,
            prefix=ft.Icon(ft.Icons.TASK_ALT),
        )

        self.date_tf = ft.TextField(
            label="Дата", hint_text="напр.: 10.10.2025", width=160
        )
        self.time_tf = ft.TextField(
            label="Время", hint_text="чч:мм", width=120
        )


        # В 0.28.3 дата надёжно приходит через control.value, иногда только в on_dismiss
        self.date_picker_add = ft.DatePicker(
            first_date=date(2000, 1, 1),
            last_date=date(2100, 12, 31),
            on_change=lambda e: self._set_tf_date(self.date_tf, e.data or e.control.value),
            on_dismiss=lambda e: self._set_tf_date(self.date_tf, e.control.value),
        )

        # TimePicker
        self.time_picker_add = self._new_time_picker()

        for p in (self.date_picker_add, self.time_picker_add):
            if p not in self.app.page.overlay:
                self.app.page.overlay.append(p)

        self.date_btn = ft.IconButton(
            icon=ft.Icons.CALENDAR_MONTH, tooltip="Календарь",
            on_click=lambda e: self.app.page.open(self.date_picker_add)
        )
        self.time_btn = ft.IconButton(
            icon=ft.Icons.SCHEDULE,
            tooltip="Выбрать время",
            on_click=lambda e: self._open_time_picker(self.time_picker_add, self.time_tf),
        )

        self.dur_tf = ft.TextField(
            label="Длительность, мин",
            value=str(UI.today.default_duration_minutes),
            width=160,
            prefix=ft.Icon(ft.Icons.TIMER),
        )
        self.priority_dd = ft.Dropdown(
            label="Приоритет",
            width=160,
            value=str(0),
            options=[ft.dropdown.Option(key, label) for key, label in priority_options().items()],
        )
        self.to_calendar_cb = ft.Checkbox(
            label="Сразу в календарь",
            value=UI.today.add_to_calendar_by_default,
        )
        self.add_btn = ft.FilledButton("Добавить", icon=ft.Icons.ADD, on_click=self.on_add)

        quick_add = ft.Card(
            content=ft.Container(
                content=ft.Column(
                    [
                        ft.Text("Быстрый ввод", size=18, weight=ft.FontWeight.W_600),
                        ft.Row(
                            [
                                self.title_tf,
                                ft.Row([self.date_tf, self.date_btn], spacing=6),
                                ft.Row([self.time_tf, self.time_btn], spacing=6),
                                self.dur_tf,
                                self.priority_dd,
                                self.to_calendar_cb,
                                self.add_btn,
                            ],
                            alignment=ft.MainAxisAlignment.START,
                            vertical_alignment=ft.CrossAxisAlignment.END,
                        ),
                    ],
                    spacing=12,
                ),
                padding=16,
            )
        )

        self.today_list = ft.ListView(expand=True, spacing=12)
        self.unscheduled_list = ft.ListView(expand=True, spacing=12)

        today_card = ft.Card(
            content=ft.Container(
                padding=16,
                content=ft.Column(
                    [
                        ft.Text("Сегодня", size=18, weight=ft.FontWeight.W_600),
                        ft.Container(content=self.today_list, height=self.LIST_SECTION_HEIGHT),
                    ],
                    spacing=12,
                ),
            )
        )
        unscheduled_card = ft.Card(
            content=ft.Container(
                padding=16,
                content=ft.Column(
                    [
                        ft.Text("Без даты", size=18, weight=ft.FontWeight.W_600),
                        ft.Container(content=self.unscheduled_list, height=self.LIST_SECTION_HEIGHT),
                    ],
                    spacing=12,
                ),
            )
        )

        lists_row = ft.Row(
            [
                ft.Container(content=today_card, expand=True),
                ft.Container(content=unscheduled_card, expand=True),
            ],
            spacing=16,
            vertical_alignment=ft.CrossAxisAlignment.START,
        )

        self.view = ft.Container(
            content=ft.Column(
                [
                    ft.Text("Задачи", size=24, weight=ft.FontWeight.BOLD),
                    quick_add,
                    lists_row,
                ],
                spacing=16,
                expand=True,
            ),
            expand=True,
            padding=20,
        )

        self.refresh_lists()
    
    # --- вызов из меню/автообновления ---
    def activate_from_menu(self):
        self.load()

    def load(self):
        # алиас для унификации с календарём
        self.refresh_lists()

    # ---------- Утилиты ----------
    def _new_time_picker(self) -> ft.TimePicker:
        picker = ft.TimePicker(help_text="Выберите время")
        picker.on_change = lambda e, _picker=picker: self._time_picker_on_change(_picker, e)
        picker.on_dismiss = lambda e, _picker=picker: self._time_picker_on_dismiss(_picker, e)
        return picker

    def _open_time_picker(self, picker: ft.TimePicker, tf: ft.TextField):
        prev = tf.value
        parsed = self._parse_time_tf(tf.value)
        if parsed:
            base_time = dt_time(parsed[0], parsed[1])
        else:
            now = datetime.now()
            base_time = dt_time(now.hour, now.minute)
        try:
            picker.value = base_time
        except Exception:
            pass
        picker.data = {"tf": tf, "prev": prev, "applied": False}
        if picker not in self.app.page.overlay:
            self.app.page.overlay.append(picker)
        self.app.page.open(picker)

    def _time_picker_on_change(self, picker: ft.TimePicker, e: ft.ControlEvent):
        data = picker.data or {}
        tf = data.get("tf")
        if not tf:
            return
        value = e.data or picker.value
        if value:
            self._set_tf_time(tf, value)
            data["applied"] = True
            picker.data = data

    def _time_picker_on_dismiss(self, picker: ft.TimePicker, e: ft.ControlEvent):
        data = picker.data or {}
        tf = data.get("tf")
        if not tf:
            picker.data = None
            return
        value = e.data
        if value:
            self._set_tf_time(tf, value)
            data["applied"] = True
        elif not data.get("applied"):
            tf.value = data.get("prev", tf.value)
            self.app.page.update()
        picker.data = None

    def _set_tf_date(self, tf: ft.TextField, value):
        from datetime import date as _date, datetime

        v = value  # сюда вы передаёте e.data or e.control.value

        # Если пришёл объект date
        if isinstance(v, _date):
            tf.value = v.strftime("%d.%m.%Y")

        # Если пришла строка
        elif isinstance(v, str) and v.strip():
            s = v.strip()

            # 1) ISO 'YYYY-MM-DD'
            try:
                tf.value = datetime.strptime(s, "%Y-%m-%d").strftime("%d.%m.%Y")
            except ValueError:
                # 2) 'YYYY-MM-DDTHH:MM:SS...' -> берём дату до 'T'
                if "T" in s:
                    try:
                        tf.value = datetime.strptime(s.split("T")[0], "%Y-%m-%d").strftime("%d.%m.%Y")
                    except ValueError:
                        pass
                else:
                    # 3) уже 'DD.MM.YYYY' — оставляем как есть, если валидно
                    try:
                        datetime.strptime(s, "%d.%m.%Y")
                        tf.value = s
                    except ValueError:
                        # не распознали — ничего не меняем
                        return

        # Обновляем UI
        self.app.page.update()

    def _set_tf_time(self, tf: ft.TextField, value):
        """
        Унифицирует значение из TimePicker в формат HH:MM.
        Поддерживает: datetime.time, "HH:MM", "HH:MM:SS".
        """
        if value in (None, ""):
            return

        # если пришёл time-объект
        try:
            tf.value = value.strftime("%H:%M")
            self.app.page.update()
            return
        except Exception:
            pass

        # строковые варианты
        s = str(value or "").strip()
        m = re.match(r"^(\d{1,2}):(\d{2})(?::(\d{2}))?$", s)
        if m:
            h = int(m.group(1))
            mm = int(m.group(2))
            if 0 <= h <= 23 and 0 <= mm <= 59:
                tf.value = f"{h:02d}:{mm:02d}"
        self.app.page.update()


    def _parse_date_tf(self, s: str):
        s = (s or "").strip()
        m = re.match(r"^\s*(\d{1,2})\.(\d{1,2})\.(\d{4})\s*$", s)
        if not m:
            return None
        d, mth, y = int(m.group(1)), int(m.group(2)), int(m.group(3))
        try:
            return date(y, mth, d)
        except ValueError:
            return None

    def _parse_time_tf(self, s: str):
        """
        Возвращает (hour, minute) или None. Допускает секунды.
        """
        s = (s or "").strip()
        m = re.match(r"^\s*(\d{1,2}):(\d{2})(?::\d{2})?\s*$", s)
        if not m:
            return None
        h, minute = int(m.group(1)), int(m.group(2))
        if 0 <= h <= 23 and 0 <= minute <= 59:
            return h, minute
        return None

    def _combine_dt(self, date_str: str, time_str: str):
        d = self._parse_date_tf(date_str)
        t = self._parse_time_tf(time_str)
        if d and t:
            return datetime(d.year, d.month, d.day, t[0], t[1])
        if d and not t:
            return datetime(d.year, d.month, d.day)  # без времени
        if not d and t:
            now = datetime.now()
            cand = datetime(now.year, now.month, now.day, t[0], t[1])
            if cand < now - timedelta(minutes=1):
                cand += timedelta(days=1)
            return cand
        return None

    # ---------- CRUD ----------
    def on_add(self, _):
        title = (self.title_tf.value or "").strip()
        if not title:
            return self._toast("Введите название задачи")

        if self.date_tf.value and self._parse_date_tf(self.date_tf.value) is None:
            return self._toast("Неверный формат даты. Пример: 10.10.2025")
        if self.time_tf.value and self._parse_time_tf(self.time_tf.value) is None:
            return self._toast("Неверный формат времени. Пример: 09:30")

        start_dt = self._combine_dt(self.date_tf.value, self.time_tf.value)

        try:
            duration = int(self.dur_tf.value) if self.dur_tf.value else None
        except ValueError:
            return self._toast("Длительность должна быть числом (мин)")

        priority = normalize_priority(self.priority_dd.value)

        task = self.svc.add(
            title=title,
            start=start_dt,
            duration_minutes=duration,
            priority=priority,
        )

        msg = "Задача добавлена"

        self.title_tf.value = ""
        self.date_tf.value = ""
        self.time_tf.value = ""
        self.dur_tf.value = "30"
        self.priority_dd.value = str(priority)
        self.refresh_lists()
        if GOOGLE_SYNC.auto_push_on_edit:
            self.app.push_tasks_to_google()
        self._toast(msg)

    def on_toggle_done(self, task_id: int, checked: bool):
        self.svc.set_status(task_id, "done" if checked else "todo")
        self.refresh_lists()
        if GOOGLE_SYNC.auto_push_on_edit:
            self.app.push_tasks_to_google()

    def on_delete(self, task_id: int):
        self.svc.delete(task_id)
        self.refresh_lists()
        if GOOGLE_SYNC.auto_push_on_edit:
            self.app.push_tasks_to_google()
        self._toast("Задача удалена")

    def on_edit_click(self, e: ft.ControlEvent):
        self.open_edit_dialog(int(e.control.data))

    # ---------- Рендер ----------
    def refresh_lists(self):
        from datetime import date as _date
        self.today_list.controls.clear()
        for t in self.svc.list_for_day(_date.today()):
            self.today_list.controls.append(self._row_for_task(t))
        self.unscheduled_list.controls.clear()
        for t in self.svc.list_unscheduled():
            self.unscheduled_list.controls.append(self._row_for_task(t))
        self.app.cleanup_overlays()
        self.app.page.update()

    def _row_for_task(self, t):
        meta = self._human_time(t)
        checkbox = ft.Checkbox(
            value=(t.status == "done"),
            on_change=lambda e, tid=t.id: self.on_toggle_done(tid, e.control.value),
        )

        checkbox_holder = ft.Container(
            width=52,
            alignment=ft.alignment.center,
            content=checkbox,
        )

        priority_marker = self._priority_marker(t.priority)

        title_text = ft.Text(
            t.title,
            weight=ft.FontWeight.W_600,
            size=15,
            max_lines=2,
            overflow=ft.TextOverflow.ELLIPSIS,
        )

        meta_items = []
        if getattr(t, "priority", 0) > 0:
            meta_items.append(
                ft.Container(
                    content=ft.Text(
                        priority_label(t.priority, short=True),
                        size=12,
                        weight=ft.FontWeight.W_500,
                        color=ft.Colors.WHITE,
                    ),
                    bgcolor=priority_color(t.priority),
                    padding=ft.padding.symmetric(horizontal=10, vertical=4),
                    border_radius=999,
                )
            )
        meta_items.append(
            ft.Text(
                meta,
                color=ft.Colors.BLUE_GREY_400,
                size=12,
            )
        )
        if t.gcal_event_id:
            meta_items.append(
                ft.Row(
                    controls=[
                        ft.Icon(ft.Icons.LINK, size=14),
                        ft.Text("Google", size=12, color=ft.Colors.BLUE_GREY_400),
                    ],
                    spacing=4,
                    vertical_alignment=ft.CrossAxisAlignment.CENTER,
                )
            )

        info_column = ft.Column(
            controls=[
                ft.Row(
                    controls=[priority_marker, title_text],
                    spacing=12,
                    vertical_alignment=ft.CrossAxisAlignment.CENTER,
                ),
                ft.Row(meta_items, spacing=12, wrap=True),
            ],
            spacing=6,
            alignment=ft.MainAxisAlignment.CENTER,
            expand=True,
        )

        actions = ft.Row(
            controls=[
                ft.IconButton(
                    icon=ft.Icons.EDIT_OUTLINED,
                    tooltip="Редактировать",
                    data=t.id,
                    on_click=self.on_edit_click,
                    style=ft.ButtonStyle(padding=ft.padding.all(8)),
                ),
                ft.IconButton(
                    icon=ft.Icons.DELETE_OUTLINE,
                    tooltip="Удалить",
                    on_click=lambda e, tid=t.id: self.on_delete(tid),
                    style=ft.ButtonStyle(padding=ft.padding.all(8)),
                ),
            ],
            spacing=4,
            vertical_alignment=ft.CrossAxisAlignment.CENTER,
        )

        content_row = ft.Row(
            controls=[checkbox_holder, info_column, actions],
            alignment=ft.MainAxisAlignment.SPACE_BETWEEN,
            vertical_alignment=ft.CrossAxisAlignment.CENTER,
        )

        return ft.Container(
            content=content_row,
            padding=ft.padding.symmetric(horizontal=16, vertical=12),
            border_radius=12,
            bgcolor=ft.Colors.SURFACE,
            border=ft.border.all(1, ft.Colors.with_opacity(0.08, ft.Colors.ON_SURFACE)),
        )

    # ---------- Диалог редактирования ----------
    def open_edit_dialog(self, task_id: int):
        t = self.svc.get(task_id)
        if not t:
            return self._toast("Задача не найдена")

        # --- поля без expand, фикс-ширины только там, где нужно ---
        title_tf = ft.TextField(label="Название", value=t.title, width=420)

        date_val = t.start.strftime("%d.%m.%Y") if t.start else ""
        time_val = t.start.strftime("%H:%M") if (t.start and t.start.time() != datetime.min.time()) else ""

        date_tf = ft.TextField(label="Дата", value=date_val, width=160)
        time_tf = ft.TextField(label="Время", value=time_val, width=120)


        # Пикеры (значения забираем из e.data или control.value)
        dp = ft.DatePicker(
            first_date=date(2000, 1, 1),
            last_date=date(2100, 12, 31),
            on_change=lambda e: self._set_tf_date(date_tf, e.data or e.control.value),
            on_dismiss=lambda e: self._set_tf_date(date_tf, e.control.value),
        )
        tp = self._new_time_picker()
        for p in (dp, tp):
            if p not in self.app.page.overlay:
                self.app.page.overlay.append(p)

        date_btn = ft.IconButton(
            icon=ft.Icons.CALENDAR_MONTH,
            tooltip="Календарь",
            on_click=lambda e, _dp=dp: self.app.page.open(_dp),
        )
        time_btn = ft.IconButton(
            icon=ft.Icons.SCHEDULE,
            tooltip="Выбрать время",
            on_click=lambda e, _tp=tp: self._open_time_picker(_tp, time_tf),
        )

        dur_tf = ft.TextField(
            label="Длительность, мин",
            value=(str(t.duration_minutes) if t.duration_minutes else ""),
            width=140
        )
        priority_dd = ft.Dropdown(
            label="Приоритет",
            width=160,
            value=str(getattr(t, "priority", 0)),
            options=[ft.dropdown.Option(key, label) for key, label in priority_options().items()],
        )
        notes_tf = ft.TextField(
            label="Заметки",
            value=(t.notes or ""),
            multiline=True,
            min_lines=3,
            max_lines=6,
        )

        def _remove_pickers():
            for ctrl in (dp, tp):
                try:
                    ctrl.open = False
                except Exception:
                    pass
                try:
                    if ctrl in self.app.page.overlay:
                        self.app.page.overlay.remove(ctrl)
                except Exception:
                    pass

        def _finalize_dialog():
            dlg = self.edit_dialog
            self.edit_dialog = None
            self._close_alert_dialog(dlg)

        def on_save(_):
            new_title = (title_tf.value or "").strip()
            if not new_title:
                return self._toast("Введите название")
            if date_tf.value and self._parse_date_tf(date_tf.value) is None:
                return self._toast("Неверный формат даты. Пример: 10.10.2025")
            if time_tf.value and self._parse_time_tf(time_tf.value) is None:
                return self._toast("Неверный формат времени. Пример: 09:30")

            new_start = self._combine_dt(date_tf.value, time_tf.value)
            try:
                new_dur = int(dur_tf.value) if dur_tf.value.strip() else None
            except ValueError:
                return self._toast("Длительность должна быть числом (мин)")

            updated = self.svc.update(
                task_id,
                title=new_title,
                notes=notes_tf.value,
                start=new_start,
                duration_minutes=new_dur,
                priority=normalize_priority(priority_dd.value),
            )

            _remove_pickers()
            _finalize_dialog()
            self.refresh_lists()
            if GOOGLE_SYNC.auto_push_on_edit:
                self.app.push_tasks_to_google()
            self._toast("Сохранено")

        def on_cancel(_=None):
            _remove_pickers()
            _finalize_dialog()

        # --- КОМПАКТНАЯ ВЁРСТКА ---

        # ... всё, что выше (поля, пикеры, on_save/on_cancel) оставь как есть ...

        # компактная разметка без Wrap
        DATE_W, TIME_W, DUR_W = 140, 100, 120
        date_tf.width = DATE_W
        time_tf.width = TIME_W
        dur_tf.width  = DUR_W

        date_btn.icon_size = 18
        time_btn.icon_size = 18

        utils_row = ft.Row(
            controls=[date_tf, date_btn, time_tf, time_btn, dur_tf, priority_dd],
            spacing=8,
            run_spacing=12,
            wrap=True,
            alignment=ft.MainAxisAlignment.START,
            vertical_alignment=ft.CrossAxisAlignment.CENTER,
        )
        buttons_row = ft.Row(
            [ft.TextButton("Отмена", on_click=on_cancel),
            ft.FilledButton("Сохранить", icon=ft.Icons.SAVE, on_click=on_save)],
            alignment=ft.MainAxisAlignment.END,
        )

        MAX_W = 520
        self.edit_dialog = ft.AlertDialog(
            modal=False,
            inset_padding=ft.padding.all(16),
            content_padding=ft.padding.all(12),
            title=ft.Text("Редактировать задачу"),
            content=ft.Container(
                width=MAX_W,  # вместо constraints
                content=ft.Column(
                    [title_tf, utils_row, notes_tf, buttons_row],
                    spacing=10,
                    tight=True,
                    scroll=ft.ScrollMode.ADAPTIVE,
                ),
            ),
        )

        if self.edit_dialog not in self.app.page.overlay:
            self.app.page.overlay.append(self.edit_dialog)
        self.edit_dialog.open = True
        self.edit_dialog.on_dismiss = on_cancel
        self.app.page.update()



    # ---------- Вспомогательное ----------
    def _human_time(self, t):
        if t.start and t.duration_minutes:
            return f"{t.start.strftime('%d.%m %H:%M')} · {t.duration_minutes} мин"
        if t.start:
            if t.start.time() == datetime.min.time():
                return "без времени"
            return t.start.strftime("%d.%m %H:%M")
        return "без времени"

    def _priority_marker(self, priority: int) -> ft.Control:
        if priority <= 0:
            return ft.Container(width=12)
        return ft.Container(
            width=12,
            height=12,
            border_radius=6,
            bgcolor=priority_color(priority),
            tooltip=priority_label(priority),
        )

    def _toast(self, text: str):
        self.app.page.snack_bar = ft.SnackBar(ft.Text(text))
        self.app.page.snack_bar.open = True
        self.app.page.update()

    def _close_alert_dialog(self, dlg: ft.AlertDialog | None):
        if not dlg:
            return
        try:
            dlg.open = False
        except Exception:
            pass
        try:
            if dlg in self.app.page.overlay:
                self.app.page.overlay.remove(dlg)
        except Exception:
            pass
        self.app.page.update()
        self.app.cleanup_overlays()

```

### utils/__init__.py
```python
"""Helper utilities for Planner."""

__all__ = ["datetime_utils"]

```

### utils/datetime_utils.py
```python
"""Utilities for working with RFC3339 timestamps and UTC datetimes."""

from __future__ import annotations

from datetime import date, datetime, time, timezone
from typing import Optional, Union

UTC = timezone.utc


def parse_rfc3339(s: Optional[str]) -> Optional[datetime]:
    """Parse a RFC3339 string and return a timezone-aware UTC datetime."""

    if not s:
        return None

    value = s.strip()
    if not value:
        return None

    if value.endswith("Z"):
        value = value[:-1] + "+00:00"

    if "." in value:
        head, tail = value.split(".", 1)
        if "+" in tail:
            frac, tz = tail.split("+", 1)
            sign = "+"
        elif "-" in tail:
            frac, tz = tail.split("-", 1)
            sign = "-"
        else:
            frac, tz = tail, "+00:00"
            sign = "+"
        frac = (frac + "000000")[:6]
        value = f"{head}.{frac}{sign}{tz}"
    try:
        dt = datetime.fromisoformat(value)
    except ValueError:
        return None

    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=UTC)
    else:
        dt = dt.astimezone(UTC)
    return dt


def to_rfc3339_utc(dt: Optional[Union[datetime, str]]) -> Optional[str]:
    """Convert a datetime (or string) to RFC3339 in UTC with second precision."""

    if dt is None:
        return None
    if isinstance(dt, str):
        dt = parse_rfc3339(dt)
    if dt is None:
        return None
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=UTC)
    else:
        dt = dt.astimezone(UTC)
    return dt.replace(microsecond=0).isoformat().replace("+00:00", "Z")


def ensure_utc(dt: Optional[datetime]) -> Optional[datetime]:
    if dt is None:
        return None
    if dt.tzinfo is None:
        return dt.replace(tzinfo=UTC)
    return dt.astimezone(UTC)


def utc_now() -> datetime:
    return datetime.now(UTC)


def midnight_utc(d: date) -> datetime:
    return datetime.combine(d, time.min, tzinfo=UTC)


def normalize_midnight(dt: Optional[datetime]) -> Optional[datetime]:
    if dt is None:
        return None
    normalized = ensure_utc(dt)
    return normalized.replace(hour=0, minute=0, second=0, microsecond=0)


__all__ = [
    "UTC",
    "ensure_utc",
    "midnight_utc",
    "normalize_midnight",
    "parse_rfc3339",
    "to_rfc3339_utc",
    "utc_now",
]

```

